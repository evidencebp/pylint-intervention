file,name,complexity
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,_load_weights,19
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.__init__,12
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,init_weights_vit_jax,8
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,checkpoint_filter_fn,7
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,ParallelBlock.__init__,6
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.reset_classifier,6
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,Block.__init__,5
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,ParallelBlock,5
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,init_weights_vit_moco,4
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,resize_pos_embed,4
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,_create_vision_transformer,4
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,Block,4
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.forward_head,4
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,init_weights_vit_timm,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,get_init_weights_vit,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,Attention,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,LayerScale,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,ParallelBlock._forward_jit,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,ParallelBlock._forward,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,ParallelBlock.forward,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.init_weights,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.forward_features,3
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,Attention.__init__,2
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,LayerScale.forward,2
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer._reset_representation,2
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,_cfg,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_tiny_patch16_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_tiny_patch16_384,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch32_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch32_384,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch16_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch16_384,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch32_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base2_patch32_256,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch32_384,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch16_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch16_384,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch8_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_large_patch32_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_large_patch32_384,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_large_patch16_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_large_patch16_384,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_large_patch14_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_huge_patch14_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_giant_patch14_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_gigantic_patch14_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_tiny_patch16_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch32_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch16_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch32_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch16_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch8_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_large_patch32_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_large_patch16_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_huge_patch14_224_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch16_224_sam,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch32_224_sam,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch16_224_dino,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch8_224_dino,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch16_224_dino,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch8_224_dino,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch16_224_miil_in21k,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch16_224_miil,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch16_36x1_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_small_patch16_18x2_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,vit_base_patch16_18x2_224,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,Attention.forward,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,LayerScale.__init__,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,Block.forward,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer._init_weights,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.load_pretrained,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.no_weight_decay,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.group_matcher,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.set_grad_checkpointing,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.get_classifier,1
c:/src/pylint-intervention/data/in_the_wild\versions/pytorch-image-models/41dc49a33752b72dbb3cff5cb181b9953e07971f/before/timm_slash_models_slash_vision_transformer.py,VisionTransformer.forward,1
