path,msg_id,msg,alerts,chosen,In which repository the modification was done?,In which pull request the modification was done?,Do you consider the removed alert harmful?,Why do you consider it harmful (or harmless)?,"What is the code quality (1 lowest, 10 best)? Code quality refers to the code prior to the pull request.",Why do you consider the code quality as such?,"What is the expected benefit(1 – negative, 5 – neutral, 10 – great)?",Why do you consider the pull request to improve the code (or not improve it)?
examples\training\avg_word_embeddings\training_stsbenchmark_bilstm.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\evaluation\LabelAccuracyEvaluator.py,C0301, line-too-long,1,1, , , , , , , , 
examples\training\sts\training_stsbenchmark_continue_training.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\model_card_templates.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\applications\semantic-search\semantic_search_quora_elasticsearch.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\matryoshka\2d_matryoshka_sts.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\model_card.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\evaluation\evaluation_stsbenchmark.py,C0301, line-too-long,1,1, , , , , , , , 
sentence_transformers\fit_mixin.py,R0912, too-many-branches,2,1, , , , , , , , 
sentence_transformers\readers\TripletReader.py,C0301, line-too-long,1,1, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_avg_word_embeddings.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\distillation\model_distillation_layer_reduction.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\evaluation\TripletEvaluator.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\training\matryoshka\matryoshka_nli.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\evaluation\SequentialEvaluator.py,C0301, line-too-long,2,1, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_cnn.py,W0718, broad-exception-caught,1,1, , , , , , , , 
docs\_themes\sphinx_rtd_theme\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
examples\training\multilingual\get_parallel_data_opus.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\models\Pooling.py,R0912, too-many-branches,1,1, , , , , , , , 
sentence_transformers\cross_encoder\CrossEncoder.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\datasets\SentencesDataset.py,C0301, line-too-long,2,1, , , , , , , , 
examples\training\adaptive_layer\adaptive_layer_sts.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_bow.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\data_augmentation\train_sts_indomain_bm25.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\quora_duplicate_questions\training_OnlineContrastiveLoss.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_tf-idf_word_embeddings.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\multilingual\get_parallel_data_wikimatrix.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\LoggingHandler.py,C0301, line-too-long,1,1, , , , , , , , 
sentence_transformers\models\CNN.py,C0301, line-too-long,1,1, , , , , , , , 
sentence_transformers\trainer.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\matryoshka\matryoshka_eval_stsb.py,C0301, line-too-long,2,1, , , , , , , , 
sentence_transformers\models\CLIPModel.py,C0301, line-too-long,1,1, , , , , , , , 
examples\applications\image-search\example.py,C0301, line-too-long,1,1, , , , , , , , 
examples\training\distillation\model_distillation.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\quora_duplicate_questions\training_multi-task-learning.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\nli\training_nli_v3.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\SentenceTransformer.py,W0718, broad-exception-caught,2,1, , , , , , , , 
examples\training\data_augmentation\train_sts_indomain_nlpaug.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\quora_duplicate_questions\application_duplicate_questions_mining.py,C0301, line-too-long,2,1, , , , , , , , 
sentence_transformers\evaluation\ParaphraseMiningEvaluator.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\unsupervised_learning\TSDAE\eval_askubuntu.py,C0301, line-too-long,2,1, , , , , , , , 
sentence_transformers\models\LayerNorm.py,C0301, line-too-long,1,1, , , , , , , , 
examples\training\other\training_wikipedia_sections.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\applications\computing-embeddings\computing_embeddings_multi_gpu.py,C0301, line-too-long,2,1, , , , , , , , 
examples\training\adaptive_layer\adaptive_layer_nli.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\nli\training_nli_v2.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\models\tokenizer\WhitespaceTokenizer.py,C0301, line-too-long,1,1, , , , , , , , 
examples\applications\computing-embeddings\computing_embeddings.py,C0301, line-too-long,1,1, , , , , , , , 
examples\training\other\training_multi-task.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\matryoshka\matryoshka_nli_reduced_dim.py,W0718, broad-exception-caught,1,1, , , , , , , , 
sentence_transformers\evaluation\TranslationEvaluator.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\unsupervised_learning\query_generation\3_programming_semantic_search.py,C0301, line-too-long,2,1, , , , , , , , 
sentence_transformers\models\LSTM.py,C0301, line-too-long,2,1, , , , , , , , 
examples\training\matryoshka\2d_matryoshka_nli.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\matryoshka\matryoshka_sts.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\nli\training_nli.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\quora_duplicate_questions\training_MultipleNegativesRankingLoss.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\paraphrases\training.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\training\sts\training_stsbenchmark.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\applications\clustering\agglomerative.py,C0301, line-too-long,2,1, , , , , , , , 
examples\unsupervised_learning\query_generation\2_programming_train_bi-encoder.py,C0301, line-too-long,2,1, , , , , , , , 
sentence_transformers\util.py,C0302, too-many-lines,1,1, , , , , , , , 
sentence_transformers\evaluation\SentenceEvaluator.py,W0107,unnecessary-pass,1,1, , , , , , , , 
sentence_transformers\models\Normalize.py,C0301, line-too-long,1,1, , , , , , , , 
examples\training\multilingual\get_parallel_data_talks.py,C0301, line-too-long,6,0, , , , , , , , 
examples\training\quora_duplicate_questions\create_splits.py,C0301, line-too-long,16,0, , , , , , , , 
sentence_transformers\losses\BatchHardSoftMarginTripletLoss.py,C0301, line-too-long,16,0, , , , , , , , 
sentence_transformers\models\tokenizer\PhraseTokenizer.py,C0301, line-too-long,4,0, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_bilstm.py,C0301, line-too-long,6,0, , , , , , , , 
sentence_transformers\cross_encoder\evaluation\CEBinaryClassificationEvaluator.py,C0301, line-too-long,7,0, , , , , , , , 
sentence_transformers\datasets\SentenceLabelDataset.py,C0301, line-too-long,11,0, , , , , , , , 
sentence_transformers\models\Transformer.py,C0301, line-too-long,5,0, , , , , , , , 
sentence_transformers\models\WordEmbeddings.py,C0301, line-too-long,8,0, , , , , , , , 
examples\evaluation\evaluation_translation_matching.py,C0301, line-too-long,8,0, , , , , , , , 
examples\training\distillation\dimensionality_reduction.py,C0301, line-too-long,3,0, , , , , , , , 
examples\unsupervised_learning\CT\train_ct_from_file.py,C0301, line-too-long,6,0, , , , , , , , 
sentence_transformers\datasets\ParallelSentencesDataset.py,C0301, line-too-long,17,0, , , , , , , , 
examples\training\sts\training_stsbenchmark_continue_training.py,C0301, line-too-long,9,0, , , , , , , , 
sentence_transformers\models\Asym.py,C0301, line-too-long,8,0, , , , , , , , 
examples\applications\embedding-quantization\semantic_search_usearch.py,C0301, line-too-long,10,0, , , , , , , , 
examples\training\other\training_batch_hard_trec.py,C0301, line-too-long,9,0, , , , , , , , 
examples\unsupervised_learning\CT\train_askubuntu_ct.py,C0301, line-too-long,5,0, , , , , , , , 
sentence_transformers\losses\ContrastiveLoss.py,C0301, line-too-long,8,0, , , , , , , , 
sentence_transformers\losses\MegaBatchMarginLoss.py,C0301, line-too-long,18,0, , , , , , , , 
sentence_transformers\model_card_templates.py,C0301, line-too-long,4,0, , , , , , , , 
examples\training\hpo\hpo_nli.py,C0301, line-too-long,4,0, , , , , , , , 
sentence_transformers\losses\MarginMSELoss.py,C0301, line-too-long,25,0, , , , , , , , 
examples\applications\semantic-search\semantic_search_quora_elasticsearch.py,C0301, line-too-long,4,0, , , , , , , , 
examples\training\matryoshka\2d_matryoshka_sts.py,C0301, line-too-long,10,0, , , , , , , , 
sentence_transformers\model_card.py,C0301, line-too-long,50,0, , , , , , , , 
sentence_transformers\model_card.py,R0912, too-many-branches,2,0, , , , , , , , 
sentence_transformers\model_card.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
sentence_transformers\model_card.py,W0718, broad-exception-caught,6,0, , , , , , , , 
examples\unsupervised_learning\CT_In-Batch_Negatives\train_askubuntu_ct-improved.py,C0301, line-too-long,5,0, , , , , , , , 
examples\unsupervised_learning\query_generation\1_programming_query_generation.py,C0301, line-too-long,4,0, , , , , , , , 
sentence_transformers\similarity_functions.py,C0301, line-too-long,8,0, , , , , , , , 
examples\applications\semantic-search\semantic_search_quora_pytorch.py,C0301, line-too-long,5,0, , , , , , , , 
examples\training\data_augmentation\train_sts_indomain_semantic.py,C0301, line-too-long,12,0, , , , , , , , 
examples\training\data_augmentation\train_sts_seed_optimization.py,C0301, line-too-long,7,0, , , , , , , , 
sentence_transformers\fit_mixin.py,C0301, line-too-long,34,0, , , , , , , , 
sentence_transformers\fit_mixin.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\applications\embedding-quantization\semantic_search_faiss_benchmark.py,C0301, line-too-long,4,0, , , , , , , , 
sentence_transformers\losses\Matryoshka2dLoss.py,C0301, line-too-long,9,0, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_avg_word_embeddings.py,C0301, line-too-long,7,0, , , , , , , , 
examples\training\distillation\model_distillation_layer_reduction.py,C0301, line-too-long,14,0, , , , , , , , 
examples\unsupervised_learning\SimCSE\train_simcse_from_file.py,C0301, line-too-long,6,0, , , , , , , , 
sentence_transformers\cross_encoder\evaluation\CERerankingEvaluator.py,C0301, line-too-long,8,0, , , , , , , , 
sentence_transformers\evaluation\MSEEvaluator.py,C0301, line-too-long,11,0, , , , , , , , 
sentence_transformers\evaluation\TripletEvaluator.py,C0301, line-too-long,11,0, , , , , , , , 
sentence_transformers\evaluation\TripletEvaluator.py,R0912, too-many-branches,1,0, , , , , , , , 
sentence_transformers\losses\AdaptiveLayerLoss.py,C0301, line-too-long,17,0, , , , , , , , 
sentence_transformers\losses\CoSENTLoss.py,C0301, line-too-long,11,0, , , , , , , , 
sentence_transformers\losses\MSELoss.py,C0301, line-too-long,8,0, , , , , , , , 
examples\training\data_augmentation\train_sts_qqp_crossdomain.py,C0301, line-too-long,12,0, , , , , , , , 
examples\training\ms_marco\train_bi-encoder_mnrl.py,C0301, line-too-long,19,0, , , , , , , , 
sentence_transformers\training_args.py,C0301, line-too-long,35,0, , , , , , , , 
examples\training\matryoshka\matryoshka_nli.py,C0301, line-too-long,12,0, , , , , , , , 
examples\training\multilingual\get_parallel_data_tatoeba.py,C0301, line-too-long,3,0, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_cnn.py,C0301, line-too-long,5,0, , , , , , , , 
examples\unsupervised_learning\SimCSE\train_askubuntu_simcse.py,C0301, line-too-long,4,0, , , , , , , , 
sentence_transformers\evaluation\BinaryClassificationEvaluator.py,C0301, line-too-long,16,0, , , , , , , , 
examples\training\multilingual\get_parallel_data_opus.py,C0301, line-too-long,8,0, , , , , , , , 
sentence_transformers\models\Dense.py,C0301, line-too-long,3,0, , , , , , , , 
examples\unsupervised_learning\CT_In-Batch_Negatives\train_ct-improved_from_file.py,C0301, line-too-long,5,0, , , , , , , , 
examples\training\cross-encoder\training_nli.py,C0301, line-too-long,6,0, , , , , , , , 
examples\unsupervised_learning\TSDAE\train_stsb_tsdae.py,C0301, line-too-long,8,0, , , , , , , , 
sentence_transformers\quantization.py,C0301, line-too-long,17,0, , , , , , , , 
sentence_transformers\quantization.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\training\cross-encoder\training_stsbenchmark.py,C0301, line-too-long,8,0, , , , , , , , 
sentence_transformers\models\Pooling.py,C0301, line-too-long,15,0, , , , , , , , 
sentence_transformers\models\Pooling.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\applications\embedding-quantization\semantic_search_recommended.py,C0301, line-too-long,5,0, , , , , , , , 
examples\applications\text-summarization\text-summarization.py,C0301, line-too-long,4,0, , , , , , , , 
sentence_transformers\cross_encoder\CrossEncoder.py,C0301, line-too-long,65,0, , , , , , , , 
sentence_transformers\cross_encoder\CrossEncoder.py,R0912, too-many-branches,1,0, , , , , , , , 
sentence_transformers\cross_encoder\CrossEncoder.py,R0915, too-many-statements,1,0, , , , , , , , 
sentence_transformers\readers\STSDataReader.py,C0301, line-too-long,3,0, , , , , , , , 
examples\applications\semantic-search\semantic_search_quora_hnswlib.py,C0301, line-too-long,9,0, , , , , , , , 
examples\training\adaptive_layer\adaptive_layer_sts.py,C0301, line-too-long,10,0, , , , , , , , 
examples\training\ms_marco\train_bi-encoder_margin-mse.py,C0301, line-too-long,14,0, , , , , , , , 
sentence_transformers\losses\ContrastiveTensionLoss.py,C0301, line-too-long,23,0, , , , , , , , 
sentence_transformers\losses\CosineSimilarityLoss.py,C0301, line-too-long,9,0, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_bow.py,C0301, line-too-long,9,0, , , , , , , , 
examples\training\data_augmentation\train_sts_indomain_bm25.py,C0301, line-too-long,11,0, , , , , , , , 
examples\training\quora_duplicate_questions\training_OnlineContrastiveLoss.py,C0301, line-too-long,15,0, , , , , , , , 
examples\unsupervised_learning\SimCSE\train_stsb_simcse.py,C0301, line-too-long,7,0, , , , , , , , 
examples\unsupervised_learning\TSDAE\train_askubuntu_tsdae.py,C0301, line-too-long,5,0, , , , , , , , 
sentence_transformers\losses\BatchAllTripletLoss.py,C0301, line-too-long,10,0, , , , , , , , 
examples\training\avg_word_embeddings\training_stsbenchmark_tf-idf_word_embeddings.py,C0301, line-too-long,11,0, , , , , , , , 
sentence_transformers\datasets\DenoisingAutoEncoderDataset.py,C0301, line-too-long,3,0, , , , , , , , 
sentence_transformers\evaluation\EmbeddingSimilarityEvaluator.py,C0301, line-too-long,22,0, , , , , , , , 
examples\training\multilingual\get_parallel_data_wikimatrix.py,C0301, line-too-long,4,0, , , , , , , , 
sentence_transformers\LoggingHandler.py,W0706, try-except-raise,1,0, , , , , , , , 
sentence_transformers\LoggingHandler.py,W0718, broad-exception-caught,1,0, , , , , , , , 
sentence_transformers\losses\AnglELoss.py,C0301, line-too-long,10,0, , , , , , , , 
examples\training\ms_marco\eval_cross-encoder-trec-dl.py,C0301, line-too-long,7,0, , , , , , , , 
examples\training\ms_marco\train_cross-encoder_kd.py,C0301, line-too-long,20,0, , , , , , , , 
examples\applications\embedding-quantization\semantic_search_faiss.py,C0301, line-too-long,10,0, , , , , , , , 
examples\applications\semantic-search\semantic_search_quora_annoy.py,C0301, line-too-long,11,0, , , , , , , , 
examples\training\distillation\model_quantization.py,C0301, line-too-long,7,0, , , , , , , , 
examples\training\ms_marco\eval_msmarco.py,C0301, line-too-long,5,0, , , , , , , , 
sentence_transformers\losses\MatryoshkaLoss.py,C0301, line-too-long,9,0, , , , , , , , 
sentence_transformers\trainer.py,C0301, line-too-long,105,0, , , , , , , , 
sentence_transformers\trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
sentence_transformers\trainer.py,R0915, too-many-statements,1,0, , , , , , , , 
sentence_transformers\losses\SoftmaxLoss.py,C0301, line-too-long,13,0, , , , , , , , 
examples\training\distillation\model_distillation.py,C0301, line-too-long,14,0, , , , , , , , 
sentence_transformers\cross_encoder\evaluation\CECorrelationEvaluator.py,C0301, line-too-long,4,0, , , , , , , , 
sentence_transformers\losses\CachedMultipleNegativesRankingLoss.py,C0301, line-too-long,36,0, , , , , , , , 
sentence_transformers\losses\TripletLoss.py,C0301, line-too-long,3,0, , , , , , , , 
examples\applications\cross-encoder\cross-encoder_reranking.py,C0301, line-too-long,5,0, , , , , , , , 
examples\training\ms_marco\train_cross-encoder_scratch.py,C0301, line-too-long,13,0, , , , , , , , 
examples\training\quora_duplicate_questions\training_multi-task-learning.py,C0301, line-too-long,21,0, , , , , , , , 
examples\unsupervised_learning\MLM\train_mlm.py,C0301, line-too-long,5,0, , , , , , , , 
examples\training\nli\training_nli_v3.py,C0301, line-too-long,13,0, , , , , , , , 
sentence_transformers\SentenceTransformer.py,C0301, line-too-long,187,0, , , , , , , , 
sentence_transformers\SentenceTransformer.py,C0302, too-many-lines,1,0, , , , , , , , 
sentence_transformers\SentenceTransformer.py,R0912, too-many-branches,3,0, , , , , , , , 
sentence_transformers\SentenceTransformer.py,R0915, too-many-statements,3,0, , , , , , , , 
sentence_transformers\losses\BatchHardTripletLoss.py,C0301, line-too-long,23,0, , , , , , , , 
sentence_transformers\losses\GISTEmbedLoss.py,C0301, line-too-long,7,0, , , , , , , , 
examples\training\data_augmentation\train_sts_indomain_nlpaug.py,C0301, line-too-long,11,0, , , , , , , , 
examples\applications\parallel-sentence-mining\bitext_mining.py,C0301, line-too-long,3,0, , , , , , , , 
sentence_transformers\losses\MultipleNegativesRankingLoss.py,C0301, line-too-long,22,0, , , , , , , , 
examples\applications\computing-embeddings\computing_embeddings_streaming.py,C0301, line-too-long,3,0, , , , , , , , 
examples\training\cross-encoder\training_quora_duplicate_questions.py,C0301, line-too-long,7,0, , , , , , , , 
sentence_transformers\losses\DenoisingAutoEncoderLoss.py,C0301, line-too-long,23,0, , , , , , , , 
sentence_transformers\evaluation\MSEEvaluatorFromDataFrame.py,C0301, line-too-long,13,0, , , , , , , , 
sentence_transformers\models\WordWeights.py,C0301, line-too-long,7,0, , , , , , , , 
sentence_transformers\evaluation\ParaphraseMiningEvaluator.py,C0301, line-too-long,19,0, , , , , , , , 
examples\training\ms_marco\multilingual\translate_queries.py,C0301, line-too-long,4,0, , , , , , , , 
examples\unsupervised_learning\TSDAE\train_tsdae_from_file.py,C0301, line-too-long,6,0, , , , , , , , 
sentence_transformers\losses\MultipleNegativesSymmetricRankingLoss.py,C0301, line-too-long,11,0, , , , , , , , 
examples\applications\retrieve_rerank\in_document_search_crossencoder.py,C0301, line-too-long,6,0, , , , , , , , 
examples\unsupervised_learning\query_generation\example_query_generation.py,C0301, line-too-long,9,0, , , , , , , , 
sentence_transformers\losses\CachedGISTEmbedLoss.py,C0301, line-too-long,37,0, , , , , , , , 
examples\applications\parallel-sentence-mining\bucc2018.py,C0301, line-too-long,9,0, , , , , , , , 
examples\training\other\training_wikipedia_sections.py,C0301, line-too-long,13,0, , , , , , , , 
examples\unsupervised_learning\CT_In-Batch_Negatives\train_stsb_ct-improved.py,C0301, line-too-long,5,0, , , , , , , , 
sentence_transformers\losses\CachedMultipleNegativesSymmetricRankingLoss.py,C0301, line-too-long,21,0, , , , , , , , 
examples\training\adaptive_layer\adaptive_layer_nli.py,C0301, line-too-long,11,0, , , , , , , , 
examples\training\nli\training_nli_v2.py,C0301, line-too-long,12,0, , , , , , , , 
examples\applications\clustering\fast_clustering.py,C0301, line-too-long,7,0, , , , , , , , 
examples\applications\embedding-quantization\semantic_search_usearch_benchmark.py,C0301, line-too-long,4,0, , , , , , , , 
examples\training\other\training_multi-task.py,C0301, line-too-long,12,0, , , , , , , , 
sentence_transformers\evaluation\RerankingEvaluator.py,C0301, line-too-long,21,0, , , , , , , , 
sentence_transformers\sampler.py,C0301, line-too-long,18,0, , , , , , , , 
examples\training\matryoshka\matryoshka_nli_reduced_dim.py,C0301, line-too-long,16,0, , , , , , , , 
sentence_transformers\cross_encoder\evaluation\CEF1Evaluator.py,C0301, line-too-long,6,0, , , , , , , , 
sentence_transformers\evaluation\TranslationEvaluator.py,C0301, line-too-long,12,0, , , , , , , , 
sentence_transformers\losses\BatchSemiHardTripletLoss.py,C0301, line-too-long,20,0, , , , , , , , 
sentence_transformers\evaluation\InformationRetrievalEvaluator.py,C0301, line-too-long,30,0, , , , , , , , 
sentence_transformers\evaluation\InformationRetrievalEvaluator.py,R0912, too-many-branches,3,0, , , , , , , , 
sentence_transformers\readers\NLIDataReader.py,C0301, line-too-long,3,0, , , , , , , , 
examples\applications\semantic-search\semantic_search_publications.py,C0301, line-too-long,7,0, , , , , , , , 
examples\training\matryoshka\2d_matryoshka_nli.py,C0301, line-too-long,10,0, , , , , , , , 
examples\training\matryoshka\matryoshka_sts.py,C0301, line-too-long,11,0, , , , , , , , 
examples\training\nli\training_nli.py,C0301, line-too-long,11,0, , , , , , , , 
examples\training\multilingual\make_multilingual.py,C0301, line-too-long,25,0, , , , , , , , 
examples\training\multilingual\make_multilingual.py,W0718, broad-exception-caught,5,0, , , , , , , , 
examples\training\quora_duplicate_questions\training_MultipleNegativesRankingLoss.py,C0301, line-too-long,19,0, , , , , , , , 
sentence_transformers\cross_encoder\evaluation\CEBinaryAccuracyEvaluator.py,C0301, line-too-long,4,0, , , , , , , , 
examples\unsupervised_learning\CT\train_stsb_ct.py,C0301, line-too-long,5,0, , , , , , , , 
sentence_transformers\models\BoW.py,C0301, line-too-long,3,0, , , , , , , , 
sentence_transformers\models\WeightedLayerPooling.py,C0301, line-too-long,6,0, , , , , , , , 
examples\applications\semantic-search\semantic_search_quora_faiss.py,C0301, line-too-long,13,0, , , , , , , , 
sentence_transformers\data_collator.py,C0301, line-too-long,6,0, , , , , , , , 
examples\training\paraphrases\training.py,C0301, line-too-long,10,0, , , , , , , , 
examples\training\sts\training_stsbenchmark.py,C0301, line-too-long,9,0, , , , , , , , 
sentence_transformers\losses\OnlineContrastiveLoss.py,C0301, line-too-long,8,0, , , , , , , , 
sentence_transformers\cross_encoder\evaluation\CESoftmaxAccuracyEvaluator.py,C0301, line-too-long,3,0, , , , , , , , 
sentence_transformers\util.py,C0301, line-too-long,94,0, , , , , , , , 
sentence_transformers\util.py,R0912, too-many-branches,3,0, , , , , , , , 
sentence_transformers\util.py,R0915, too-many-statements,1,0, , , , , , , , 
sentence_transformers\util.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
sentence_transformers\util.py,W0718, broad-exception-caught,4,0, , , , , , , , 
examples\applications\semantic-search\semantic_search_wikipedia_qa.py,C0301, line-too-long,3,0, , , , , , , , 
sentence_transformers\evaluation\SentenceEvaluator.py,C0301, line-too-long,7,0, , , , , , , , 
