path,msg_id,msg,alerts,chosen,In which repository the modification was done?,In which pull request the modification was done?,Do you consider the removed alert harmful?,Why do you consider it harmful (or harmless)?,"What is the code quality (1 lowest, 10 best)? Code quality refers to the code prior to the pull request.",Why do you consider the code quality as such?,"What is the expected benefit(1 – negative, 5 – neutral, 10 – great)?",Why do you consider the pull request to improve the code (or not improve it)?
examples\pytorch\question-answering\run_qa.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\codeparrot\scripts\validation_loss.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\convert_graph_to_onnx.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\models\clipseg\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\dpt\modeling_dpt.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\fuyu\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\idefics\modeling_idefics.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\lxmert\modeling_lxmert.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\mbart\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\mistral\convert_mistral_weights_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\mpnet\modeling_mpnet.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\oneformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\umt5\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\univnet\configuration_univnet.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\vit\feature_extraction_vit.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\yolos\image_processing_yolos.py,C0325, superfluous-parens,1,1, , , , , , , , 
examples\flax\question-answering\utils_qa.py,R0916, too-many-boolean-expressions,2,1, , , , , , , , 
examples\modular-transformers\modeling_dummy_bert.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_blenderbot_small.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\chameleon\modeling_chameleon.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\convnext\feature_extraction_convnext.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\mctct\modeling_mctct.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\detr\image_processing_detr.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\dpt\feature_extraction_dpt.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\electra\tokenization_electra.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\gpt_bigcode\modeling_gpt_bigcode.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mamba2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mask2former\convert_mask2former_original_pytorch_checkpoint_to_pytorch.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\megatron_bert\modeling_megatron_bert.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\mobilebert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mobilevit\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mpnet\modeling_tf_mpnet.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\olmoe\modeling_olmoe.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\patchtsmixer\modeling_patchtsmixer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\rt_detr\convert_rt_detr_original_pytorch_checkpoint_to_hf.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\siglip\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\speech_encoder_decoder\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\speech_encoder_decoder\convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\unispeech_sat\modeling_unispeech_sat.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\whisper\modeling_tf_whisper.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\xlm\tokenization_xlm.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\zoedepth\convert_zoedepth_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\training_args_tf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\utils\hub.py,R0911, too-many-return-statements,2,1, , , , , , , , 
examples\pytorch\speech-pretraining\run_wav2vec2_pretraining_no_trainer.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\bertology\run_prune_gpt.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\seq2seq-distillation\distillation.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\barthez\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\clipseg\modeling_clipseg.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\decision_transformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\decision_transformer\modeling_decision_transformer.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\dpt\convert_dpt_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\maskformer\modeling_maskformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\rwkv\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\sew_d\convert_sew_d_original_pytorch_checkpoint_to_pytorch.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
src\transformers\models\speecht5\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\squeezebert\tokenization_squeezebert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\x_clip\convert_x_clip_original_pytorch_to_hf.py,R0915, too-many-statements,2,1, , , , , , , , 
examples\pytorch\language-modeling\run_clm_no_trainer.py,R0915, too-many-statements,2,1, , , , , , , , 
scripts\fsmt\fsmt-make-tiny-model.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\agents\tools.py,W0718, broad-exception-caught,2,1, , , , , , , , 
src\transformers\models\altclip\modeling_altclip.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\deprecated\tapex\tokenization_tapex.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_tf_transfo_xl.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\flaubert\modeling_tf_flaubert.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\flava\configuration_flava.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_layoutlmv3.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\led\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\mobilenet_v2\feature_extraction_mobilenet_v2.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mpnet\tokenization_mpnet.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\owlvit\modeling_owlvit.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\t5\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\pipelines\token_classification.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
examples\legacy\run_chinese_ref.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
examples\legacy\seq2seq\run_distributed_eval.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\bert\tokenization_bert_tf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\bloom\modeling_bloom.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\clip\modeling_tf_clip.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\donut\processing_donut.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\gemma\modeling_gemma.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\gpt_neox_japanese\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\longt5\convert_longt5x_checkpoint_to_flax.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\mistral\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\olmoe\convert_olmoe_weights_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\sam\processing_sam.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\stablelm\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\visual_bert\convert_visual_bert_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\whisper\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\onnx\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
examples\legacy\seq2seq\finetune_trainer.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\information-gain-filtration\run_clm_igf.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\visual_bert\utils.py,R0912, too-many-branches,2,1, , , , , , , , 
examples\research_projects\wav2vec2\run_asr.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\generation\flax_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\align\modeling_align.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\data2vec\convert_data2vec_text_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\mega\modeling_mega.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\detr\feature_extraction_detr.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\omdet_turbo\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\oneformer\image_processing_oneformer.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\pix2struct\modeling_pix2struct.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\roberta\modeling_roberta.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\univnet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
examples\legacy\seq2seq\pack_dataset.py,C0301, line-too-long,1,1, , , , , , , , 
examples\pytorch\instance-segmentation\run_instance_segmentation_no_trainer.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\pytorch\language-modeling\run_mlm_no_trainer.py,R0915, too-many-statements,2,1, , , , , , , , 
examples\research_projects\self-training-text-classification\selftraining.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\tensorflow\language-modeling\run_mlm.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\code_llama\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\grounding_dino\convert_grounding_dino_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\hubert\convert_hubert_original_pytorch_checkpoint_to_pytorch.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\idefics\processing_idefics.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\layoutxlm\tokenization_layoutxlm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\marian\modeling_marian.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\musicgen_melody\modeling_musicgen_melody.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\phobert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\speecht5\modeling_speecht5.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\table_transformer\modeling_table_transformer.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\udop\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\visual_bert\modeling_visual_bert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\wav2vec2\convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\pipelines\image_classification.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\tokenization_utils.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\altclip\configuration_altclip.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\bart\modeling_tf_bart.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\blip_2\convert_blip_2_original_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\convnext\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\dac\feature_extraction_dac.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\deprecated\van\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\donut\modeling_donut_swin.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\fsmt\modeling_fsmt.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\hiera\convert_hiera_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\layoutlm\tokenization_layoutlm.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\llava_next\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\llava_onevision\convert_llava_onevision_weights_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\m2m_100\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\mluke\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\siglip\convert_siglip_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\speech_encoder_decoder\modeling_speech_encoder_decoder.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\splinter\tokenization_splinter.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\upernet\convert_swin_upernet_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\modular-transformers\modeling_dummy.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_ctc_adapter.py,R0915, too-many-statements,1,1, , , , , , , , 
scripts\fsmt\fsmt-make-super-tiny-model.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\modeling_outputs.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\bit\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\deta\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\ibert\modeling_ibert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\pegasus\modeling_flax_pegasus.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\speech_to_text\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\timesformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\whisper\english_normalizer.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\tokenization_utils_base.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\pytorch\translation\run_translation_no_trainer.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\image_processing_base.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\integrations\integration_utils.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\modeling_gguf_pytorch_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\modeling_tf_pytorch_utils.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\autoformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\bartpho\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\bridgetower\modeling_bridgetower.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\clip\modeling_flax_clip.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\mctct\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\vit_hybrid\convert_vit_hybrid_timm_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\gpt_neox\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\gptj\modeling_gptj.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\layoutlm\modeling_tf_layoutlm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mistral\modeling_mistral.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\mobilebert\tokenization_mobilebert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\mobilenet_v2\convert_original_tf_checkpoint_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\nougat\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\trocr\modeling_trocr.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\tvp\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\whisper\feature_extraction_whisper.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\xlm\modeling_tf_xlm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\trainer_utils.py,R0912, too-many-branches,2,1, , , , , , , , 
examples\flax\language-modeling\run_clm_flax.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\contrastive-image-text\run_clip.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\research_projects\jax-projects\model_parallel\run_clm_mp.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\data\processors\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\auto\auto_factory.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\bert_generation\modeling_bert_generation.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\blip\modeling_tf_blip_text.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\mega\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\distilbert\modeling_flax_distilbert.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\donut\feature_extraction_donut.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutlmv2\modeling_layoutlmv2.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\llava_next_video\convert_llava_next_video_weights_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\timesformer\convert_timesformer_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\univnet\modeling_univnet.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\wav2vec2_conformer\configuration_wav2vec2_conformer.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\xlm\modeling_xlm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\pipelines\__init__.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\pipelines\mask_generation.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_ctc.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\tensorflow\translation\run_translation.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\cvt\modeling_cvt.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\deprecated\retribert\tokenization_retribert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\funnel\modeling_tf_funnel.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\gemma\modular_gemma.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\groupvit\modeling_tf_groupvit.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\markuplm\modeling_markuplm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mask2former\image_processing_mask2former.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\paligemma\processing_paligemma.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\seggpt\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\vit_mae\modeling_tf_vit_mae.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\vit_msn\convert_msn_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\pipelines\automatic_speech_recognition.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
src\transformers\training_args.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\pytorch\language-modeling\run_plm.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\bert-loses-patience\pabee\modeling_pabee_bert.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\bertabs\utils_summarization.py,C0301, line-too-long,1,1, , , , , , , , 
examples\research_projects\jax-projects\hybrid_clip\run_hybrid_clip.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\lxmert\utils.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\feature_extraction_sequence_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\integrations\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\big_bird\modeling_big_bird.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\byt5\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\cvt\modeling_tf_cvt.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deberta\modeling_deberta.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\graphormer\modeling_graphormer.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\esm\convert_esm.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\gpt2\modeling_gpt2.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\gpt2\modeling_tf_gpt2.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\hubert\modeling_tf_hubert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\instructblipvideo\convert_instructblipvideo_original_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\llama\convert_llama_weights_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\luke\convert_luke_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\phi3\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\qwen2_moe\modeling_qwen2_moe.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\yolos\modeling_yolos.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\pytorch\multiple-choice\run_swag.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\translation\run_translation.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\jax-projects\model_parallel\partitions.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\albert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\auto\tokenization_auto.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\bert\convert_bert_token_dropping_original_tf2_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deformable_detr\feature_extraction_deformable_detr.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\dit\convert_dit_unilm_to_pytorch.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\falcon_mamba\modeling_falcon_mamba.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\fastspeech2_conformer\configuration_fastspeech2_conformer.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\gpt_neo\modeling_gpt_neo.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\gptj\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\llava_onevision\modeling_llava_onevision.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\mbart50\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\musicgen_melody\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\omdet_turbo\modeling_omdet_turbo.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\openai\tokenization_openai.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\paligemma\convert_paligemma_weights_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\pegasus\modeling_tf_pegasus.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_roberta_prelayernorm.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\roformer\modeling_flax_roformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\rwkv\modeling_rwkv.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\models\unispeech_sat\configuration_unispeech_sat.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\xlm_roberta\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\processing_utils.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
utils\notification_service_quantization.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
examples\research_projects\jax-projects\wav2vec2\run_wav2vec2_pretrain_flax.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\seq2seq-distillation\make_student.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\vqgan-clip\VQGAN_CLIP.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\blenderbot\modeling_blenderbot.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\idefics2\convert_idefics2_weights_to_hf.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mobilevitv2\convert_mlcvnets_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\phi\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\swinv2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\vit\convert_vit_timm_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\utils\sentencepiece_model_pb2.py,C0302, too-many-lines,1,1, , , , , , , , 
utils\check_repo.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
examples\tensorflow\language-modeling\run_clm.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\dynamic_module_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\clip\modeling_clip.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deformable_detr\image_processing_deformable_detr.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\distilbert\modeling_distilbert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\flava\image_processing_flava.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
src\transformers\models\hiera\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\omdet_turbo\configuration_omdet_turbo.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\reformer\modeling_reformer.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\sam\modeling_sam.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\segformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
utils\check_copies.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\research_projects\bertabs\configuration_bertabs.py,C0301, line-too-long,1,1, , , , , , , , 
examples\research_projects\xtreme-s\run_xtreme_s.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\data\data_collator.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\generation\beam_search.py,C0325, superfluous-parens,2,1, , , , , , , , 
src\transformers\generation\tf_logits_process.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\bark\modeling_bark.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\deta\configuration_deta.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\grounding_dino\image_processing_grounding_dino.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\jetmoe\modeling_jetmoe.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\llava_next\modeling_llava_next.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\roformer\tokenization_roformer.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\rt_detr\image_processing_rt_detr.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\speech_to_text\modeling_speech_to_text.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\starcoder2\modeling_starcoder2.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\superpoint\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\switch_transformers\modeling_switch_transformers.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\udop\tokenization_udop.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\vit_mae\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\x_clip\modeling_x_clip.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\generation\beam_constraints.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\albert\modeling_albert.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\biogpt\modeling_biogpt.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\convbert\modeling_convbert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\xlm_prophetnet\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\gemma2\modeling_gemma2.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\groupvit\convert_groupvit_nvlab_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\lilt\modeling_lilt.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mgp_str\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\nemotron\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\sam\modeling_tf_sam.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\sew\convert_sew_original_pytorch_checkpoint_to_pytorch.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\table_transformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\unispeech\modeling_unispeech.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\whisper\modeling_flax_whisper.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\whisper\tokenization_whisper.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\utils\dummy_pt_objects.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\pytorch\question-answering\utils_qa.py,R0916, too-many-boolean-expressions,2,1, , , , , , , , 
examples\research_projects\bert-loses-patience\run_glue_with_pabee.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
src\transformers\__init__.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\blenderbot\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\bros\modeling_bros.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\canine\modeling_canine.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\codegen\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\longformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\markuplm\tokenization_markuplm_fast.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\mimi\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mpt\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\oneformer\configuration_oneformer.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\poolformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\segformer\modeling_tf_segformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\tapas\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\video_llava\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\vits\modeling_vits.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\yolos\convert_yolos_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\pytorch\image-pretraining\run_mim_no_trainer.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\robust-speech-event\run_speech_recognition_ctc_bnb.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\kernels\falcon_mamba\selective_scan_with_ln_interface.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\bart\modeling_flax_bart.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\tokenization_gptsan_japanese.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\electra\modeling_flax_electra.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\imagegpt\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\maskformer\feature_extraction_maskformer.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\reformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\rt_detr\modeling_rt_detr.py,W0718, broad-exception-caught,2,1, , , , , , , , 
src\transformers\onnx\__main__.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\pipelines\pt_utils.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\safetensors_conversion.py,W0718, broad-exception-caught,2,1, , , , , , , , 
utils\notification_service.py,R0912, too-many-branches,2,1, , , , , , , , 
examples\pytorch\audio-classification\run_audio_classification.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\bertology\run_bertology.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\seq2seq-distillation\sentence_splitter.py,C0301, line-too-long,2,1, , , , , , , , 
scripts\benchmark\trainer-benchmark.py,W0125,using-constant-test,1,1, , , , , , , , 
src\transformers\dependency_versions_check.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\integrations\bitsandbytes.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\beit\convert_beit_unilm_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\cpmant\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\data2vec\convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\distilbert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\ibert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\idefics2\image_processing_idefics2.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\lxmert\modeling_tf_lxmert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\owlv2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\qwen2_audio\modeling_qwen2_audio.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\qwen2_vl\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\seamless_m4t\configuration_seamless_m4t.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\swiftformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\swin2sr\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\xglm\convert_xglm_original_ckpt_to_trfms.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\zoedepth\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
examples\pytorch\semantic-segmentation\run_semantic_segmentation.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\mlm_wwm\run_mlm_wwm.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\audio_utils.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\modeling_utils.py,C0325, superfluous-parens,2,1, , , , , , , , 
src\transformers\models\audio_spectrogram_transformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\blip\modeling_blip_text.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\ernie_m\tokenization_ernie_m.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\deprecated\mega\convert_mega_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\instructblipvideo\modeling_instructblipvideo.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\jamba\modeling_jamba.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\llava_next_video\modeling_llava_next_video.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\swin\convert_swin_timm_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\yolos\feature_extraction_yolos.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\quantizers\quantizer_hqq.py,C0325, superfluous-parens,2,1, , , , , , , , 
src\transformers\utils\dummy_tf_objects.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\utils\fx.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\data\processors\utils.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\debug_utils.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\bark\convert_suno_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\beit\modeling_beit.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\clap\modeling_clap.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\clvp\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\deta\image_processing_deta.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\open_llama\modeling_open_llama.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\donut\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\dpt\configuration_dpt.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\longt5\modeling_flax_longt5.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\markuplm\tokenization_markuplm.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\maskformer\image_processing_maskformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\nougat\tokenization_nougat_fast.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\opt\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\roc_bert\modeling_roc_bert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\unispeech\convert_unispeech_original_pytorch_checkpoint_to_pytorch.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\vit_mae\convert_vit_mae_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\vitdet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\wav2vec2\modeling_wav2vec2.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\yoso\convert_yoso_pytorch_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
utils\check_docstrings.py,C0302, too-many-lines,1,1, , , , , , , , 
utils\update_tiny_models.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\modular-transformers\modeling_my_new_model2.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
examples\pytorch\text-classification\run_glue_no_trainer.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\token-classification\run_ner.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\mlm_wwm\run_chinese_ref.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\agents\python_interpreter.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\integrations\awq.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\cvt\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\convert_gptsan_tf_checkpoint_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\electra\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\falcon\modeling_falcon.py,R1719, simplifiable-if-expression,2,1, , , , , , , , 
src\transformers\models\informer\modeling_informer.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\kosmos2\modeling_kosmos2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mamba2\modeling_mamba2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\nystromformer\convert_nystromformer_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\qwen2_moe\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\recurrent_gemma\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\swin2sr\modeling_swin2sr.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\vilt\feature_extraction_vilt.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\utils\generic.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\distillation\run_squad_w_distillation.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
examples\research_projects\distillation\train.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\tapex\run_tabfact_with_tapex.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\wav2vec2\run_pretrain.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\tensorflow\image-classification\run_image_classification.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\feature_extraction_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\altclip\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_flax_blenderbot_small.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\cohere\modeling_cohere.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\conditional_detr\modeling_conditional_detr.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\dac\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\mmbt\configuration_mmbt.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\tvlt\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\electra\modeling_tf_electra.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\encodec\feature_extraction_encodec.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\esm\openfold_utils\rigid_utils.py,C0325, superfluous-parens,2,1, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3_fast.py,R1703, simplifiable-if-statement,1,1, , , , , , , , 
src\transformers\models\mllama\modeling_mllama.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mvp\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\regnet\convert_regnet_seer_10b_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\speech_encoder_decoder\convert_mbart_wav2vec2_seq2seq_original_to_pytorch.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\udop\tokenization_udop_fast.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\wav2vec2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\x_clip\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
examples\flax\speech-recognition\run_flax_speech_recognition_seq2seq.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\legacy\question-answering\run_squad.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
examples\legacy\run_transfo_xl.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\modular-transformers\modeling_super.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
examples\pytorch\semantic-segmentation\run_semantic_segmentation_no_trainer.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\visual_bert\modeling_frcnn.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\modeling_tf_utils.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\bark\generation_configuration_bark.py,W0107,unnecessary-pass,1,1, , , , , , , , 
src\transformers\models\blip_2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\clip\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\codegen\modeling_codegen.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deberta_v2\modeling_tf_deberta_v2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\realm\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\speech_to_text_2\modeling_speech_to_text_2.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_tf_transfo_xl_utilities.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\esm\openfold_utils\feats.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\fnet\modeling_fnet.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\gpt_bigcode\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutlm\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mbart\modeling_flax_mbart.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\mra\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\owlvit\processing_owlvit.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\pixtral\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\seamless_m4t_v2\configuration_seamless_m4t_v2.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\trainer.py,R1719, simplifiable-if-expression,2,1, , , , , , , , 
examples\pytorch\language-modeling\run_fim_no_trainer.py,R0915, too-many-statements,2,1, , , , , , , , 
examples\pytorch\text-classification\run_classification.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\tapex\run_wikitablequestions_with_tapex.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\bark\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\clip\feature_extraction_clip.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\ctrl\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\fastspeech2_conformer\convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\gpt_neox_japanese\tokenization_gpt_neox_japanese.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\granite\modeling_granite.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\marian\modeling_flax_marian.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\nemotron\convert_nemotron_nemo_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\opt\modeling_opt.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\plbart\modeling_plbart.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\pop2piano\modeling_pop2piano.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\pvt\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\roformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\seggpt\modeling_seggpt.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\switch_transformers\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\unispeech\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\pipelines\zero_shot_classification.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\utils\bitsandbytes.py,C0301, line-too-long,1,1, , , , , , , , 
examples\research_projects\distillation\grouped_batch_sampler.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\clvp\number_normalizer.py,R0911, too-many-return-statements,1,1, , , , , , , , 
src\transformers\models\electra\modeling_electra.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\informer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutlmv3\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\led\modeling_tf_led.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\mobilevitv2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\oneformer\convert_to_hf_oneformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\pegasus\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\speecht5\number_normalizer.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\swin\modeling_swin.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\vits\convert_original_checkpoint.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\wav2vec2_bert\modeling_wav2vec2_bert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\quantizers\quantizer_compressed_tensors.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\utils\doc.py,R0912, too-many-branches,1,1, , , , , , , , 
utils\check_inits.py,R0912, too-many-branches,1,1, , , , , , , , 
benchmark\optimum_benchmark_wrapper.py,C0301, line-too-long,2,1, , , , , , , , 
examples\flax\language-modeling\run_mlm_flax.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\language-modeling\run_fim.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\question-answering\run_qa_beam_search_no_trainer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\data\processors\squad.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\blip\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\efficientformer\convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\nezha\modeling_nezha.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\glpn\feature_extraction_glpn.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\idefics\modeling_tf_idefics.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mbart\modeling_mbart.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\mixtral\modeling_mixtral.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\mobilevitv2\modeling_mobilevitv2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mvp\modeling_mvp.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\owlvit\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\patchtsmixer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\roberta\modeling_flax_roberta.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\segformer\convert_segformer_original_to_pytorch.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\unispeech_sat\convert_unispeech_sat_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\vivit\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\pipelines\text_classification.py,R0912, too-many-branches,1,1, , , , , , , , 
utils\modular_model_converter.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\flax\vision\run_image_classification.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\question-answering\run_seq2seq_qa.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\movement-pruning\bertarize.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\file_utils.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\bart\modeling_bart.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\blenderbot\modeling_tf_blenderbot.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\blip\modeling_tf_blip.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\bridgetower\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\chameleon\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deberta\modeling_tf_deberta.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\jukebox\convert_jukebox.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\nezha\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\tvlt\modeling_tvlt.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\vit_hybrid\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\instructblip\modeling_instructblip.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\lxmert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\nllb_moe\convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py,R1726, simplifiable-condition,2,1, , , , , , , , 
src\transformers\models\olmo\convert_olmo_weights_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\segformer\feature_extraction_segformer.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\xglm\modeling_xglm.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\quantizers\quantizer_bnb_4bit.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\utils\sentencepiece_model_pb2_new.py,C0301, line-too-long,1,1, , , , , , , , 
utils\check_config_attributes.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\commands\add_new_model_like.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\keras_callbacks.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\bigbird_pegasus\convert_bigbird_pegasus_tf_to_pytorch.py,R1719, simplifiable-if-expression,2,1, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_audio.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\flaubert\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\llava\modeling_llava.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\lxmert\tokenization_lxmert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\megatron_bert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\nougat\convert_nougat_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\roformer\modeling_roformer.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\sew\modeling_sew.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\swin\modeling_tf_swin.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\t5\modeling_t5.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\models\udop\convert_udop_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\video_llava\modeling_video_llava.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\vilt\convert_vilt_original_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\vision_encoder_decoder\modeling_tf_vision_encoder_decoder.py,R0912, too-many-branches,2,1, , , , , , , , 
utils\models_to_deprecate.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\pytorch\question-answering\run_qa_beam_search.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\agents\text_to_speech.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\configuration_utils.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\hf_argparser.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\auto\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\clap\convert_clap_original_pytorch_to_hf.py,R1726, simplifiable-condition,1,1, , , , , , , , 
src\transformers\models\cohere\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\dac\convert_dac_checkpoint.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\deit\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\bort\convert_bort_original_gluonnlp_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\gpt_neox\modeling_gpt_neox.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\groupvit\modeling_groupvit.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\herbert\tokenization_herbert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\idefics3\image_processing_idefics3.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\musicgen\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\patchtst\modeling_patchtst.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\prophetnet\modeling_prophetnet.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\vitmatte\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_flax_xlm_roberta.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\yolos\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
examples\research_projects\codeparrot\examples\train_complexity_predictor.py,C0301, line-too-long,2,1, , , , , , , , 
examples\research_projects\seq2seq-distillation\convert_pl_checkpoint_to_hf.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\agents\image_question_answering.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\modeling_flax_utils.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\bloom\convert_bloom_original_checkpoint_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\clap\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\ctrl\modeling_ctrl.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\deprecated\graphormer\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\dinov2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\encoder_decoder\modeling_tf_encoder_decoder.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\granitemoe\modeling_granitemoe.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\llava_next\convert_llava_next_weights_to_hf.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\mamba\modeling_mamba.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\owlvit\feature_extraction_owlvit.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\perceiver\modeling_perceiver.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\phi\modeling_phi.py,R0912, too-many-branches,2,1, , , , , , , , 
examples\research_projects\tapex\run_wikisql_with_tapex.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\data\metrics\__init__.py,R0911, too-many-return-statements,1,1, , , , , , , , 
src\transformers\models\camembert\modeling_tf_camembert.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\jukebox\modeling_jukebox.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\depth_anything\convert_depth_anything_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\fnet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\fsmt\convert_fsmt_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\idefics3\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\imagegpt\modeling_imagegpt.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\rembert\modeling_rembert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\roc_bert\tokenization_roc_bert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\speecht5\feature_extraction_speecht5.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\swin2sr\convert_swin2sr_original_to_pytorch.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\table_transformer\convert_table_transformer_to_hf_no_timm.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\trocr\convert_trocr_unilm_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\vilt\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\whisper\convert_openai_to_hf.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\models\xmod\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
utils\check_build.py,C0301, line-too-long,2,1, , , , , , , , 
utils\patch_helper.py,C0301, line-too-long,1,1, , , , , , , , 
examples\legacy\run_camembert.py,C0301, line-too-long,2,1, , , , , , , , 
examples\legacy\run_language_modeling.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\quantization-qdqbert\utils_qa.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\agents\monitoring.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\audio_spectrogram_transformer\convert_audio_spectrogram_transformer_original_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\conditional_detr\convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deberta_v2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\qdqbert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\flaubert\modeling_flaubert.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\focalnet\convert_focalnet_to_hf_format.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\mobilebert\modeling_mobilebert.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\mobilenet_v1\feature_extraction_mobilenet_v1.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mpt\modeling_mpt.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\rt_detr\configuration_rt_detr.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\swinv2\modeling_swinv2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\udop\modeling_udop.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\xmod\convert_xmod_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\utils\hp_naming.py,C0301, line-too-long,2,1, , , , , , , , 
utils\update_metadata.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\bertabs\modeling_bertabs.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\agents\evaluate_agent.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\data\datasets\language_modeling.py,R1702, too-many-nested-blocks,2,1, , , , , , , , 
src\transformers\models\albert\modeling_tf_albert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deformable_detr\convert_deformable_detr_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\nat\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\realm\modeling_realm.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\granite\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_tf_layoutlmv3.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\luke\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\maskformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\oneformer\modeling_oneformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\openai\convert_openai_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\patchtst\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\perceiver\convert_perceiver_haiku_to_pytorch.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\prophetnet\convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\sew_d\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\t5\modeling_tf_t5.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\visual_bert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
examples\pytorch\object-detection\run_object_detection.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\commands\convert.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\generation\logits_process.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\modelcard.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\camembert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\chinese_clip\configuration_chinese_clip.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\distilbert\modeling_tf_distilbert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\grounding_dino\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\hubert\modeling_hubert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mobilenet_v2\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\nystromformer\modeling_nystromformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\olmoe\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\xglm\modeling_tf_xglm.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\optimization.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\flax\summarization\run_summarization_flax.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\luke\luke_utils.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
examples\tensorflow\multiple-choice\run_swag.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\tensorflow\token-classification\run_ner.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\convert_slow_tokenizer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\generation\streamers.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\dpt\convert_dinov2_depth_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\gpt_neox_japanese\modeling_gpt_neox_japanese.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\idefics3\modeling_idefics3.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mobilenet_v2\modeling_mobilenet_v2.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\olmo\modeling_olmo.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\sew\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\upernet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\xlm_roberta_xl\convert_xlm_roberta_xl_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\text-classification\run_xnli.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\data\metrics\squad_metrics.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\auto\image_processing_auto.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\deprecated\jukebox\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\depth_anything\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\detr\convert_detr_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\grounding_dino\modeling_grounding_dino.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\llava_next_video\modular_llava_next_video.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\longt5\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\mask2former\modeling_mask2former.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\mobilevit\feature_extraction_mobilevit.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\opt\modeling_tf_opt.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\persimmon\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\pvt_v2\convert_pvt_v2_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\roberta\modeling_tf_roberta.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\videomae\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\tokenization_utils_fast.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\ctrl\modeling_tf_ctrl.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\efficientformer\modeling_tf_efficientformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\xlm_prophetnet\modeling_xlm_prophetnet.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\encodec\convert_encodec_checkpoint_to_pytorch.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\funnel\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutxlm\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\m2m_100\convert_m2m100_original_checkpoint_to_pytorch.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\maskformer\convert_maskformer_resnet_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\nllb_moe\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\qwen2_vl\modeling_qwen2_vl.py,R0915, too-many-statements,2,1, , , , , , , , 
examples\legacy\seq2seq\save_randomly_initialized_model.py,C0301, line-too-long,1,1, , , , , , , , 
examples\legacy\token-classification\utils_ner.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\quantization-qdqbert\run_quant_qa.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\rag\parse_dpr_relevance_data.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\generation\utils.py,R0911, too-many-return-statements,1,1, , , , , , , , 
src\transformers\image_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\blenderbot\modeling_flax_blenderbot.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\bridgetower\image_processing_bridgetower.py,W0104, pointless-statement,1,1, , , , , , , , 
src\transformers\models\chameleon\convert_chameleon_weights_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\chinese_clip\feature_extraction_chinese_clip.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\clip\tokenization_clip.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\data2vec\modeling_tf_data2vec_vision.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\dpt\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\encodec\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\esm\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\flava\modeling_flava.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\fuyu\modeling_fuyu.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\git\modeling_git.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\megatron_gpt2\checkpoint_reshaping_and_interoperability.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\rembert\modeling_tf_rembert.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\wavlm\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\xlm_roberta_xl\modeling_xlm_roberta_xl.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\legacy\seq2seq\convert_model_to_fp16.py,C0301, line-too-long,2,1, , , , , , , , 
examples\pytorch\image-pretraining\run_mae.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\pytorch\summarization\run_summarization.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\deebert\src\modeling_highway_roberta.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\vqgan-clip\loaders.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\agents\search.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\generation\tf_utils.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\big_bird\modeling_flax_big_bird.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\blenderbot_small\tokenization_blenderbot_small_fast.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\clip\configuration_clip.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\clipseg\configuration_clipseg.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\convbert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\dbrx\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\ernie_m\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\imagegpt\convert_imagegpt_original_tf2_to_pytorch.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\instructblip\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutlm\modeling_layoutlm.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\wav2vec2_with_lm\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\xlnet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\onnx\convert.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\pipelines\text_generation.py,R0912, too-many-branches,1,1, , , , , , , , 
benchmark\benchmark.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
src\transformers\models\auto\processing_auto.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\beit\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\bigbird_pegasus\modeling_bigbird_pegasus.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\blip\modeling_blip.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deit\modeling_tf_deit.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\instructblip\convert_instructblip_original_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\maskformer\convert_maskformer_swin_to_pytorch.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\owlv2\convert_owlv2_to_hf.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\prophetnet\tokenization_prophetnet.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
utils\check_self_hosted_runner.py,C0301, line-too-long,1,1, , , , , , , , 
examples\flax\question-answering\run_qa.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\image-classification\run_image_classification.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\language-modeling\run_mlm.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\codeparrot\scripts\preprocessing.py,R0911, too-many-return-statements,1,1, , , , , , , , 
examples\research_projects\pplm\run_pplm.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\benchmark\benchmark_utils.py,R0911, too-many-return-statements,1,1, , , , , , , , 
src\transformers\generation\flax_logits_process.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\integrations\peft.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\conditional_detr\configuration_conditional_detr.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\data2vec\convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\ernie\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\esm\modeling_tf_esm.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\fuyu\image_processing_fuyu.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\gpt2\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\grounding_dino\configuration_grounding_dino.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\marian\modeling_tf_marian.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\mistral\modeling_tf_mistral.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\speech_to_text\modeling_tf_speech_to_text.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\tapas\tokenization_tapas.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\xmod\modeling_xmod.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\movement-pruning\emmental\modules\masked_nn.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\modeling_attn_mask_utils.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\bert_japanese\tokenization_bert_japanese.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_tf_blenderbot_small.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\ernie\modeling_ernie.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\layoutlmv2\feature_extraction_layoutlmv2.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mimi\modeling_mimi.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\mixtral\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\seamless_m4t_v2\modeling_seamless_m4t_v2.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\speecht5\convert_speecht5_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\t5\convert_t5x_checkpoint_to_flax.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\utils\chat_template_utils.py,R0911, too-many-return-statements,1,1, , , , , , , , 
examples\pytorch\object-detection\run_object_detection_no_trainer.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\text-generation\run_generation.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\pytorch\token-classification\run_ner_no_trainer.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\movement-pruning\emmental\modeling_bert_masked.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\research_projects\pplm\run_pplm_discrim_train.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\tensorflow\text-classification\run_glue.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\albert\modeling_flax_albert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\bert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\bert\modeling_tf_bert.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\deberta_v2\modeling_deberta_v2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\deta\convert_deta_resnet_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\levit\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\mluke\tokenization_mluke.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\pix2struct\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\speecht5\configuration_speecht5.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\squeezebert\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\swin\convert_swin_simmim_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\unispeech_sat\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\xlm\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\xlnet\modeling_xlnet.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\multiple-choice\run_swag_no_trainer.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\jax-projects\big_bird\prepare_natural_questions.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\movement-pruning\emmental\configuration_bert_masked.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\autoformer\modeling_autoformer.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\clvp\modeling_clvp.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\deta\convert_deta_swin_to_pytorch.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\modeling_gptsan_japanese.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\gemma2\modular_gemma2.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\led\modeling_led.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mt5\modeling_mt5.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\roformer\modeling_tf_roformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\sam\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\time_series_transformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\wav2vec2\configuration_wav2vec2.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\wav2vec2\modeling_tf_wav2vec2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\auto\modeling_auto.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\clvp\convert_clvp_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\convbert\tokenization_convbert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_text.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deberta_v2\tokenization_deberta_v2.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\focalnet\modeling_focalnet.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\longt5\modeling_longt5.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\stablelm\modeling_stablelm.py,R0912, too-many-branches,2,1, , , , , , , , 
examples\pytorch\image-pretraining\run_mim.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\distillation\distiller.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\robust-speech-event\run_speech_recognition_ctc_streaming.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\tapex\wikisql_utils.py,C0301, line-too-long,1,1, , , , , , , , 
examples\research_projects\vqgan-clip\utils.py,C0301, line-too-long,2,1, , , , , , , , 
examples\tensorflow\question-answering\utils_qa.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\agents\speech_to_text.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\bert\modeling_flax_bert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\blenderbot_small\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mpnet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\nystromformer\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\persimmon\modeling_persimmon.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\rag\modeling_rag.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\rag\modeling_tf_rag.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\seamless_m4t\convert_fairseq2_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\trocr\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\vipllava\modeling_vipllava.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\vits\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\whisper\generation_whisper.py,R0911, too-many-return-statements,1,1, , , , , , , , 
utils\get_github_job_time.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\flax\image-captioning\run_image_captioning_flax.py,R0912, too-many-branches,2,1, , , , , , , , 
examples\research_projects\deebert\run_glue_deebert.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
examples\research_projects\deebert\src\modeling_highway_bert.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\convert_pytorch_checkpoint_to_tf2.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\bloom\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\convbert\modeling_tf_convbert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\convnext\convert_convnext_to_pytorch.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\deformable_detr\modeling_deformable_detr.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\dpr\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\efficientnet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\encoder_decoder\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\git\convert_git_to_pytorch.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\glpn\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\luke\modeling_luke.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\m2m_100\modeling_m2m_100.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\markuplm\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mask2former\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mluke\convert_mluke_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\openai\modeling_tf_openai.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\pegasus_x\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\zoedepth\modeling_zoedepth.py,C0302, too-many-lines,1,1, , , , , , , , 
utils\create_dummy_models.py,R0911, too-many-return-statements,1,1, , , , , , , , 
src\transformers\agents\document_question_answering.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\cache_utils.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\deta\modeling_deta.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\dpt\convert_dpt_hybrid_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\granitemoe\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutxlm\tokenization_layoutxlm_fast.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\megatron_bert\convert_megatron_bert_checkpoint.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\mra\modeling_mra.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\nllb\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\seamless_m4t\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\splinter\modeling_splinter.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\swinv2\convert_swinv2_timm_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\umt5\modeling_umt5.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\vit_msn\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\utils\backbone_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\utils\dummy_flax_objects.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\camembert\modeling_camembert.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\clipseg\convert_clipseg_original_pytorch_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deformable_detr\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_transfo_xl_utilities.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\detr\modeling_detr.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\fastspeech2_conformer\modeling_fastspeech2_conformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\herbert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\jetmoe\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\musicgen_melody\convert_musicgen_melody_transformers.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\olmo\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\paligemma\modeling_paligemma.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\seamless_m4t\modeling_seamless_m4t.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\vision_text_dual_encoder\modeling_tf_vision_text_dual_encoder.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\vit\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\wav2vec2_bert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\wav2vec2_conformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
examples\pytorch\text-classification\run_glue.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\bert-loses-patience\pabee\modeling_pabee_albert.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\mm-imdb\utils_mmimdb.py,C0301, line-too-long,2,1, , , , , , , , 
examples\tensorflow\text-classification\run_text_classification.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\bertweet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\dbrx\modeling_dbrx.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\deformable_detr\configuration_deformable_detr.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\deprecated\efficientformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\speech_to_text_2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\dinat\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\esm\openfold_utils\chunk_utils.py,C0325, superfluous-parens,1,1, , , , , , , , 
src\transformers\models\falcon\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\funnel\modeling_funnel.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\hiera\modeling_hiera.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\kosmos2\processing_kosmos2.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\owlv2\processing_owlv2.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\phi3\modeling_phi3.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\poolformer\feature_extraction_poolformer.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_flax_roberta_prelayernorm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\speech_to_text\convert_s2t_fairseq_to_tfms.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\vit_mae\modeling_vit_mae.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\whisper\modeling_whisper.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
examples\research_projects\wav2vec2\run_common_voice.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\align\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\biogpt\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\bit\convert_bit_to_pytorch.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\chinese_clip\modeling_chinese_clip.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\qdqbert\modeling_qdqbert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\dpt\convert_dpt_beit_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\gemma2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\groupvit\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\idefics3\processing_idefics3.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\mamba\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\megatron_gpt2\convert_megatron_gpt2_checkpoint.py,R0915, too-many-statements,2,1, , , , , , , , 
src\transformers\models\qwen2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\sam\image_processing_sam.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\table_transformer\configuration_table_transformer.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\table_transformer\convert_table_transformer_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_tf_xlm_roberta.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\yoso\modeling_yoso.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\flax\language-modeling\run_bart_dlm_flax.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\flax\text-classification\run_flax_glue.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\pytorch\image-classification\run_image_classification_no_trainer.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\performer\modeling_flax_performer_utils.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\wav2vec2\alignment.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\tensorflow\contrastive-image-text\run_clip.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\data\processors\xnli.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\modeling_flax_pytorch_utils.py,R0911, too-many-return-statements,1,1, , , , , , , , 
src\transformers\models\bert\convert_bert_original_tf2_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\blenderbot\convert_blenderbot_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\mmbt\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\distilbert\tokenization_distilbert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\esm\openfold_utils\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\glpn\convert_glpn_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\longformer\modeling_longformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\nllb_moe\modeling_nllb_moe.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\timm_backbone\modeling_timm_backbone.py,W0107,unnecessary-pass,1,1, , , , , , , , 
src\transformers\models\wav2vec2_conformer\convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\pipelines\base.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\pipelines\question_answering.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\trainer_pt_utils.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\pytorch\question-answering\run_qa_no_trainer.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\lxmert\modeling_frcnn.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\models\auto\configuration_auto.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\bert\modeling_bert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\open_llama\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\esm\modeling_esm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\fastspeech2_conformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\gpt_sw3\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\instructblipvideo\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\jamba\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutlmv2\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\layoutlmv3\feature_extraction_layoutlmv3.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\llava_onevision\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mllama\convert_mllama_weights_to_hf.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\pop2piano\tokenization_pop2piano.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\rembert\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\roberta\convert_roberta_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\swin\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\wavlm\modeling_wavlm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\xlnet\convert_xlnet_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\pipelines\table_question_answering.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_seq2seq.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\bert_generation\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\blenderbot_small\tokenization_blenderbot_small.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\bros\convert_bros_to_pytorch.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\data2vec\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\realm\tokenization_realm.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_transfo_xl.py,W0107,unnecessary-pass,1,1, , , , , , , , 
src\transformers\models\falcon_mamba\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\flava\feature_extraction_flava.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\roberta\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\roberta_prelayernorm\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\sew_d\modeling_sew_d.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\starcoder2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\t5\convert_t5x_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\pytorch\summarization\run_summarization_no_trainer.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\rag\finetune_rag.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\tensorflow\summarization\run_summarization.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\generation\configuration_utils.py,W0104, pointless-statement,1,1, , , , , , , , 
src\transformers\models\cpm\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\trajectory_transformer\modeling_trajectory_transformer.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\detr\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\focalnet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\fsmt\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\groupvit\configuration_groupvit.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\hubert\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\idefics2\modeling_idefics2.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\longformer\modeling_tf_longformer.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\luke\tokenization_luke.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_tf_roberta_prelayernorm.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\seamless_m4t_v2\convert_fairseq2_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\t5\modeling_flax_t5.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\time_series_transformer\modeling_time_series_transformer.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\timm_backbone\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\univnet\feature_extraction_univnet.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\videomae\feature_extraction_videomae.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\vilt\modeling_vilt.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\trainer_seq2seq.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\utils\import_utils.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\flax\language-modeling\run_t5_mlm_flax.py,C0302, too-many-lines,1,1, , , , , , , , 
examples\legacy\token-classification\run_ner.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\research_projects\jax-projects\big_bird\train.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\agents\agents.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\big_bird\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_vision.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\deprecated\speech_to_text_2\tokenization_speech_to_text_2.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\gemma\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\llava_next_video\processing_llava_next_video.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\mbart\modeling_tf_mbart.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mixtral\convert_mixtral_weights_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\mobilevit\modeling_mobilevit.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\pegasus_x\modeling_pegasus_x.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\tapas\modeling_tf_tapas.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\wav2vec2_conformer\modeling_wav2vec2_conformer.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\x_clip\configuration_x_clip.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\utils\quantization_config.py,C0325, superfluous-parens,1,1, , , , , , , , 
examples\research_projects\performer\modeling_flax_performer.py,W0125,using-constant-test,1,1, , , , , , , , 
src\transformers\models\bigbird_pegasus\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deprecated\ernie_m\modeling_ernie_m.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\deprecated\retribert\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\tvlt\feature_extraction_tvlt.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\esm\modeling_esmfold.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\llava_next_video\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mobilebert\modeling_tf_mobilebert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\mobilevit\modeling_tf_mobilevit.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\nemotron\modeling_nemotron.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\omdet_turbo\convert_omdet_turbo_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\openai\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\owlv2\modeling_owlv2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\poolformer\convert_poolformer_original_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\splinter\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\umt5\convert_umt5_checkpoint_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\videomae\convert_videomae_to_pytorch.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\models\wav2vec2_phoneme\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\yoso\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
examples\research_projects\token-healing\run_token_healing.py,C0301, line-too-long,1,1, , , , , , , , 
scripts\check_tokenizers.py,W0718, broad-exception-caught,1,1, , , , , , , , 
src\transformers\commands\env.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\convert_slow_tokenizers_checkpoints_to_fast.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\bert\tokenization_bert.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\conditional_detr\feature_extraction_conditional_detr.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deit\feature_extraction_deit.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\funnel\tokenization_funnel.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
src\transformers\models\git\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\gptj\modeling_tf_gptj.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\imagegpt\feature_extraction_imagegpt.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\marian\convert_marian_to_pytorch.py,C0325, superfluous-parens,2,1, , , , , , , , 
src\transformers\models\mobilevit\convert_mlcvnets_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\resnet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\siglip\modeling_siglip.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\xlnet\modeling_tf_xlnet.py,R0912, too-many-branches,2,1, , , , , , , , 
src\transformers\pipelines\document_question_answering.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\sagemaker\trainer_sm.py,C0301, line-too-long,1,1, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_squad.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\bart\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\conditional_detr\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\deprecated\trajectory_transformer\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\detr\configuration_detr.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\llama\modeling_llama.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\perceiver\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\squeezebert\modeling_squeezebert.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\tapas\modeling_tapas.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\wav2vec2\modeling_flax_wav2vec2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\wavlm\configuration_wavlm.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\pipelines\fill_mask.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\legacy\run_openai_gpt.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\layoutlmv3\run_funsd_cord.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\tensorflow\question-answering\run_qa.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\blip\convert_blip_original_pytorch_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\blip_2\modeling_blip_2.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\canine\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\conditional_detr\image_processing_conditional_detr.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\convnextv2\convert_convnextv2_to_pytorch.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\dinov2\convert_dinov2_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\donut\convert_donut_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\idefics2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2_fast.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
src\transformers\models\levit\feature_extraction_levit.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\lilt\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\mobilenet_v1\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\mra\convert_mra_pytorch_to_pytorch.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\pegasus\modeling_pegasus.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\perceiver\feature_extraction_perceiver.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\prophetnet\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\qwen2\modeling_qwen2.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\videomae\modeling_videomae.py,R0912, too-many-branches,1,1, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_xlm_roberta.py,R0915, too-many-statements,2,1, , , , , , , , 
examples\flax\token-classification\run_flax_ner.py,R0915, too-many-statements,1,1, , , , , , , , 
examples\legacy\run_swag.py,R0915, too-many-statements,2,1, , , , , , , , 
examples\legacy\seq2seq\sentence_splitter.py,C0301, line-too-long,2,1, , , , , , , , 
examples\pytorch\language-modeling\run_clm.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\luke\run_luke_ner_no_trainer.py,R0912, too-many-branches,1,1, , , , , , , , 
examples\research_projects\mm-imdb\run_mmimdb.py,R1702, too-many-nested-blocks,1,1, , , , , , , , 
examples\research_projects\rag-end2end-retriever\finetune_rag.py,R1703, simplifiable-if-statement,1,1, , , , , , , , 
src\transformers\models\align\convert_align_tf_to_hf.py,R0915, too-many-statements,1,1, , , , , , , , 
src\transformers\models\beit\feature_extraction_beit.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\deberta\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\flava\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\marian\convert_marian_tatoeba_to_pytorch.py,C0302, too-many-lines,1,1, , , , , , , , 
src\transformers\models\musicgen\modeling_musicgen.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
src\transformers\models\pvt_v2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
src\transformers\models\roc_bert\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
src\transformers\models\seamless_m4t_v2\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
utils\extract_warnings.py,W0718, broad-exception-caught,1,1, , , , , , , , 
examples\pytorch\question-answering\run_qa.py,C0301, line-too-long,75,0, , , , , , , , 
examples\pytorch\question-answering\run_qa.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\commands\train.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\convert_graph_to_onnx.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\deepspeed.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\align\configuration_align.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\code_llama\tokenization_code_llama_fast.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\dinov2\configuration_dinov2.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\dpt\modeling_dpt.py,C0301, line-too-long,87,0, , , , , , , , 
src\transformers\models\esm\openfold_utils\data_transforms.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\funnel\convert_funnel_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\gpt_neox\configuration_gpt_neox.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\idefics\modeling_idefics.py,C0301, line-too-long,159,0, , , , , , , , 
src\transformers\models\idefics\modeling_idefics.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\idefics\modeling_idefics.py,C0325, superfluous-parens,2,0, , , , , , , , 
src\transformers\models\idefics\modeling_idefics.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\idefics\modeling_idefics.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\lxmert\modeling_lxmert.py,C0301, line-too-long,93,0, , , , , , , , 
src\transformers\models\lxmert\modeling_lxmert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\lxmert\modeling_lxmert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mistral\convert_mistral_weights_to_hf.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\mpnet\modeling_mpnet.py,C0301, line-too-long,45,0, , , , , , , , 
src\transformers\models\pop2piano\feature_extraction_pop2piano.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\t5\configuration_t5.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\univnet\configuration_univnet.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\yolos\image_processing_yolos.py,C0301, line-too-long,131,0, , , , , , , , 
src\transformers\models\yolos\image_processing_yolos.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\yolos\image_processing_yolos.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\yolos\image_processing_yolos.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\flax\question-answering\utils_qa.py,C0301, line-too-long,51,0, , , , , , , , 
examples\flax\question-answering\utils_qa.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\flax\question-answering\utils_qa.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\modular-transformers\modeling_dummy_bert.py,C0301, line-too-long,89,0, , , , , , , , 
examples\modular-transformers\modeling_dummy_bert.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\modular-transformers\modeling_dummy_bert.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\modular-transformers\modeling_dummy_bert.py,R0915, too-many-statements,3,0, , , , , , , , 
examples\research_projects\rag\consolidate_rag_checkpoint.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_blenderbot_small.py,C0301, line-too-long,122,0, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_blenderbot_small.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_blenderbot_small.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\bridgetower\processing_bridgetower.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\chameleon\modeling_chameleon.py,C0301, line-too-long,127,0, , , , , , , , 
src\transformers\models\chameleon\modeling_chameleon.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\chameleon\modeling_chameleon.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\deprecated\mctct\modeling_mctct.py,C0301, line-too-long,46,0, , , , , , , , 
src\transformers\models\deprecated\mctct\modeling_mctct.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\deprecated\tvlt\configuration_tvlt.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\detr\image_processing_detr.py,C0301, line-too-long,197,0, , , , , , , , 
src\transformers\models\detr\image_processing_detr.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\detr\image_processing_detr.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\detr\image_processing_detr.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\electra\tokenization_electra.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\gpt_bigcode\modeling_gpt_bigcode.py,C0301, line-too-long,92,0, , , , , , , , 
src\transformers\models\gpt_bigcode\modeling_gpt_bigcode.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\gpt_bigcode\modeling_gpt_bigcode.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\gpt_bigcode\modeling_gpt_bigcode.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\gpt_bigcode\modeling_gpt_bigcode.py,W0104, pointless-statement,1,0, , , , , , , , 
src\transformers\models\led\configuration_led.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\mask2former\convert_mask2former_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,95,0, , , , , , , , 
src\transformers\models\megatron_bert\modeling_megatron_bert.py,C0301, line-too-long,140,0, , , , , , , , 
src\transformers\models\megatron_bert\modeling_megatron_bert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\megatron_bert\modeling_megatron_bert.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\mpnet\modeling_tf_mpnet.py,C0301, line-too-long,61,0, , , , , , , , 
src\transformers\models\musicgen\processing_musicgen.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\musicgen_melody\processing_musicgen_melody.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\olmoe\modeling_olmoe.py,C0301, line-too-long,102,0, , , , , , , , 
src\transformers\models\olmoe\modeling_olmoe.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\olmoe\modeling_olmoe.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\olmoe\modeling_olmoe.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\patchtsmixer\modeling_patchtsmixer.py,C0301, line-too-long,142,0, , , , , , , , 
src\transformers\models\patchtsmixer\modeling_patchtsmixer.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\patchtsmixer\modeling_patchtsmixer.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\plbart\configuration_plbart.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\pop2piano\configuration_pop2piano.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\rag\configuration_rag.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\rt_detr\convert_rt_detr_original_pytorch_checkpoint_to_hf.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\rt_detr\convert_rt_detr_original_pytorch_checkpoint_to_hf.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\rt_detr\convert_rt_detr_original_pytorch_checkpoint_to_hf.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\speech_encoder_decoder\convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\speech_to_text\configuration_speech_to_text.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\unispeech_sat\modeling_unispeech_sat.py,C0301, line-too-long,170,0, , , , , , , , 
src\transformers\models\unispeech_sat\modeling_unispeech_sat.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\unispeech_sat\modeling_unispeech_sat.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\unispeech_sat\modeling_unispeech_sat.py,R1719, simplifiable-if-expression,3,0, , , , , , , , 
src\transformers\models\whisper\modeling_tf_whisper.py,C0301, line-too-long,157,0, , , , , , , , 
src\transformers\models\whisper\modeling_tf_whisper.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\whisper\modeling_tf_whisper.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\xlm\tokenization_xlm.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\models\zoedepth\convert_zoedepth_to_hf.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\zoedepth\convert_zoedepth_to_hf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\training_args_tf.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\utils\hub.py,C0301, line-too-long,129,0, , , , , , , , 
src\transformers\utils\hub.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\utils\hub.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\utils\hub.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\utils\hub.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\utils\hub.py,W0718, broad-exception-caught,3,0, , , , , , , , 
examples\pytorch\speech-pretraining\run_wav2vec2_pretraining_no_trainer.py,C0301, line-too-long,55,0, , , , , , , , 
examples\pytorch\speech-pretraining\run_wav2vec2_pretraining_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\bertology\run_prune_gpt.py,C0301, line-too-long,31,0, , , , , , , , 
examples\research_projects\jax-projects\dataset-streaming\run_mlm_flax_stream.py,C0301, line-too-long,59,0, , , , , , , , 
examples\research_projects\longform-qa\eli5_app.py,C0301, line-too-long,23,0, , , , , , , , 
examples\research_projects\rag\callbacks_rag.py,C0301, line-too-long,6,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\distillation.py,C0301, line-too-long,14,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\distillation.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\tensorflow\language-modeling-tpu\run_mlm.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\generation\stopping_criteria.py,C0301, line-too-long,104,0, , , , , , , , 
src\transformers\models\auto\feature_extraction_auto.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\models\auto\modeling_flax_auto.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\clap\feature_extraction_clap.py,C0301, line-too-long,45,0, , , , , , , , 
src\transformers\models\clipseg\modeling_clipseg.py,C0301, line-too-long,108,0, , , , , , , , 
src\transformers\models\deberta\tokenization_deberta.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\models\decision_transformer\modeling_decision_transformer.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\decision_transformer\modeling_decision_transformer.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\decision_transformer\modeling_decision_transformer.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\dpt\convert_dpt_to_pytorch.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\dpt\convert_dpt_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\instructblipvideo\modular_instructblipvideo.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\models\maskformer\modeling_maskformer.py,C0301, line-too-long,201,0, , , , , , , , 
src\transformers\models\maskformer\modeling_maskformer.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\mimi\convert_mimi_checkpoint_to_pytorch.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\sew_d\convert_sew_d_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\sew_d\convert_sew_d_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\sew_d\convert_sew_d_original_pytorch_checkpoint_to_pytorch.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\squeezebert\tokenization_squeezebert.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\superpoint\convert_superpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\t5\convert_t5_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\x_clip\convert_x_clip_original_pytorch_to_hf.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\x_clip\convert_x_clip_original_pytorch_to_hf.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\pytorch\language-modeling\run_clm_no_trainer.py,C0301, line-too-long,56,0, , , , , , , , 
examples\pytorch\language-modeling\run_clm_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\kb_encode_utils.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\agents\tools.py,C0301, line-too-long,74,0, , , , , , , , 
src\transformers\models\altclip\modeling_altclip.py,C0301, line-too-long,131,0, , , , , , , , 
src\transformers\models\altclip\modeling_altclip.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\altclip\modeling_altclip.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\camembert\tokenization_camembert.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\deprecated\tapex\tokenization_tapex.py,C0301, line-too-long,71,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_tf_transfo_xl.py,C0301, line-too-long,74,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_tf_transfo_xl.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_tf_transfo_xl.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\flaubert\modeling_tf_flaubert.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\flaubert\modeling_tf_flaubert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\flaubert\modeling_tf_flaubert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\flava\configuration_flava.py,C0301, line-too-long,94,0, , , , , , , , 
src\transformers\models\flava\configuration_flava.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\gemma2\convert_gemma2_weights_to_hf.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\kosmos2\configuration_kosmos2.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_layoutlmv3.py,C0301, line-too-long,66,0, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_layoutlmv3.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_layoutlmv3.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_layoutlmv3.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mpnet\tokenization_mpnet.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\models\owlvit\modeling_owlvit.py,C0301, line-too-long,105,0, , , , , , , , 
src\transformers\models\pop2piano\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\siglip\processing_siglip.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\vision_text_dual_encoder\modeling_vision_text_dual_encoder.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\wav2vec2\tokenization_wav2vec2.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\pipelines\token_classification.py,C0301, line-too-long,53,0, , , , , , , , 
src\transformers\pipelines\token_classification.py,R0912, too-many-branches,1,0, , , , , , , , 
utils\check_dummies.py,C0301, line-too-long,15,0, , , , , , , , 
examples\legacy\run_chinese_ref.py,C0301, line-too-long,7,0, , , , , , , , 
examples\legacy\seq2seq\run_distributed_eval.py,C0301, line-too-long,13,0, , , , , , , , 
examples\legacy\seq2seq\xla_spawn.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\bert\tokenization_bert_tf.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\bert\tokenization_bert_tf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\bloom\modeling_bloom.py,C0301, line-too-long,104,0, , , , , , , , 
src\transformers\models\bloom\modeling_bloom.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\bloom\modeling_bloom.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\clip\modeling_tf_clip.py,C0301, line-too-long,49,0, , , , , , , , 
src\transformers\models\deprecated\graphormer\configuration_graphormer.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\donut\processing_donut.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\donut\processing_donut.py,R1702, too-many-nested-blocks,2,0, , , , , , , , 
src\transformers\models\gemma\modeling_gemma.py,C0301, line-too-long,105,0, , , , , , , , 
src\transformers\models\gemma\modeling_gemma.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\gemma\modeling_gemma.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\longt5\convert_longt5x_checkpoint_to_flax.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\models\longt5\convert_longt5x_checkpoint_to_flax.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\olmoe\convert_olmoe_weights_to_hf.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\openai\modeling_openai.py,C0301, line-too-long,56,0, , , , , , , , 
src\transformers\models\openai\modeling_openai.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\owlvit\convert_owlvit_original_flax_to_hf.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\sam\processing_sam.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\segformer\configuration_segformer.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\timesformer\modeling_timesformer.py,C0301, line-too-long,46,0, , , , , , , , 
src\transformers\models\visual_bert\convert_visual_bert_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\wav2vec2_bert\processing_wav2vec2_bert.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\xglm\tokenization_xglm.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\pipelines\video_classification.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\utils\logging.py,C0301, line-too-long,17,0, , , , , , , , 
examples\legacy\seq2seq\finetune_trainer.py,C0301, line-too-long,26,0, , , , , , , , 
examples\legacy\seq2seq\finetune_trainer.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\information-gain-filtration\run_clm_igf.py,C0301, line-too-long,18,0, , , , , , , , 
examples\research_projects\visual_bert\utils.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\visual_bert\utils.py,W0718, broad-exception-caught,2,0, , , , , , , , 
examples\research_projects\wav2vec2\run_asr.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\commands\user.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\generation\flax_utils.py,C0301, line-too-long,116,0, , , , , , , , 
src\transformers\generation\flax_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\generation\flax_utils.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\align\modeling_align.py,C0301, line-too-long,94,0, , , , , , , , 
src\transformers\models\align\modeling_align.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\align\modeling_align.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\align\modeling_align.py,R1719, simplifiable-if-expression,3,0, , , , , , , , 
src\transformers\models\ctrl\tokenization_ctrl.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\data2vec\convert_data2vec_text_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\deprecated\mega\modeling_mega.py,C0301, line-too-long,248,0, , , , , , , , 
src\transformers\models\deprecated\mega\modeling_mega.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\deprecated\mega\modeling_mega.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\deprecated\tvlt\image_processing_tvlt.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\m2m_100\configuration_m2m_100.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\oneformer\image_processing_oneformer.py,C0301, line-too-long,120,0, , , , , , , , 
src\transformers\models\oneformer\image_processing_oneformer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\pix2struct\image_processing_pix2struct.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\pix2struct\modeling_pix2struct.py,C0301, line-too-long,77,0, , , , , , , , 
src\transformers\models\pix2struct\modeling_pix2struct.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\pix2struct\modeling_pix2struct.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\pix2struct\modeling_pix2struct.py,W0107,unnecessary-pass,1,0, , , , , , , , 
src\transformers\models\pix2struct\modeling_pix2struct.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\poolformer\image_processing_poolformer.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\qwen2\tokenization_qwen2.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\roberta\modeling_roberta.py,C0301, line-too-long,130,0, , , , , , , , 
src\transformers\models\roberta\modeling_roberta.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\roberta\modeling_roberta.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\roberta\modeling_roberta.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\tvp\configuration_tvp.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\xlm\configuration_xlm.py,C0301, line-too-long,21,0, , , , , , , , 
examples\pytorch\instance-segmentation\run_instance_segmentation_no_trainer.py,C0301, line-too-long,47,0, , , , , , , , 
examples\pytorch\instance-segmentation\run_instance_segmentation_no_trainer.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\pytorch\language-modeling\run_mlm_no_trainer.py,C0301, line-too-long,64,0, , , , , , , , 
examples\pytorch\language-modeling\run_mlm_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\question-answering\trainer_qa.py,C0301, line-too-long,8,0, , , , , , , , 
examples\research_projects\self-training-text-classification\selftraining.py,C0301, line-too-long,25,0, , , , , , , , 
examples\research_projects\self-training-text-classification\selftraining.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\self-training-text-classification\selftraining.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
examples\tensorflow\language-modeling\run_mlm.py,C0301, line-too-long,72,0, , , , , , , , 
examples\tensorflow\language-modeling\run_mlm.py,R0912, too-many-branches,1,0, , , , , , , , 
hubconf.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\align\processing_align.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\audio_spectrogram_transformer\modeling_audio_spectrogram_transformer.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\cvt\convert_cvt_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\grounding_dino\convert_grounding_dino_to_hf.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\models\grounding_dino\convert_grounding_dino_to_hf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\hubert\convert_hubert_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\idefics2\processing_idefics2.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\idefics\processing_idefics.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\idefics\processing_idefics.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\idefics\processing_idefics.py,R1719, simplifiable-if-expression,2,0, , , , , , , , 
src\transformers\models\layoutxlm\tokenization_layoutxlm.py,C0301, line-too-long,85,0, , , , , , , , 
src\transformers\models\layoutxlm\tokenization_layoutxlm.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\layoutxlm\tokenization_layoutxlm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\levit\modeling_levit.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\models\marian\modeling_marian.py,C0301, line-too-long,143,0, , , , , , , , 
src\transformers\models\marian\modeling_marian.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\marian\modeling_marian.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\musicgen_melody\modeling_musicgen_melody.py,C0301, line-too-long,244,0, , , , , , , , 
src\transformers\models\musicgen_melody\modeling_musicgen_melody.py,R0912, too-many-branches,6,0, , , , , , , , 
src\transformers\models\musicgen_melody\modeling_musicgen_melody.py,R0915, too-many-statements,4,0, , , , , , , , 
src\transformers\models\musicgen_melody\modeling_musicgen_melody.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\mvp\tokenization_mvp_fast.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\rag\tokenization_rag.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\sew_d\configuration_sew_d.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\speecht5\modeling_speecht5.py,C0301, line-too-long,274,0, , , , , , , , 
src\transformers\models\speecht5\modeling_speecht5.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\speecht5\modeling_speecht5.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\swin\configuration_swin.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\table_transformer\modeling_table_transformer.py,C0301, line-too-long,207,0, , , , , , , , 
src\transformers\models\table_transformer\modeling_table_transformer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\time_series_transformer\configuration_time_series_transformer.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\visual_bert\modeling_visual_bert.py,C0301, line-too-long,90,0, , , , , , , , 
src\transformers\models\wav2vec2\convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\wav2vec2\convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\pipelines\image_classification.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\pipelines\text2text_generation.py,C0301, line-too-long,49,0, , , , , , , , 
src\transformers\tokenization_utils.py,C0301, line-too-long,61,0, , , , , , , , 
src\transformers\tokenization_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\tokenization_utils.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\tokenization_utils.py,R0916, too-many-boolean-expressions,1,0, , , , , , , , 
src\transformers\tokenization_utils.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
examples\legacy\seq2seq\download_wmt.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\agents\agent_types.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\data\processors\glue.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\altclip\configuration_altclip.py,C0301, line-too-long,56,0, , , , , , , , 
src\transformers\models\bart\modeling_tf_bart.py,C0301, line-too-long,107,0, , , , , , , , 
src\transformers\models\bart\modeling_tf_bart.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\bart\modeling_tf_bart.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\blip_2\convert_blip_2_original_to_pytorch.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\blip_2\convert_blip_2_original_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\byt5\convert_byt5_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\cohere\tokenization_cohere_fast.py,C0301, line-too-long,86,0, , , , , , , , 
src\transformers\models\dac\feature_extraction_dac.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\deprecated\mctct\feature_extraction_mctct.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\donut\modeling_donut_swin.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\models\fsmt\modeling_fsmt.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\models\fsmt\modeling_fsmt.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\fsmt\modeling_fsmt.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\gpt_neo\modeling_flax_gpt_neo.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\hiera\convert_hiera_to_hf.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\hiera\convert_hiera_to_hf.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\idefics3\convert_idefics3_weights_to_hf.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\imagegpt\configuration_imagegpt.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\layoutlm\tokenization_layoutlm.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\llava_next\configuration_llava_next.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\llava_onevision\convert_llava_onevision_weights_to_hf.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\llava_onevision\convert_llava_onevision_weights_to_hf.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\llava_onevision\processing_llava_onevision.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\owlv2\image_processing_owlv2.py,C0301, line-too-long,52,0, , , , , , , , 
src\transformers\models\siglip\convert_siglip_to_hf.py,C0301, line-too-long,64,0, , , , , , , , 
src\transformers\models\siglip\convert_siglip_to_hf.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\speech_encoder_decoder\modeling_speech_encoder_decoder.py,C0301, line-too-long,66,0, , , , , , , , 
src\transformers\models\splinter\tokenization_splinter.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\upernet\convert_swin_upernet_to_pytorch.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\video_llava\convert_video_llava_weights_to_hf.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\pipelines\depth_estimation.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\pipelines\feature_extraction.py,C0301, line-too-long,9,0, , , , , , , , 
examples\modular-transformers\modeling_dummy.py,C0301, line-too-long,103,0, , , , , , , , 
examples\modular-transformers\modeling_dummy.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\modular-transformers\modeling_dummy.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_ctc_adapter.py,C0301, line-too-long,53,0, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_ctc_adapter.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\adversarial\run_hans.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\modeling_outputs.py,C0301, line-too-long,524,0, , , , , , , , 
src\transformers\models\clap\configuration_clap.py,C0301, line-too-long,45,0, , , , , , , , 
src\transformers\models\deprecated\mega\configuration_mega.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\deprecated\trajectory_transformer\configuration_trajectory_transformer.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\fnet\tokenization_fnet_fast.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\glpn\modeling_glpn.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\models\ibert\modeling_ibert.py,C0301, line-too-long,73,0, , , , , , , , 
src\transformers\models\layoutlmv2\configuration_layoutlmv2.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\llama\tokenization_llama.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\models\lxmert\tokenization_lxmert_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\pegasus\modeling_flax_pegasus.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\models\pegasus\modeling_flax_pegasus.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\pvt_v2\configuration_pvt_v2.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\whisper\english_normalizer.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\whisper\english_normalizer.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\tokenization_utils_base.py,C0301, line-too-long,488,0, , , , , , , , 
src\transformers\tokenization_utils_base.py,R0912, too-many-branches,11,0, , , , , , , , 
src\transformers\tokenization_utils_base.py,R0915, too-many-statements,6,0, , , , , , , , 
src\transformers\tokenization_utils_base.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
src\transformers\tokenization_utils_base.py,W0107,unnecessary-pass,3,0, , , , , , , , 
examples\pytorch\translation\run_translation_no_trainer.py,C0301, line-too-long,64,0, , , , , , , , 
examples\pytorch\translation\run_translation_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\image_processing_base.py,C0301, line-too-long,63,0, , , , , , , , 
src\transformers\image_processing_base.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\integrations\integration_utils.py,C0301, line-too-long,144,0, , , , , , , , 
src\transformers\integrations\integration_utils.py,R0912, too-many-branches,5,0, , , , , , , , 
src\transformers\integrations\integration_utils.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\integrations\integration_utils.py,R1703, simplifiable-if-statement,1,0, , , , , , , , 
src\transformers\integrations\integration_utils.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\modeling_gguf_pytorch_utils.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\modeling_gguf_pytorch_utils.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\modeling_tf_pytorch_utils.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\modeling_tf_pytorch_utils.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\bridgetower\modeling_bridgetower.py,C0301, line-too-long,154,0, , , , , , , , 
src\transformers\models\bridgetower\modeling_bridgetower.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\bridgetower\modeling_bridgetower.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\clip\modeling_flax_clip.py,C0301, line-too-long,65,0, , , , , , , , 
src\transformers\models\deprecated\vit_hybrid\convert_vit_hybrid_timm_to_pytorch.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\deprecated\xlm_prophetnet\configuration_xlm_prophetnet.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\distilbert\tokenization_distilbert_fast.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\donut\configuration_donut_swin.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\esm\openfold_utils\tensor_utils.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\falcon\configuration_falcon.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\flava\convert_flava_original_pytorch_to_hf.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\gptj\modeling_gptj.py,C0301, line-too-long,85,0, , , , , , , , 
src\transformers\models\gptj\modeling_gptj.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\gptj\modeling_gptj.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\idefics\image_processing_idefics.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\layoutlm\modeling_tf_layoutlm.py,C0301, line-too-long,74,0, , , , , , , , 
src\transformers\models\lxmert\configuration_lxmert.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\mistral\modeling_mistral.py,C0301, line-too-long,106,0, , , , , , , , 
src\transformers\models\mistral\modeling_mistral.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\mistral\modeling_mistral.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\mistral\modeling_mistral.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mllama\processing_mllama.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\mobilebert\tokenization_mobilebert.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\mobilenet_v2\convert_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\speech_encoder_decoder\modeling_flax_speech_encoder_decoder.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\models\trocr\modeling_trocr.py,C0301, line-too-long,97,0, , , , , , , , 
src\transformers\models\trocr\modeling_trocr.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\trocr\modeling_trocr.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\whisper\feature_extraction_whisper.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\xlm\modeling_tf_xlm.py,C0301, line-too-long,63,0, , , , , , , , 
src\transformers\models\xlm\modeling_tf_xlm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\xlm\modeling_tf_xlm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\xmod\configuration_xmod.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\trainer_utils.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\trainer_utils.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
examples\flax\language-modeling\run_clm_flax.py,C0301, line-too-long,62,0, , , , , , , , 
examples\flax\language-modeling\run_clm_flax.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\contrastive-image-text\run_clip.py,C0301, line-too-long,42,0, , , , , , , , 
examples\pytorch\contrastive-image-text\run_clip.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\contrastive-image-text\run_clip.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\jax-projects\model_parallel\run_clm_mp.py,C0301, line-too-long,49,0, , , , , , , , 
examples\research_projects\jax-projects\model_parallel\run_clm_mp.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\eval_rag.py,C0301, line-too-long,11,0, , , , , , , , 
examples\research_projects\self-training-text-classification\finetuning.py,C0301, line-too-long,47,0, , , , , , , , 
examples\research_projects\self-training-text-classification\finetuning.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\research_projects\self-training-text-classification\finetuning.py,R0915, too-many-statements,3,0, , , , , , , , 
examples\research_projects\self-training-text-classification\finetuning.py,R1702, too-many-nested-blocks,5,0, , , , , , , , 
src\transformers\models\auto\auto_factory.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\auto\auto_factory.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\bert_generation\modeling_bert_generation.py,C0301, line-too-long,89,0, , , , , , , , 
src\transformers\models\bert_generation\modeling_bert_generation.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\bert_generation\modeling_bert_generation.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\blip\modeling_tf_blip_text.py,C0301, line-too-long,78,0, , , , , , , , 
src\transformers\models\blip\modeling_tf_blip_text.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\configuration_gptsan_japanese.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\distilbert\modeling_flax_distilbert.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\funnel\tokenization_funnel_fast.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\granitemoe\configuration_granitemoe.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\layoutlmv2\image_processing_layoutlmv2.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\layoutlmv2\modeling_layoutlmv2.py,C0301, line-too-long,79,0, , , , , , , , 
src\transformers\models\layoutlmv2\modeling_layoutlmv2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\layoutlmv2\modeling_layoutlmv2.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\layoutlmv2\modeling_layoutlmv2.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\llava_next_video\convert_llava_next_video_weights_to_hf.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\mistral\configuration_mistral.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\patchtst\configuration_patchtst.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\persimmon\convert_persimmon_weights_to_hf.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\poolformer\modeling_poolformer.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\pvt\configuration_pvt.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\timesformer\convert_timesformer_to_pytorch.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\timesformer\convert_timesformer_to_pytorch.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\univnet\modeling_univnet.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\wav2vec2\feature_extraction_wav2vec2.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\wav2vec2_conformer\configuration_wav2vec2_conformer.py,C0301, line-too-long,60,0, , , , , , , , 
src\transformers\models\xlm\modeling_xlm.py,C0301, line-too-long,73,0, , , , , , , , 
src\transformers\models\xlm\modeling_xlm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\xlm\modeling_xlm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\pipelines\__init__.py,C0301, line-too-long,89,0, , , , , , , , 
src\transformers\pipelines\__init__.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\pipelines\__init__.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\pipelines\mask_generation.py,C0301, line-too-long,31,0, , , , , , , , 
utils\get_previous_daily_ci.py,C0301, line-too-long,4,0, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_ctc.py,C0301, line-too-long,56,0, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_ctc.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\tensorflow\translation\run_translation.py,C0301, line-too-long,68,0, , , , , , , , 
examples\tensorflow\translation\run_translation.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\agents\translation.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\bart\tokenization_bart.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\convnext\modeling_convnext.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\cvt\modeling_cvt.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\deberta\configuration_deberta.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\deprecated\retribert\tokenization_retribert.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\flava\convert_dalle_to_flava_codebook.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\funnel\modeling_tf_funnel.py,C0301, line-too-long,96,0, , , , , , , , 
src\transformers\models\gemma\modular_gemma.py,C0301, line-too-long,76,0, , , , , , , , 
src\transformers\models\gemma\modular_gemma.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\git\processing_git.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\groupvit\modeling_tf_groupvit.py,C0301, line-too-long,86,0, , , , , , , , 
src\transformers\models\groupvit\modeling_tf_groupvit.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\marian\configuration_marian.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\markuplm\modeling_markuplm.py,C0301, line-too-long,74,0, , , , , , , , 
src\transformers\models\markuplm\modeling_markuplm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\markuplm\modeling_markuplm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mask2former\image_processing_mask2former.py,C0301, line-too-long,115,0, , , , , , , , 
src\transformers\models\mask2former\image_processing_mask2former.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\nllb_moe\configuration_nllb_moe.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\paligemma\processing_paligemma.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\paligemma\processing_paligemma.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\swiftformer\modeling_tf_swiftformer.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\vilt\configuration_vilt.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\vit_mae\modeling_tf_vit_mae.py,C0301, line-too-long,74,0, , , , , , , , 
src\transformers\models\vit_msn\convert_msn_to_pytorch.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\pipelines\automatic_speech_recognition.py,C0301, line-too-long,88,0, , , , , , , , 
src\transformers\pipelines\automatic_speech_recognition.py,R0912, too-many-branches,5,0, , , , , , , , 
src\transformers\pipelines\automatic_speech_recognition.py,R0915, too-many-statements,4,0, , , , , , , , 
src\transformers\training_args.py,C0301, line-too-long,513,0, , , , , , , , 
src\transformers\training_args.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\training_args.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\training_args.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\training_args.py,W0104, pointless-statement,1,0, , , , , , , , 
examples\pytorch\language-modeling\run_plm.py,C0301, line-too-long,57,0, , , , , , , , 
examples\pytorch\language-modeling\run_plm.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\bert-loses-patience\pabee\modeling_pabee_bert.py,C0301, line-too-long,31,0, , , , , , , , 
examples\research_projects\bert-loses-patience\pabee\modeling_pabee_bert.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\jax-projects\hybrid_clip\run_hybrid_clip.py,C0301, line-too-long,28,0, , , , , , , , 
examples\research_projects\jax-projects\hybrid_clip\run_hybrid_clip.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\lxmert\extracting_data.py,C0301, line-too-long,6,0, , , , , , , , 
examples\research_projects\lxmert\extracting_data.py,W0718, broad-exception-caught,3,0, , , , , , , , 
examples\research_projects\lxmert\utils.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\lxmert\utils.py,W0718, broad-exception-caught,2,0, , , , , , , , 
src\transformers\feature_extraction_sequence_utils.py,C0301, line-too-long,45,0, , , , , , , , 
src\transformers\models\auto\modeling_tf_auto.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\bartpho\tokenization_bartpho.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\big_bird\modeling_big_bird.py,C0301, line-too-long,228,0, , , , , , , , 
src\transformers\models\big_bird\modeling_big_bird.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\big_bird\modeling_big_bird.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\bit\image_processing_bit.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\bloom\configuration_bloom.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\codegen\configuration_codegen.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\cvt\modeling_tf_cvt.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\deberta\modeling_deberta.py,C0301, line-too-long,67,0, , , , , , , , 
src\transformers\models\deberta\modeling_deberta.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\deprecated\graphormer\modeling_graphormer.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\deprecated\graphormer\modeling_graphormer.py,C0325, superfluous-parens,4,0, , , , , , , , 
src\transformers\models\deprecated\graphormer\modeling_graphormer.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\jukebox\configuration_jukebox.py,C0301, line-too-long,54,0, , , , , , , , 
src\transformers\models\dinov2\modeling_flax_dinov2.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\efficientnet\modeling_efficientnet.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\efficientnet\modeling_efficientnet.py,R1719, simplifiable-if-expression,3,0, , , , , , , , 
src\transformers\models\esm\convert_esm.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\esm\convert_esm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\esm\convert_esm.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\gpt2\modeling_flax_gpt2.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\gpt2\modeling_gpt2.py,C0301, line-too-long,127,0, , , , , , , , 
src\transformers\models\gpt2\modeling_gpt2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\gpt2\modeling_gpt2.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\gpt2\modeling_gpt2.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\gpt2\modeling_gpt2.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\gpt2\modeling_tf_gpt2.py,C0301, line-too-long,79,0, , , , , , , , 
src\transformers\models\gpt2\modeling_tf_gpt2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\gpt2\modeling_tf_gpt2.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\hubert\modeling_tf_hubert.py,C0301, line-too-long,75,0, , , , , , , , 
src\transformers\models\instructblipvideo\convert_instructblipvideo_original_to_pytorch.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\instructblipvideo\convert_instructblipvideo_original_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\llama\configuration_llama.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\llama\convert_llama_weights_to_hf.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\models\llama\convert_llama_weights_to_hf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\luke\convert_luke_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\luke\convert_luke_original_pytorch_checkpoint_to_pytorch.py,C0325, superfluous-parens,3,0, , , , , , , , 
src\transformers\models\qwen2_moe\modeling_qwen2_moe.py,C0301, line-too-long,140,0, , , , , , , , 
src\transformers\models\qwen2_moe\modeling_qwen2_moe.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\qwen2_moe\modeling_qwen2_moe.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\qwen2_moe\modeling_qwen2_moe.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\sew\configuration_sew.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\models\speech_to_text\feature_extraction_speech_to_text.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\squeezebert\tokenization_squeezebert_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\timm_backbone\configuration_timm_backbone.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\yolos\modeling_yolos.py,C0301, line-too-long,97,0, , , , , , , , 
examples\pytorch\multiple-choice\run_swag.py,C0301, line-too-long,43,0, , , , , , , , 
examples\pytorch\multiple-choice\run_swag.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\translation\run_translation.py,C0301, line-too-long,64,0, , , , , , , , 
examples\pytorch\translation\run_translation.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\audio_spectrogram_transformer\configuration_audio_spectrogram_transformer.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\auto\tokenization_auto.py,C0301, line-too-long,121,0, , , , , , , , 
src\transformers\models\auto\tokenization_auto.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\beit\image_processing_beit.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\models\bert\convert_bert_token_dropping_original_tf2_checkpoint_to_pytorch.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\chinese_clip\image_processing_chinese_clip.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\deprecated\realm\configuration_realm.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\dit\convert_dit_unilm_to_pytorch.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\falcon_mamba\modeling_falcon_mamba.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\models\falcon_mamba\modeling_falcon_mamba.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\fastspeech2_conformer\configuration_fastspeech2_conformer.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\glpn\configuration_glpn.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\gpt_neo\modeling_gpt_neo.py,C0301, line-too-long,74,0, , , , , , , , 
src\transformers\models\gpt_neo\modeling_gpt_neo.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\gpt_neo\modeling_gpt_neo.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\llama\tokenization_llama_fast.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\llava_onevision\modeling_llava_onevision.py,C0301, line-too-long,69,0, , , , , , , , 
src\transformers\models\llava_onevision\modeling_llava_onevision.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mask2former\configuration_mask2former.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\omdet_turbo\modeling_omdet_turbo.py,C0301, line-too-long,117,0, , , , , , , , 
src\transformers\models\omdet_turbo\modeling_omdet_turbo.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\omdet_turbo\modeling_omdet_turbo.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\omdet_turbo\modeling_omdet_turbo.py,W0718, broad-exception-caught,2,0, , , , , , , , 
src\transformers\models\openai\tokenization_openai.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\paligemma\convert_paligemma_weights_to_hf.py,C0301, line-too-long,54,0, , , , , , , , 
src\transformers\models\pegasus\modeling_tf_pegasus.py,C0301, line-too-long,109,0, , , , , , , , 
src\transformers\models\pegasus\modeling_tf_pegasus.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\pegasus\modeling_tf_pegasus.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\pop2piano\convert_pop2piano_weights_to_hf.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\qwen2_audio\configuration_qwen2_audio.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\rag\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\reformer\configuration_reformer.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\models\resnet\configuration_resnet.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_roberta_prelayernorm.py,C0301, line-too-long,131,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_roberta_prelayernorm.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_roberta_prelayernorm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\roformer\modeling_flax_roformer.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\rwkv\modeling_rwkv.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\rwkv\modeling_rwkv.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\unispeech_sat\configuration_unispeech_sat.py,C0301, line-too-long,53,0, , , , , , , , 
src\transformers\processing_utils.py,C0301, line-too-long,91,0, , , , , , , , 
src\transformers\processing_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\processing_utils.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\processing_utils.py,R0915, too-many-statements,1,0, , , , , , , , 
utils\deprecate_models.py,C0301, line-too-long,12,0, , , , , , , , 
utils\notification_service_quantization.py,C0301, line-too-long,10,0, , , , , , , , 
examples\research_projects\jax-projects\wav2vec2\run_wav2vec2_pretrain_flax.py,C0301, line-too-long,36,0, , , , , , , , 
examples\research_projects\jax-projects\wav2vec2\run_wav2vec2_pretrain_flax.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\make_student.py,C0301, line-too-long,20,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\make_student.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\visual_bert\processing_image.py,C0301, line-too-long,5,0, , , , , , , , 
examples\research_projects\vqgan-clip\VQGAN_CLIP.py,C0301, line-too-long,14,0, , , , , , , , 
examples\research_projects\vqgan-clip\VQGAN_CLIP.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\bart\convert_bart_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\blenderbot\modeling_blenderbot.py,C0301, line-too-long,132,0, , , , , , , , 
src\transformers\models\blenderbot\modeling_blenderbot.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\blenderbot\modeling_blenderbot.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\deberta_v2\configuration_deberta_v2.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\fastspeech2_conformer\convert_hifigan.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\llava\configuration_llava.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\maskformer\configuration_maskformer.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\mobilevitv2\convert_mlcvnets_to_pytorch.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\mobilevitv2\convert_mlcvnets_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\pegasus\tokenization_pegasus_fast.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\pvt\image_processing_pvt.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\models\qwen2_audio\processing_qwen2_audio.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\recurrent_gemma\configuration_recurrent_gemma.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\regnet\modeling_flax_regnet.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\vit\convert_vit_timm_to_pytorch.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\vit\convert_vit_timm_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\xlnet\tokenization_xlnet.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\utils\notebook.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\utils\sentencepiece_model_pb2.py,C0301, line-too-long,19,0, , , , , , , , 
utils\check_repo.py,C0301, line-too-long,60,0, , , , , , , , 
utils\check_repo.py,C0302, too-many-lines,1,0, , , , , , , , 
utils\check_repo.py,R0911, too-many-return-statements,1,0, , , , , , , , 
utils\check_repo.py,R0912, too-many-branches,1,0, , , , , , , , 
utils\check_repo.py,R1702, too-many-nested-blocks,3,0, , , , , , , , 
examples\research_projects\codeparrot\scripts\human_eval.py,C0301, line-too-long,12,0, , , , , , , , 
examples\tensorflow\language-modeling\run_clm.py,C0301, line-too-long,68,0, , , , , , , , 
examples\tensorflow\language-modeling\run_clm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\dynamic_module_utils.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\dynamic_module_utils.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\integrations\ggml.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\bart\tokenization_bart_fast.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\bloom\tokenization_bloom_fast.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\clip\modeling_clip.py,C0301, line-too-long,118,0, , , , , , , , 
src\transformers\models\deformable_detr\image_processing_deformable_detr.py,C0301, line-too-long,142,0, , , , , , , , 
src\transformers\models\deformable_detr\image_processing_deformable_detr.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\deformable_detr\image_processing_deformable_detr.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\deformable_detr\image_processing_deformable_detr.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\graphormer\collating_graphormer.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\deprecated\nat\modeling_nat.py,C0301, line-too-long,61,0, , , , , , , , 
src\transformers\models\distilbert\modeling_distilbert.py,C0301, line-too-long,101,0, , , , , , , , 
src\transformers\models\flava\image_processing_flava.py,C0301, line-too-long,92,0, , , , , , , , 
src\transformers\models\mbart50\tokenization_mbart50_fast.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\omdet_turbo\configuration_omdet_turbo.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\reformer\modeling_reformer.py,C0301, line-too-long,174,0, , , , , , , , 
src\transformers\models\reformer\modeling_reformer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\reformer\modeling_reformer.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\rwkv\convert_rwkv_checkpoint_to_hf.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\sam\modeling_sam.py,C0301, line-too-long,94,0, , , , , , , , 
src\transformers\models\sam\modeling_sam.py,C0325, superfluous-parens,2,0, , , , , , , , 
src\transformers\models\sam\modeling_sam.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\speecht5\tokenization_speecht5.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\timesformer\configuration_timesformer.py,C0301, line-too-long,9,0, , , , , , , , 
utils\check_copies.py,C0301, line-too-long,103,0, , , , , , , , 
utils\check_copies.py,R0912, too-many-branches,2,0, , , , , , , , 
utils\check_copies.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\xtreme-s\run_xtreme_s.py,C0301, line-too-long,52,0, , , , , , , , 
examples\research_projects\xtreme-s\run_xtreme_s.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\commands\download.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\data\data_collator.py,C0301, line-too-long,207,0, , , , , , , , 
src\transformers\data\data_collator.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\generation\beam_search.py,C0301, line-too-long,97,0, , , , , , , , 
src\transformers\generation\beam_search.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\generation\beam_search.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\generation\beam_search.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\generation\tf_logits_process.py,C0301, line-too-long,69,0, , , , , , , , 
src\transformers\generation\tf_logits_process.py,C0325, superfluous-parens,2,0, , , , , , , , 
src\transformers\modeling_flax_outputs.py,C0301, line-too-long,198,0, , , , , , , , 
src\transformers\models\bark\modeling_bark.py,C0301, line-too-long,114,0, , , , , , , , 
src\transformers\models\bark\modeling_bark.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\bark\modeling_bark.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\cohere\configuration_cohere.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\convnextv2\configuration_convnextv2.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\deprecated\deta\configuration_deta.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\gemma\tokenization_gemma.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\grounding_dino\image_processing_grounding_dino.py,C0301, line-too-long,137,0, , , , , , , , 
src\transformers\models\grounding_dino\image_processing_grounding_dino.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\grounding_dino\image_processing_grounding_dino.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\grounding_dino\image_processing_grounding_dino.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\jetmoe\modeling_jetmoe.py,C0301, line-too-long,122,0, , , , , , , , 
src\transformers\models\jetmoe\modeling_jetmoe.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\jetmoe\modeling_jetmoe.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\jetmoe\modeling_jetmoe.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\llava_next\modeling_llava_next.py,C0301, line-too-long,105,0, , , , , , , , 
src\transformers\models\llava_next\modeling_llava_next.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\nougat\processing_nougat.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\pvt\modeling_pvt.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\roformer\tokenization_roformer.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\rt_detr\image_processing_rt_detr.py,C0301, line-too-long,106,0, , , , , , , , 
src\transformers\models\rt_detr\image_processing_rt_detr.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\rt_detr\image_processing_rt_detr.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\seggpt\configuration_seggpt.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\speech_to_text\modeling_speech_to_text.py,C0301, line-too-long,96,0, , , , , , , , 
src\transformers\models\speech_to_text\modeling_speech_to_text.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\speech_to_text\modeling_speech_to_text.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\starcoder2\modeling_starcoder2.py,C0301, line-too-long,133,0, , , , , , , , 
src\transformers\models\starcoder2\modeling_starcoder2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\starcoder2\modeling_starcoder2.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\starcoder2\modeling_starcoder2.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\switch_transformers\modeling_switch_transformers.py,C0301, line-too-long,123,0, , , , , , , , 
src\transformers\models\switch_transformers\modeling_switch_transformers.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\switch_transformers\modeling_switch_transformers.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\tvp\modeling_tvp.py,C0301, line-too-long,53,0, , , , , , , , 
src\transformers\models\udop\tokenization_udop.py,C0301, line-too-long,110,0, , , , , , , , 
src\transformers\models\udop\tokenization_udop.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\udop\tokenization_udop.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\wav2vec2_bert\configuration_wav2vec2_bert.py,C0301, line-too-long,52,0, , , , , , , , 
src\transformers\models\x_clip\modeling_x_clip.py,C0301, line-too-long,97,0, , , , , , , , 
examples\legacy\seq2seq\seq2seq_training_args.py,C0301, line-too-long,7,0, , , , , , , , 
examples\research_projects\codeparrot\scripts\codeparrot_training.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\generation\beam_constraints.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\models\albert\modeling_albert.py,C0301, line-too-long,98,0, , , , , , , , 
src\transformers\models\albert\modeling_albert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\albert\modeling_albert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\bertweet\tokenization_bertweet.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\biogpt\modeling_biogpt.py,C0301, line-too-long,60,0, , , , , , , , 
src\transformers\models\biogpt\modeling_biogpt.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\biogpt\modeling_biogpt.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\biogpt\modeling_biogpt.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\convbert\modeling_convbert.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\convbert\modeling_convbert.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\deprecated\mctct\configuration_mctct.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\gemma2\configuration_gemma2.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\gemma2\modeling_gemma2.py,C0301, line-too-long,103,0, , , , , , , , 
src\transformers\models\gemma2\modeling_gemma2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\gemma2\modeling_gemma2.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\groupvit\convert_groupvit_nvlab_to_hf.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\lilt\modeling_lilt.py,C0301, line-too-long,77,0, , , , , , , , 
src\transformers\models\llama\modeling_flax_llama.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\models\mobilevit\image_processing_mobilevit.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\nystromformer\configuration_nystromformer.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\owlvit\configuration_owlvit.py,C0301, line-too-long,38,0, , , , , , , , 
src\transformers\models\regnet\configuration_regnet.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\sam\modeling_tf_sam.py,C0301, line-too-long,110,0, , , , , , , , 
src\transformers\models\sam\modeling_tf_sam.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\sam\modeling_tf_sam.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\sew\convert_sew_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\speech_to_text\processing_speech_to_text.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\trocr\configuration_trocr.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\udop\configuration_udop.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\unispeech\modeling_unispeech.py,C0301, line-too-long,150,0, , , , , , , , 
src\transformers\models\unispeech\modeling_unispeech.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\unispeech\modeling_unispeech.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\unispeech\modeling_unispeech.py,R1719, simplifiable-if-expression,3,0, , , , , , , , 
src\transformers\models\whisper\modeling_flax_whisper.py,C0301, line-too-long,80,0, , , , , , , , 
src\transformers\models\whisper\modeling_flax_whisper.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\whisper\tokenization_whisper.py,C0301, line-too-long,76,0, , , , , , , , 
src\transformers\models\whisper\tokenization_whisper.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\whisper\tokenization_whisper.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\whisper\tokenization_whisper.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\whisper\tokenization_whisper.py,R1702, too-many-nested-blocks,2,0, , , , , , , , 
src\transformers\quantizers\quantizer_aqlm.py,C0301, line-too-long,6,0, , , , , , , , 
utils\past_ci_versions.py,C0301, line-too-long,7,0, , , , , , , , 
examples\flax\image-captioning\create_model_from_encoder_decoder_models.py,C0301, line-too-long,4,0, , , , , , , , 
examples\pytorch\question-answering\utils_qa.py,C0301, line-too-long,51,0, , , , , , , , 
examples\pytorch\question-answering\utils_qa.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\pytorch\question-answering\utils_qa.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\research_projects\bert-loses-patience\run_glue_with_pabee.py,C0301, line-too-long,32,0, , , , , , , , 
examples\research_projects\bert-loses-patience\run_glue_with_pabee.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\research_projects\bert-loses-patience\run_glue_with_pabee.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\__init__.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\bros\modeling_bros.py,C0301, line-too-long,78,0, , , , , , , , 
src\transformers\models\bros\modeling_bros.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\bros\modeling_bros.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\canine\modeling_canine.py,C0301, line-too-long,105,0, , , , , , , , 
src\transformers\models\canine\modeling_canine.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\canine\modeling_canine.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\chameleon\processing_chameleon.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\deprecated\vit_hybrid\configuration_vit_hybrid.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\falcon\convert_custom_code_checkpoint.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\gemma\tokenization_gemma_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\gptj\modeling_flax_gptj.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3.py,C0301, line-too-long,127,0, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\llava_onevision\image_processing_llava_onevision.py,C0301, line-too-long,81,0, , , , , , , , 
src\transformers\models\longformer\tokenization_longformer.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\lxmert\convert_lxmert_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\markuplm\tokenization_markuplm_fast.py,C0301, line-too-long,81,0, , , , , , , , 
src\transformers\models\markuplm\tokenization_markuplm_fast.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\markuplm\tokenization_markuplm_fast.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
src\transformers\models\oneformer\configuration_oneformer.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\roberta\tokenization_roberta.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\segformer\modeling_tf_segformer.py,C0301, line-too-long,45,0, , , , , , , , 
src\transformers\models\squeezebert\configuration_squeezebert.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\vitdet\modeling_vitdet.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\vits\modeling_vits.py,C0301, line-too-long,90,0, , , , , , , , 
src\transformers\models\vits\modeling_vits.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\yolos\convert_yolos_to_pytorch.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\pipelines\visual_question_answering.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\pytorch_utils.py,C0301, line-too-long,22,0, , , , , , , , 
utils\check_tf_ops.py,C0301, line-too-long,7,0, , , , , , , , 
examples\pytorch\image-pretraining\run_mim_no_trainer.py,C0301, line-too-long,37,0, , , , , , , , 
examples\pytorch\image-pretraining\run_mim_no_trainer.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\decision_transformer\run_decision_transformer.py,C0301, line-too-long,6,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\callbacks_rag.py,C0301, line-too-long,6,0, , , , , , , , 
examples\research_projects\robust-speech-event\run_speech_recognition_ctc_bnb.py,C0301, line-too-long,51,0, , , , , , , , 
examples\research_projects\robust-speech-event\run_speech_recognition_ctc_bnb.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\callbacks.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\kernels\falcon_mamba\selective_scan_with_ln_interface.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\kernels\falcon_mamba\selective_scan_with_ln_interface.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\bart\modeling_flax_bart.py,C0301, line-too-long,86,0, , , , , , , , 
src\transformers\models\bart\modeling_flax_bart.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\blenderbot\tokenization_blenderbot_fast.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\convbert\convert_convbert_original_tf1_checkpoint_to_pytorch_and_tf2.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\tokenization_gptsan_japanese.py,C0301, line-too-long,38,0, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\tokenization_gptsan_japanese.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\electra\modeling_flax_electra.py,C0301, line-too-long,72,0, , , , , , , , 
src\transformers\models\electra\modeling_flax_electra.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\idefics3\configuration_idefics3.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\olmo\configuration_olmo.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\rt_detr\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\rt_detr\modeling_rt_detr.py,C0301, line-too-long,229,0, , , , , , , , 
src\transformers\models\rt_detr\modeling_rt_detr.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\rt_detr\modeling_rt_detr.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\rt_detr\modeling_rt_detr.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\upernet\convert_convnext_upernet_to_pytorch.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\vilt\image_processing_vilt.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\vision_encoder_decoder\configuration_vision_encoder_decoder.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\vision_text_dual_encoder\processing_vision_text_dual_encoder.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\vit\modeling_tf_vit.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\zoedepth\configuration_zoedepth.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\onnx\__main__.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\pipelines\pt_utils.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\safetensors_conversion.py,C0301, line-too-long,8,0, , , , , , , , 
utils\download_glue_data.py,C0301, line-too-long,17,0, , , , , , , , 
utils\notification_service.py,C0301, line-too-long,57,0, , , , , , , , 
utils\notification_service.py,C0302, too-many-lines,1,0, , , , , , , , 
utils\notification_service.py,R0915, too-many-statements,1,0, , , , , , , , 
utils\notification_service.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
utils\notification_service.py,W0718, broad-exception-caught,1,0, , , , , , , , 
examples\pytorch\audio-classification\run_audio_classification.py,C0301, line-too-long,33,0, , , , , , , , 
examples\pytorch\audio-classification\run_audio_classification.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\bertology\run_bertology.py,C0301, line-too-long,37,0, , , , , , , , 
examples\research_projects\information-gain-filtration\igf\igf.py,C0301, line-too-long,6,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\finetune.py,C0301, line-too-long,27,0, , , , , , , , 
scripts\benchmark\trainer-benchmark.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\integrations\bitsandbytes.py,C0301, line-too-long,63,0, , , , , , , , 
src\transformers\integrations\bitsandbytes.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\modeling_rope_utils.py,C0301, line-too-long,64,0, , , , , , , , 
src\transformers\models\altclip\processing_altclip.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\beit\configuration_beit.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\beit\convert_beit_unilm_to_pytorch.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\beit\convert_beit_unilm_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\camembert\configuration_camembert.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\clipseg\processing_clipseg.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\data2vec\configuration_data2vec_audio.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\models\data2vec\convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\deprecated\retribert\tokenization_retribert_fast.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\encodec\modeling_encodec.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\fsmt\configuration_fsmt.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\idefics2\image_processing_idefics2.py,C0301, line-too-long,52,0, , , , , , , , 
src\transformers\models\led\tokenization_led.py,C0301, line-too-long,46,0, , , , , , , , 
src\transformers\models\lxmert\modeling_tf_lxmert.py,C0301, line-too-long,81,0, , , , , , , , 
src\transformers\models\pop2piano\processing_pop2piano.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\qwen2_audio\modeling_qwen2_audio.py,C0301, line-too-long,131,0, , , , , , , , 
src\transformers\models\qwen2_audio\modeling_qwen2_audio.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\qwen2_audio\modeling_qwen2_audio.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\qwen2_audio\modeling_qwen2_audio.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\configuration_roberta_prelayernorm.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\sam\convert_sam_to_hf.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\seamless_m4t\configuration_seamless_m4t.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\models\swiftformer\configuration_swiftformer.py,C0301, line-too-long,5,0, , , , , , , , 
utils\get_modified_files.py,C0301, line-too-long,4,0, , , , , , , , 
examples\legacy\seq2seq\run_eval.py,C0301, line-too-long,17,0, , , , , , , , 
examples\pytorch\semantic-segmentation\run_semantic_segmentation.py,C0301, line-too-long,32,0, , , , , , , , 
examples\pytorch\semantic-segmentation\run_semantic_segmentation.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\mlm_wwm\run_mlm_wwm.py,C0301, line-too-long,43,0, , , , , , , , 
examples\research_projects\mlm_wwm\run_mlm_wwm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\audio_utils.py,C0301, line-too-long,133,0, , , , , , , , 
src\transformers\audio_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\audio_utils.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\modeling_utils.py,C0301, line-too-long,652,0, , , , , , , , 
src\transformers\modeling_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\modeling_utils.py,R0911, too-many-return-statements,2,0, , , , , , , , 
src\transformers\modeling_utils.py,R0912, too-many-branches,6,0, , , , , , , , 
src\transformers\modeling_utils.py,R0915, too-many-statements,4,0, , , , , , , , 
src\transformers\modeling_utils.py,R0916, too-many-boolean-expressions,2,0, , , , , , , , 
src\transformers\modeling_utils.py,R1702, too-many-nested-blocks,6,0, , , , , , , , 
src\transformers\modeling_utils.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\modeling_utils.py,W0107,unnecessary-pass,2,0, , , , , , , , 
src\transformers\modeling_utils.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\blip\modeling_blip_text.py,C0301, line-too-long,66,0, , , , , , , , 
src\transformers\models\blip\modeling_blip_text.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\ernie_m\tokenization_ernie_m.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\deprecated\mega\convert_mega_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\deprecated\mega\convert_mega_original_pytorch_checkpoint_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\deprecated\realm\retrieval_realm.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\dinov2\modeling_dinov2.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\falcon_mamba\configuration_falcon_mamba.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\flava\processing_flava.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\gemma\convert_gemma_weights_to_hf.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\grounding_dino\processing_grounding_dino.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\instructblipvideo\modeling_instructblipvideo.py,C0301, line-too-long,132,0, , , , , , , , 
src\transformers\models\jamba\modeling_jamba.py,C0301, line-too-long,155,0, , , , , , , , 
src\transformers\models\jamba\modeling_jamba.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\jamba\modeling_jamba.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\jamba\modeling_jamba.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\jamba\modeling_jamba.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\levit\convert_levit_timm_to_pytorch.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\llava_next_video\modeling_llava_next_video.py,C0301, line-too-long,119,0, , , , , , , , 
src\transformers\models\llava_next_video\modeling_llava_next_video.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\llava_next_video\modeling_llava_next_video.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\llava_onevision\video_processing_llava_onevision.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\mt5\modeling_flax_mt5.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\musicgen_melody\configuration_musicgen_melody.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\plbart\tokenization_plbart.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\qwen2_vl\processing_qwen2_vl.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\recurrent_gemma\convert_recurrent_gemma_to_hf.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\speecht5\convert_hifigan.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\swiftformer\modeling_swiftformer.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\swin\convert_swin_timm_to_pytorch.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\vitmatte\convert_vitmatte_to_hf.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\quantizers\auto.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\quantizers\quantizer_hqq.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\quantizers\quantizer_hqq.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\utils\fx.py,C0301, line-too-long,64,0, , , , , , , , 
src\transformers\utils\fx.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\utils\fx.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\utils\fx.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\utils\fx.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\benchmark\benchmark_args_tf.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\data\processors\utils.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\data\processors\utils.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\debug_utils.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\debug_utils.py,W0125,using-constant-test,3,0, , , , , , , , 
src\transformers\models\bark\convert_suno_to_hf.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\beit\modeling_beit.py,C0301, line-too-long,94,0, , , , , , , , 
src\transformers\models\blenderbot_small\configuration_blenderbot_small.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\clap\modeling_clap.py,C0301, line-too-long,160,0, , , , , , , , 
src\transformers\models\clap\modeling_clap.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\clap\modeling_clap.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\convnextv2\modeling_convnextv2.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\models\ctrl\configuration_ctrl.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\deprecated\deta\image_processing_deta.py,C0301, line-too-long,108,0, , , , , , , , 
src\transformers\models\deprecated\deta\image_processing_deta.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\deprecated\deta\image_processing_deta.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\open_llama\modeling_open_llama.py,C0301, line-too-long,67,0, , , , , , , , 
src\transformers\models\deprecated\open_llama\modeling_open_llama.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\dpt\configuration_dpt.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\gpt2\tokenization_gpt2_fast.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\longt5\modeling_flax_longt5.py,C0301, line-too-long,124,0, , , , , , , , 
src\transformers\models\longt5\modeling_flax_longt5.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\markuplm\tokenization_markuplm.py,C0301, line-too-long,113,0, , , , , , , , 
src\transformers\models\markuplm\tokenization_markuplm.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\markuplm\tokenization_markuplm.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\maskformer\image_processing_maskformer.py,C0301, line-too-long,111,0, , , , , , , , 
src\transformers\models\maskformer\image_processing_maskformer.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\mobilenet_v1\configuration_mobilenet_v1.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\nougat\tokenization_nougat_fast.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\nougat\tokenization_nougat_fast.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\opt\convert_opt_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\owlv2\configuration_owlv2.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\qwen2_moe\configuration_qwen2_moe.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\roc_bert\modeling_roc_bert.py,C0301, line-too-long,161,0, , , , , , , , 
src\transformers\models\roc_bert\modeling_roc_bert.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\roc_bert\modeling_roc_bert.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\unispeech\convert_unispeech_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\vipllava\convert_vipllava_weights_to_hf.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\vit_mae\convert_vit_mae_to_pytorch.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\vitdet\configuration_vitdet.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\wav2vec2\modeling_wav2vec2.py,C0301, line-too-long,200,0, , , , , , , , 
src\transformers\models\wav2vec2\modeling_wav2vec2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\wav2vec2\modeling_wav2vec2.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\wav2vec2\modeling_wav2vec2.py,R1719, simplifiable-if-expression,3,0, , , , , , , , 
src\transformers\models\wav2vec2\modeling_wav2vec2.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\yoso\convert_yoso_pytorch_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\onnx\config.py,C0301, line-too-long,67,0, , , , , , , , 
utils\check_docstrings.py,C0301, line-too-long,35,0, , , , , , , , 
utils\check_docstrings.py,R0911, too-many-return-statements,1,0, , , , , , , , 
utils\check_docstrings.py,R0912, too-many-branches,3,0, , , , , , , , 
utils\check_docstrings.py,R0915, too-many-statements,2,0, , , , , , , , 
utils\check_docstrings.py,W0718, broad-exception-caught,2,0, , , , , , , , 
utils\update_tiny_models.py,C0301, line-too-long,4,0, , , , , , , , 
utils\update_tiny_models.py,R0912, too-many-branches,1,0, , , , , , , , 
utils\update_tiny_models.py,W0718, broad-exception-caught,7,0, , , , , , , , 
examples\modular-transformers\modeling_my_new_model2.py,C0301, line-too-long,86,0, , , , , , , , 
examples\modular-transformers\modeling_my_new_model2.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\modular-transformers\modeling_my_new_model2.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\pytorch\text-classification\run_glue_no_trainer.py,C0301, line-too-long,51,0, , , , , , , , 
examples\pytorch\text-classification\run_glue_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\token-classification\run_ner.py,C0301, line-too-long,48,0, , , , , , , , 
examples\pytorch\token-classification\run_ner.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\mlm_wwm\run_chinese_ref.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\agents\python_interpreter.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\agents\python_interpreter.py,C0325, superfluous-parens,2,0, , , , , , , , 
src\transformers\agents\python_interpreter.py,R0911, too-many-return-statements,3,0, , , , , , , , 
src\transformers\agents\python_interpreter.py,R0912, too-many-branches,6,0, , , , , , , , 
src\transformers\agents\python_interpreter.py,W0107,unnecessary-pass,1,0, , , , , , , , 
src\transformers\agents\python_interpreter.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\integrations\awq.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\bridgetower\configuration_bridgetower.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\convert_gptsan_tf_checkpoint_to_pytorch.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\convert_gptsan_tf_checkpoint_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\convert_transfo_xl_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\deprecated\tvlt\processing_tvlt.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\falcon\modeling_falcon.py,C0301, line-too-long,151,0, , , , , , , , 
src\transformers\models\falcon\modeling_falcon.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\falcon\modeling_falcon.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\falcon\modeling_falcon.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\focalnet\configuration_focalnet.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\informer\modeling_informer.py,C0301, line-too-long,167,0, , , , , , , , 
src\transformers\models\informer\modeling_informer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\informer\modeling_informer.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\kosmos2\modeling_kosmos2.py,C0301, line-too-long,149,0, , , , , , , , 
src\transformers\models\kosmos2\modeling_kosmos2.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\kosmos2\modeling_kosmos2.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\mamba2\modeling_mamba2.py,C0301, line-too-long,89,0, , , , , , , , 
src\transformers\models\mamba2\modeling_mamba2.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mamba2\modeling_mamba2.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mobilevit\configuration_mobilevit.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\musicgen\configuration_musicgen.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\nystromformer\convert_nystromformer_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\reformer\tokenization_reformer_fast.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\roformer\configuration_roformer.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\swin2sr\modeling_swin2sr.py,C0301, line-too-long,69,0, , , , , , , , 
src\transformers\models\t5\tokenization_t5_fast.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\utils\deprecation.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\utils\generic.py,C0301, line-too-long,32,0, , , , , , , , 
examples\legacy\seq2seq\save_len_file.py,C0301, line-too-long,3,0, , , , , , , , 
examples\modular-transformers\configuration_my_new_model2.py,C0301, line-too-long,34,0, , , , , , , , 
examples\research_projects\distillation\run_squad_w_distillation.py,C0301, line-too-long,64,0, , , , , , , , 
examples\research_projects\distillation\run_squad_w_distillation.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\research_projects\distillation\run_squad_w_distillation.py,R0915, too-many-statements,3,0, , , , , , , , 
examples\research_projects\distillation\train.py,C0301, line-too-long,33,0, , , , , , , , 
examples\research_projects\distillation\train.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\tapex\run_tabfact_with_tapex.py,C0301, line-too-long,39,0, , , , , , , , 
examples\research_projects\tapex\run_tabfact_with_tapex.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\wav2vec2\run_pretrain.py,C0301, line-too-long,33,0, , , , , , , , 
examples\tensorflow\image-classification\run_image_classification.py,C0301, line-too-long,36,0, , , , , , , , 
examples\tensorflow\image-classification\run_image_classification.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\feature_extraction_utils.py,C0301, line-too-long,73,0, , , , , , , , 
src\transformers\feature_extraction_utils.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\hyperparameter_search.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\albert\configuration_albert.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\big_bird\tokenization_big_bird_fast.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_flax_blenderbot_small.py,C0301, line-too-long,66,0, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_flax_blenderbot_small.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\chinese_clip\processing_chinese_clip.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\cohere\modeling_cohere.py,C0301, line-too-long,108,0, , , , , , , , 
src\transformers\models\cohere\modeling_cohere.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\cohere\modeling_cohere.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\conditional_detr\modeling_conditional_detr.py,C0301, line-too-long,277,0, , , , , , , , 
src\transformers\models\conditional_detr\modeling_conditional_detr.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\conditional_detr\modeling_conditional_detr.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\depth_anything\configuration_depth_anything.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\electra\modeling_tf_electra.py,C0301, line-too-long,100,0, , , , , , , , 
src\transformers\models\electra\modeling_tf_electra.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\encodec\feature_extraction_encodec.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\esm\openfold_utils\rigid_utils.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\esm\openfold_utils\rigid_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3_fast.py,C0301, line-too-long,69,0, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3_fast.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3_fast.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\layoutlmv3\tokenization_layoutlmv3_fast.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
src\transformers\models\mllama\modeling_mllama.py,C0301, line-too-long,155,0, , , , , , , , 
src\transformers\models\mllama\modeling_mllama.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mllama\modeling_mllama.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mllama\modeling_mllama.py,R1719, simplifiable-if-expression,2,0, , , , , , , , 
src\transformers\models\persimmon\configuration_persimmon.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\regnet\convert_regnet_seer_10b_to_pytorch.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\speech_encoder_decoder\convert_mbart_wav2vec2_seq2seq_original_to_pytorch.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\udop\tokenization_udop_fast.py,C0301, line-too-long,70,0, , , , , , , , 
src\transformers\models\udop\tokenization_udop_fast.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\udop\tokenization_udop_fast.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\udop\tokenization_udop_fast.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
src\transformers\models\udop\tokenization_udop_fast.py,R1703, simplifiable-if-statement,1,0, , , , , , , , 
src\transformers\pipelines\image_to_text.py,C0301, line-too-long,17,0, , , , , , , , 
utils\check_table.py,C0301, line-too-long,13,0, , , , , , , , 
utils\custom_init_isort.py,C0301, line-too-long,22,0, , , , , , , , 
utils\sort_auto_mappings.py,C0301, line-too-long,6,0, , , , , , , , 
examples\flax\speech-recognition\run_flax_speech_recognition_seq2seq.py,C0301, line-too-long,66,0, , , , , , , , 
examples\flax\speech-recognition\run_flax_speech_recognition_seq2seq.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\legacy\question-answering\run_squad.py,C0301, line-too-long,70,0, , , , , , , , 
examples\legacy\question-answering\run_squad.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\legacy\question-answering\run_squad.py,R0915, too-many-statements,3,0, , , , , , , , 
examples\legacy\run_transfo_xl.py,C0301, line-too-long,15,0, , , , , , , , 
examples\modular-transformers\configuration_my_new_model.py,C0301, line-too-long,30,0, , , , , , , , 
examples\modular-transformers\modeling_super.py,C0301, line-too-long,94,0, , , , , , , , 
examples\pytorch\semantic-segmentation\run_semantic_segmentation_no_trainer.py,C0301, line-too-long,37,0, , , , , , , , 
examples\pytorch\semantic-segmentation\run_semantic_segmentation_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\bertabs\convert_bertabs_original_pytorch_checkpoint.py,C0301, line-too-long,5,0, , , , , , , , 
examples\research_projects\fsner\src\fsner\model.py,C0301, line-too-long,4,0, , , , , , , , 
examples\research_projects\visual_bert\modeling_frcnn.py,C0301, line-too-long,52,0, , , , , , , , 
examples\research_projects\visual_bert\modeling_frcnn.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\research_projects\visual_bert\modeling_frcnn.py,R0911, too-many-return-statements,1,0, , , , , , , , 
examples\research_projects\visual_bert\modeling_frcnn.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\visual_bert\modeling_frcnn.py,W0125,using-constant-test,1,0, , , , , , , , 
examples\research_projects\visual_bert\modeling_frcnn.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\commands\pt_to_tf.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\modeling_tf_utils.py,C0301, line-too-long,396,0, , , , , , , , 
src\transformers\modeling_tf_utils.py,R0912, too-many-branches,9,0, , , , , , , , 
src\transformers\modeling_tf_utils.py,R0915, too-many-statements,5,0, , , , , , , , 
src\transformers\modeling_tf_utils.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
src\transformers\modeling_tf_utils.py,W0107,unnecessary-pass,1,0, , , , , , , , 
src\transformers\modeling_tf_utils.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\bark\generation_configuration_bark.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\codegen\modeling_codegen.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\models\codegen\modeling_codegen.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deberta_v2\modeling_tf_deberta_v2.py,C0301, line-too-long,112,0, , , , , , , , 
src\transformers\models\deit\convert_deit_timm_to_pytorch.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\deit\modeling_deit.py,C0301, line-too-long,59,0, , , , , , , , 
src\transformers\models\deprecated\speech_to_text_2\modeling_speech_to_text_2.py,C0301, line-too-long,94,0, , , , , , , , 
src\transformers\models\deprecated\speech_to_text_2\modeling_speech_to_text_2.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_tf_transfo_xl_utilities.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\donut\image_processing_donut.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\fnet\modeling_fnet.py,C0301, line-too-long,72,0, , , , , , , , 
src\transformers\models\mbart\modeling_flax_mbart.py,C0301, line-too-long,70,0, , , , , , , , 
src\transformers\models\mbart\modeling_flax_mbart.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\owlvit\processing_owlvit.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\resnet\modeling_flax_resnet.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\seamless_m4t_v2\configuration_seamless_m4t_v2.py,C0301, line-too-long,56,0, , , , , , , , 
src\transformers\models\swin2sr\image_processing_swin2sr.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\swinv2\configuration_swinv2.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\unispeech\configuration_unispeech.py,C0301, line-too-long,49,0, , , , , , , , 
src\transformers\trainer.py,C0301, line-too-long,455,0, , , , , , , , 
src\transformers\trainer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\trainer.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\trainer.py,R0912, too-many-branches,18,0, , , , , , , , 
src\transformers\trainer.py,R0915, too-many-statements,9,0, , , , , , , , 
src\transformers\trainer.py,R0916, too-many-boolean-expressions,1,0, , , , , , , , 
src\transformers\trainer.py,R1702, too-many-nested-blocks,2,0, , , , , , , , 
src\transformers\trainer.py,W0104, pointless-statement,1,0, , , , , , , , 
src\transformers\trainer.py,W0718, broad-exception-caught,4,0, , , , , , , , 
utils\check_config_docstrings.py,C0301, line-too-long,6,0, , , , , , , , 
utils\get_ci_error_statistics.py,C0301, line-too-long,13,0, , , , , , , , 
utils\get_ci_error_statistics.py,W0718, broad-exception-caught,4,0, , , , , , , , 
examples\pytorch\language-modeling\run_fim_no_trainer.py,C0301, line-too-long,66,0, , , , , , , , 
examples\pytorch\language-modeling\run_fim_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\text-classification\run_classification.py,C0301, line-too-long,65,0, , , , , , , , 
examples\pytorch\text-classification\run_classification.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\distillation\scripts\binarized_data.py,C0301, line-too-long,5,0, , , , , , , , 
examples\research_projects\onnx\summarization\run_onnx_exporter.py,C0301, line-too-long,4,0, , , , , , , , 
examples\research_projects\performer\run_mlm_performer.py,C0301, line-too-long,52,0, , , , , , , , 
examples\research_projects\quantization-qdqbert\quant_trainer.py,C0301, line-too-long,19,0, , , , , , , , 
examples\research_projects\tapex\run_wikitablequestions_with_tapex.py,C0301, line-too-long,47,0, , , , , , , , 
examples\research_projects\tapex\run_wikitablequestions_with_tapex.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\integrations\fbgemm_fp8.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\autoformer\configuration_autoformer.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\convbert\tokenization_convbert_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\deprecated\nat\configuration_nat.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\deprecated\retribert\configuration_retribert.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\esm\tokenization_esm.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\fastspeech2_conformer\convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\git\configuration_git.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\gpt_neox_japanese\tokenization_gpt_neox_japanese.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\gpt_neox_japanese\tokenization_gpt_neox_japanese.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\granite\modeling_granite.py,C0301, line-too-long,95,0, , , , , , , , 
src\transformers\models\granite\modeling_granite.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\granite\modeling_granite.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\jetmoe\configuration_jetmoe.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\layoutlmv3\image_processing_layoutlmv3.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\marian\modeling_flax_marian.py,C0301, line-too-long,65,0, , , , , , , , 
src\transformers\models\marian\modeling_flax_marian.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mobilebert\tokenization_mobilebert_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\nemotron\convert_nemotron_nemo_to_hf.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\nemotron\convert_nemotron_nemo_to_hf.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\opt\modeling_opt.py,C0301, line-too-long,110,0, , , , , , , , 
src\transformers\models\opt\modeling_opt.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\opt\modeling_opt.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\patchtsmixer\configuration_patchtsmixer.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\plbart\modeling_plbart.py,C0301, line-too-long,135,0, , , , , , , , 
src\transformers\models\plbart\modeling_plbart.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\plbart\modeling_plbart.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\pop2piano\modeling_pop2piano.py,C0301, line-too-long,92,0, , , , , , , , 
src\transformers\models\pop2piano\modeling_pop2piano.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\pop2piano\modeling_pop2piano.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\pop2piano\modeling_pop2piano.py,W0107,unnecessary-pass,1,0, , , , , , , , 
src\transformers\models\pop2piano\modeling_pop2piano.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\roc_bert\configuration_roc_bert.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\seggpt\modeling_seggpt.py,C0301, line-too-long,80,0, , , , , , , , 
src\transformers\models\vision_encoder_decoder\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\pipelines\zero_shot_classification.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\pipelines\zero_shot_image_classification.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\quantizers\quantizer_gptq.py,C0301, line-too-long,6,0, , , , , , , , 
examples\legacy\pytorch-lightning\run_ner.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\use_own_knowledge_dataset.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\benchmark\benchmark_args.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\beit\modeling_flax_beit.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\chinese_clip\convert_chinese_clip_original_pytorch_to_hf.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\clvp\number_normalizer.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\electra\configuration_electra.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\electra\modeling_electra.py,C0301, line-too-long,110,0, , , , , , , , 
src\transformers\models\electra\modeling_electra.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\electra\modeling_electra.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\flaubert\tokenization_flaubert.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\models\hubert\configuration_hubert.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\models\led\modeling_tf_led.py,C0301, line-too-long,232,0, , , , , , , , 
src\transformers\models\led\modeling_tf_led.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\led\modeling_tf_led.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\mamba2\convert_mamba2_ssm_checkpoint_to_pytorch.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\musicgen\convert_musicgen_transformers.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\oneformer\convert_to_hf_oneformer.py,C0301, line-too-long,103,0, , , , , , , , 
src\transformers\models\phi\configuration_phi.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\pix2struct\configuration_pix2struct.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\regnet\convert_regnet_to_pytorch.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\speecht5\number_normalizer.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\swin\modeling_swin.py,C0301, line-too-long,105,0, , , , , , , , 
src\transformers\models\vits\convert_original_checkpoint.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\vits\convert_original_checkpoint.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\wav2vec2_bert\modeling_wav2vec2_bert.py,C0301, line-too-long,104,0, , , , , , , , 
src\transformers\models\wav2vec2_bert\modeling_wav2vec2_bert.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\optimization_tf.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\utils\doc.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\utils\doc.py,C0302, too-many-lines,1,0, , , , , , , , 
utils\check_inits.py,C0301, line-too-long,26,0, , , , , , , , 
utils\check_inits.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\flax\language-modeling\run_mlm_flax.py,C0301, line-too-long,75,0, , , , , , , , 
examples\flax\language-modeling\run_mlm_flax.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\language-modeling\run_fim.py,C0301, line-too-long,69,0, , , , , , , , 
examples\pytorch\language-modeling\run_fim.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\question-answering\run_qa_beam_search_no_trainer.py,C0301, line-too-long,115,0, , , , , , , , 
examples\pytorch\question-answering\run_qa_beam_search_no_trainer.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\pytorch\question-answering\run_qa_beam_search_no_trainer.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\research_projects\jax-projects\big_bird\evaluate.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\data\processors\squad.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\data\processors\squad.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\deprecated\efficientformer\convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\deprecated\efficientformer\convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\nezha\modeling_nezha.py,C0301, line-too-long,104,0, , , , , , , , 
src\transformers\models\deprecated\nezha\modeling_nezha.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\deprecated\nezha\modeling_nezha.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\deprecated\speech_to_text_2\configuration_speech_to_text_2.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\gptj\configuration_gptj.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\idefics2\configuration_idefics2.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\idefics\modeling_tf_idefics.py,C0301, line-too-long,130,0, , , , , , , , 
src\transformers\models\idefics\modeling_tf_idefics.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\idefics\modeling_tf_idefics.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\idefics\vision.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\layoutlmv2\processing_layoutlmv2.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\mbart\modeling_mbart.py,C0301, line-too-long,161,0, , , , , , , , 
src\transformers\models\mbart\modeling_mbart.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\mbart\modeling_mbart.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\mbart\modeling_mbart.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\mixtral\modeling_mixtral.py,C0301, line-too-long,135,0, , , , , , , , 
src\transformers\models\mixtral\modeling_mixtral.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\mixtral\modeling_mixtral.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\mixtral\modeling_mixtral.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\mobilevitv2\configuration_mobilevitv2.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\mobilevitv2\modeling_mobilevitv2.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\models\mvp\modeling_mvp.py,C0301, line-too-long,130,0, , , , , , , , 
src\transformers\models\mvp\modeling_mvp.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\mvp\modeling_mvp.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\mvp\modeling_mvp.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\olmoe\configuration_olmoe.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\openai\configuration_openai.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\pix2struct\processing_pix2struct.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\roberta\modeling_flax_roberta.py,C0301, line-too-long,56,0, , , , , , , , 
src\transformers\models\roberta\modeling_flax_roberta.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\segformer\convert_segformer_original_to_pytorch.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\segformer\convert_segformer_original_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\siglip\image_processing_siglip.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\unispeech_sat\convert_unispeech_sat_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\video_llava\image_processing_video_llava.py,C0301, line-too-long,38,0, , , , , , , , 
src\transformers\pipelines\text_classification.py,C0301, line-too-long,23,0, , , , , , , , 
utils\modular_model_converter.py,C0301, line-too-long,74,0, , , , , , , , 
utils\modular_model_converter.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
examples\flax\vision\run_image_classification.py,C0301, line-too-long,36,0, , , , , , , , 
examples\flax\vision\run_image_classification.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\legacy\benchmarking\plot_csv_file.py,C0301, line-too-long,14,0, , , , , , , , 
examples\modular-transformers\modular_my_new_model2.py,C0301, line-too-long,4,0, , , , , , , , 
examples\pytorch\question-answering\run_seq2seq_qa.py,C0301, line-too-long,80,0, , , , , , , , 
examples\pytorch\question-answering\run_seq2seq_qa.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\movement-pruning\bertarize.py,C0301, line-too-long,6,0, , , , , , , , 
examples\research_projects\movement-pruning\bertarize.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\data\datasets\squad.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\bart\modeling_bart.py,C0301, line-too-long,158,0, , , , , , , , 
src\transformers\models\bart\modeling_bart.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\bart\modeling_bart.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\bart\modeling_bart.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\bert_generation\tokenization_bert_generation.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\blenderbot\modeling_tf_blenderbot.py,C0301, line-too-long,112,0, , , , , , , , 
src\transformers\models\blenderbot\modeling_tf_blenderbot.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\blenderbot\modeling_tf_blenderbot.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\blip\modeling_tf_blip.py,C0301, line-too-long,101,0, , , , , , , , 
src\transformers\models\bros\processing_bros.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\cpm\tokenization_cpm.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\deberta\modeling_tf_deberta.py,C0301, line-too-long,70,0, , , , , , , , 
src\transformers\models\deprecated\efficientformer\image_processing_efficientformer.py,C0301, line-too-long,38,0, , , , , , , , 
src\transformers\models\deprecated\jukebox\convert_jukebox.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\deprecated\jukebox\convert_jukebox.py,R0911, too-many-return-statements,1,0, , , , , , , , 
src\transformers\models\deprecated\jukebox\convert_jukebox.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\deprecated\tvlt\modeling_tvlt.py,C0301, line-too-long,83,0, , , , , , , , 
src\transformers\models\instructblip\modeling_instructblip.py,C0301, line-too-long,122,0, , , , , , , , 
src\transformers\models\instructblipvideo\image_processing_instructblipvideo.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\mgp_str\tokenization_mgp_str.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\nllb_moe\convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\olmo\convert_olmo_weights_to_hf.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\rag\retrieval_rag.py,C0301, line-too-long,59,0, , , , , , , , 
src\transformers\models\seggpt\convert_seggpt_to_hf.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\switch_transformers\convert_big_switch.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\umt5\configuration_umt5.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\xglm\modeling_xglm.py,C0301, line-too-long,46,0, , , , , , , , 
src\transformers\models\xglm\modeling_xglm.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\quantizers\quantizer_bnb_4bit.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\training_args_seq2seq.py,C0301, line-too-long,12,0, , , , , , , , 
utils\check_config_attributes.py,C0301, line-too-long,20,0, , , , , , , , 
examples\research_projects\bertabs\run_summarization.py,C0301, line-too-long,5,0, , , , , , , , 
examples\research_projects\rag\lightning_base.py,C0301, line-too-long,20,0, , , , , , , , 
setup.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\commands\add_new_model_like.py,C0301, line-too-long,125,0, , , , , , , , 
src\transformers\commands\add_new_model_like.py,R0912, too-many-branches,5,0, , , , , , , , 
src\transformers\commands\add_new_model_like.py,R0915, too-many-statements,4,0, , , , , , , , 
src\transformers\commands\add_new_model_like.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\keras_callbacks.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\keras_callbacks.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\bert\tokenization_bert_fast.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\bigbird_pegasus\convert_bigbird_pegasus_tf_to_pytorch.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_audio.py,C0301, line-too-long,114,0, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_audio.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_audio.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_audio.py,R1719, simplifiable-if-expression,2,0, , , , , , , , 
src\transformers\models\gpt_neo\convert_gpt_neo_mesh_tf_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\gpt_sw3\convert_megatron_to_pytorch.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\hubert\convert_hubert_original_s3prl_checkpoint_to_pytorch.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\idefics\vision_tf.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\instructblipvideo\processing_instructblipvideo.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\kosmos2\convert_kosmos2_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\llava\modeling_llava.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\models\lxmert\tokenization_lxmert.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\nougat\convert_nougat_to_hf.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\nougat\convert_nougat_to_hf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\roformer\modeling_roformer.py,C0301, line-too-long,106,0, , , , , , , , 
src\transformers\models\roformer\modeling_roformer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\roformer\modeling_roformer.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\sew\modeling_sew.py,C0301, line-too-long,95,0, , , , , , , , 
src\transformers\models\sew\modeling_sew.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\sew\modeling_sew.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\sew\modeling_sew.py,R1719, simplifiable-if-expression,2,0, , , , , , , , 
src\transformers\models\swin\modeling_tf_swin.py,C0301, line-too-long,102,0, , , , , , , , 
src\transformers\models\t5\modeling_t5.py,C0301, line-too-long,110,0, , , , , , , , 
src\transformers\models\t5\modeling_t5.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\t5\modeling_t5.py,R0912, too-many-branches,6,0, , , , , , , , 
src\transformers\models\t5\modeling_t5.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\t5\modeling_t5.py,W0107,unnecessary-pass,1,0, , , , , , , , 
src\transformers\models\udop\convert_udop_to_hf.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\udop\convert_udop_to_hf.py,W0718, broad-exception-caught,2,0, , , , , , , , 
src\transformers\models\video_llava\modeling_video_llava.py,C0301, line-too-long,76,0, , , , , , , , 
src\transformers\models\video_llava\modeling_video_llava.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\vilt\convert_vilt_original_to_pytorch.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\vilt\convert_vilt_original_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\vision_encoder_decoder\modeling_tf_vision_encoder_decoder.py,C0301, line-too-long,80,0, , , , , , , , 
src\transformers\models\whisper\tokenization_whisper_fast.py,C0301, line-too-long,57,0, , , , , , , , 
src\transformers\models\xlm_roberta\configuration_xlm_roberta.py,C0301, line-too-long,20,0, , , , , , , , 
utils\models_to_deprecate.py,C0301, line-too-long,10,0, , , , , , , , 
utils\models_to_deprecate.py,R0912, too-many-branches,1,0, , , , , , , , 
utils\models_to_deprecate.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\legacy\token-classification\tasks.py,C0301, line-too-long,6,0, , , , , , , , 
examples\pytorch\question-answering\run_qa_beam_search.py,C0301, line-too-long,74,0, , , , , , , , 
examples\pytorch\question-answering\run_qa_beam_search.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\configuration_utils.py,C0301, line-too-long,144,0, , , , , , , , 
src\transformers\configuration_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\configuration_utils.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\hf_argparser.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\hf_argparser.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\bark\configuration_bark.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\clap\convert_clap_original_pytorch_to_hf.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\dac\convert_dac_checkpoint.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\deprecated\bort\convert_bort_original_gluonnlp_checkpoint_to_pytorch.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\deprecated\efficientformer\configuration_efficientformer.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\funnel\configuration_funnel.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\gpt_neox\modeling_gpt_neox.py,C0301, line-too-long,110,0, , , , , , , , 
src\transformers\models\gpt_neox\modeling_gpt_neox.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\gpt_neox\modeling_gpt_neox.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\gpt_neox\modeling_gpt_neox.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\granite\configuration_granite.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\groupvit\modeling_groupvit.py,C0301, line-too-long,96,0, , , , , , , , 
src\transformers\models\herbert\tokenization_herbert.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\idefics3\image_processing_idefics3.py,C0301, line-too-long,93,0, , , , , , , , 
src\transformers\models\idefics3\image_processing_idefics3.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mbart\configuration_mbart.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\models\nougat\image_processing_nougat.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\patchtst\modeling_patchtst.py,C0301, line-too-long,155,0, , , , , , , , 
src\transformers\models\patchtst\modeling_patchtst.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\patchtst\modeling_patchtst.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\pegasus_x\configuration_pegasus_x.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\prophetnet\modeling_prophetnet.py,C0301, line-too-long,235,0, , , , , , , , 
src\transformers\models\prophetnet\modeling_prophetnet.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\prophetnet\modeling_prophetnet.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\rembert\tokenization_rembert_fast.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\convert_roberta_prelayernorm_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\segformer\modeling_segformer.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\swin2sr\configuration_swin2sr.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\upernet\configuration_upernet.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\vision_text_dual_encoder\modeling_flax_vision_text_dual_encoder.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\wav2vec2_bert\convert_wav2vec2_seamless_checkpoint.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_flax_xlm_roberta.py,C0301, line-too-long,67,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_flax_xlm_roberta.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\convert_pl_checkpoint_to_hf.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\modeling_flax_utils.py,C0301, line-too-long,167,0, , , , , , , , 
src\transformers\modeling_flax_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\modeling_flax_utils.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\modeling_flax_utils.py,W0107,unnecessary-pass,1,0, , , , , , , , 
src\transformers\models\bloom\convert_bloom_original_checkpoint_to_pytorch.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\bloom\convert_bloom_original_checkpoint_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\bloom\convert_bloom_original_checkpoint_to_pytorch.py,R1702, too-many-nested-blocks,2,0, , , , , , , , 
src\transformers\models\ctrl\modeling_ctrl.py,C0301, line-too-long,38,0, , , , , , , , 
src\transformers\models\ctrl\modeling_ctrl.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\cvt\configuration_cvt.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\dinat\modeling_dinat.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\dpr\configuration_dpr.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\dpr\tokenization_dpr_fast.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\encoder_decoder\modeling_tf_encoder_decoder.py,C0301, line-too-long,76,0, , , , , , , , 
src\transformers\models\granitemoe\modeling_granitemoe.py,C0301, line-too-long,125,0, , , , , , , , 
src\transformers\models\granitemoe\modeling_granitemoe.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\granitemoe\modeling_granitemoe.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\ibert\configuration_ibert.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\llava_next\convert_llava_next_weights_to_hf.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\llava_next\convert_llava_next_weights_to_hf.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\llava_next\convert_llava_next_weights_to_hf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mamba\modeling_mamba.py,C0301, line-too-long,71,0, , , , , , , , 
src\transformers\models\mamba\modeling_mamba.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\nemotron\configuration_nemotron.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\nllb\tokenization_nllb.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\perceiver\modeling_perceiver.py,C0301, line-too-long,230,0, , , , , , , , 
src\transformers\models\perceiver\modeling_perceiver.py,R0912, too-many-branches,5,0, , , , , , , , 
src\transformers\models\phi3\configuration_phi3.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\phi\modeling_phi.py,C0301, line-too-long,130,0, , , , , , , , 
src\transformers\models\phi\modeling_phi.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\phi\modeling_phi.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\phi\modeling_phi.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\regnet\modeling_regnet.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\roberta\configuration_roberta.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\switch_transformers\convert_switch_transformers_original_flax_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\videomae\configuration_videomae.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\vit_msn\configuration_vit_msn.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\vit_msn\modeling_vit_msn.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\xlm_roberta\tokenization_xlm_roberta.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\xlm_roberta_xl\configuration_xlm_roberta_xl.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\xlnet\configuration_xlnet.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\quantizers\quantizer_torchao.py,C0301, line-too-long,12,0, , , , , , , , 
.circleci\create_circleci_config.py,C0301, line-too-long,30,0, , , , , , , , 
examples\legacy\multiple_choice\utils_multiple_choice.py,C0301, line-too-long,12,0, , , , , , , , 
examples\legacy\pytorch-lightning\lightning_base.py,C0301, line-too-long,18,0, , , , , , , , 
examples\modular-transformers\configuration_new_model.py,C0301, line-too-long,13,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\lightning_base.py,C0301, line-too-long,18,0, , , , , , , , 
examples\research_projects\tapex\run_wikisql_with_tapex.py,C0301, line-too-long,47,0, , , , , , , , 
examples\research_projects\tapex\run_wikisql_with_tapex.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\tensorflow\benchmarking\plot_csv_file.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\data\metrics\__init__.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\bros\configuration_bros.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\camembert\modeling_tf_camembert.py,C0301, line-too-long,118,0, , , , , , , , 
src\transformers\models\camembert\modeling_tf_camembert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\camembert\modeling_tf_camembert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\canine\configuration_canine.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\clip\processing_clip.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\deberta\tokenization_deberta_fast.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\deprecated\jukebox\modeling_jukebox.py,C0301, line-too-long,174,0, , , , , , , , 
src\transformers\models\deprecated\jukebox\modeling_jukebox.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\jukebox\modeling_jukebox.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\depth_anything\convert_depth_anything_to_hf.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\models\depth_anything\convert_depth_anything_to_hf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\fsmt\convert_fsmt_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\fuyu\configuration_fuyu.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\gpt_neox_japanese\configuration_gpt_neox_japanese.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\imagegpt\modeling_imagegpt.py,C0301, line-too-long,61,0, , , , , , , , 
src\transformers\models\imagegpt\modeling_imagegpt.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\imagegpt\modeling_imagegpt.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\imagegpt\modeling_imagegpt.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\informer\configuration_informer.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\llava\processing_llava.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\luke\configuration_luke.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\rembert\modeling_rembert.py,C0301, line-too-long,100,0, , , , , , , , 
src\transformers\models\rembert\modeling_rembert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\rembert\modeling_rembert.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\roc_bert\tokenization_roc_bert.py,C0301, line-too-long,75,0, , , , , , , , 
src\transformers\models\roc_bert\tokenization_roc_bert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\roc_bert\tokenization_roc_bert.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\speecht5\feature_extraction_speecht5.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\models\swin2sr\convert_swin2sr_original_to_pytorch.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\swin2sr\convert_swin2sr_original_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\swin2sr\convert_swin2sr_original_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\swin2sr\convert_swin2sr_original_to_pytorch.py,W0107,unnecessary-pass,1,0, , , , , , , , 
src\transformers\models\table_transformer\convert_table_transformer_to_hf_no_timm.py,C0301, line-too-long,65,0, , , , , , , , 
src\transformers\models\trocr\convert_trocr_unilm_to_pytorch.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\trocr\convert_trocr_unilm_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\udop\processing_udop.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\vipllava\configuration_vipllava.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\vision_encoder_decoder\modeling_flax_vision_encoder_decoder.py,C0301, line-too-long,73,0, , , , , , , , 
src\transformers\models\whisper\convert_openai_to_hf.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\x_clip\processing_x_clip.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\utils\versions.py,C0301, line-too-long,6,0, , , , , , , , 
utils\patch_helper.py,W0718, broad-exception-caught,1,0, , , , , , , , 
examples\legacy\run_language_modeling.py,C0301, line-too-long,27,0, , , , , , , , 
examples\legacy\run_language_modeling.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\jax-projects\hybrid_clip\modeling_hybrid_clip.py,C0301, line-too-long,45,0, , , , , , , , 
examples\research_projects\quantization-qdqbert\utils_qa.py,C0301, line-too-long,50,0, , , , , , , , 
examples\research_projects\quantization-qdqbert\utils_qa.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\research_projects\quantization-qdqbert\utils_qa.py,R0916, too-many-boolean-expressions,1,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\distributed_ray_retriever.py,C0301, line-too-long,10,0, , , , , , , , 
scripts\stale.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\audio_spectrogram_transformer\convert_audio_spectrogram_transformer_original_to_pytorch.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\audio_spectrogram_transformer\convert_audio_spectrogram_transformer_original_to_pytorch.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\chameleon\image_processing_chameleon.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\chinese_clip\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\conditional_detr\convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,57,0, , , , , , , , 
src\transformers\models\conditional_detr\convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\cpmant\configuration_cpmant.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\deit\configuration_deit.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\deprecated\retribert\modeling_retribert.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\dinat\configuration_dinat.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\encodec\configuration_encodec.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\flaubert\modeling_flaubert.py,C0301, line-too-long,79,0, , , , , , , , 
src\transformers\models\flaubert\modeling_flaubert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\flaubert\modeling_flaubert.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\focalnet\convert_focalnet_to_hf_format.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\focalnet\convert_focalnet_to_hf_format.py,R1719, simplifiable-if-expression,3,0, , , , , , , , 
src\transformers\models\fsmt\tokenization_fsmt.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\herbert\tokenization_herbert_fast.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\mobilebert\modeling_mobilebert.py,C0301, line-too-long,100,0, , , , , , , , 
src\transformers\models\mobilebert\modeling_mobilebert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\mobilebert\modeling_mobilebert.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mobilenet_v1\convert_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\mpt\modeling_mpt.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\models\mpt\modeling_mpt.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\rt_detr\configuration_rt_detr.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\rwkv\configuration_rwkv.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\swinv2\modeling_swinv2.py,C0301, line-too-long,118,0, , , , , , , , 
src\transformers\models\switch_transformers\configuration_switch_transformers.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\udop\modeling_udop.py,C0301, line-too-long,126,0, , , , , , , , 
src\transformers\models\udop\modeling_udop.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\udop\modeling_udop.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\vit\convert_dino_to_pytorch.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\wav2vec2_phoneme\tokenization_wav2vec2_phoneme.py,C0301, line-too-long,46,0, , , , , , , , 
src\transformers\models\wavlm\convert_wavlm_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\xmod\convert_xmod_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\xmod\convert_xmod_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
utils\update_metadata.py,C0301, line-too-long,29,0, , , , , , , , 
examples\research_projects\bertabs\modeling_bertabs.py,C0301, line-too-long,19,0, , , , , , , , 
examples\research_projects\bertabs\modeling_bertabs.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\research_projects\bertabs\modeling_bertabs.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\research_projects\bertabs\modeling_bertabs.py,R1719, simplifiable-if-expression,2,0, , , , , , , , 
examples\research_projects\fsner\src\fsner\tokenizer_utils.py,C0301, line-too-long,3,0, , , , , , , , 
examples\research_projects\jax-projects\big_bird\bigbird_flax.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\agents\evaluate_agent.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\agents\evaluate_agent.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\data\datasets\language_modeling.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\data\datasets\language_modeling.py,C0325, superfluous-parens,5,0, , , , , , , , 
src\transformers\data\datasets\language_modeling.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\data\datasets\language_modeling.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\albert\modeling_tf_albert.py,C0301, line-too-long,93,0, , , , , , , , 
src\transformers\models\clap\processing_clap.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\deformable_detr\convert_deformable_detr_to_pytorch.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\deformable_detr\convert_deformable_detr_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\nezha\configuration_nezha.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\deprecated\realm\modeling_realm.py,C0301, line-too-long,123,0, , , , , , , , 
src\transformers\models\deprecated\realm\modeling_realm.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\deprecated\realm\modeling_realm.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\esm\configuration_esm.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_tf_layoutlmv3.py,C0301, line-too-long,64,0, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_tf_layoutlmv3.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\layoutlmv3\modeling_tf_layoutlmv3.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\m2m_100\tokenization_m2m_100.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\mgp_str\modeling_mgp_str.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\oneformer\modeling_oneformer.py,C0301, line-too-long,211,0, , , , , , , , 
src\transformers\models\oneformer\modeling_oneformer.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\oneformer\modeling_oneformer.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\perceiver\convert_perceiver_haiku_to_pytorch.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\perceiver\convert_perceiver_haiku_to_pytorch.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\prophetnet\convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\prophetnet\convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\prophetnet\convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py,W0104, pointless-statement,2,0, , , , , , , , 
src\transformers\models\seamless_m4t\processing_seamless_m4t.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\superpoint\image_processing_superpoint.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\t5\modeling_tf_t5.py,C0301, line-too-long,78,0, , , , , , , , 
src\transformers\models\t5\modeling_tf_t5.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\t5\modeling_tf_t5.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\t5\modeling_tf_t5.py,W0104, pointless-statement,1,0, , , , , , , , 
src\transformers\models\t5\tokenization_t5.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\tapas\convert_tapas_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\vit\modeling_vit.py,C0301, line-too-long,46,0, , , , , , , , 
src\transformers\models\vitmatte\image_processing_vitmatte.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\vits\tokenization_vits.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\wavlm\convert_wavlm_original_s3prl_checkpoint_to_pytorch.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\xlm\convert_xlm_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\yoso\configuration_yoso.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\pipelines\audio_classification.py,C0301, line-too-long,22,0, , , , , , , , 
examples\pytorch\object-detection\run_object_detection.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\activations.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\commands\convert.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\commands\convert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\generation\logits_process.py,C0301, line-too-long,296,0, , , , , , , , 
src\transformers\generation\logits_process.py,C0325, superfluous-parens,4,0, , , , , , , , 
src\transformers\modelcard.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\modelcard.py,R0912, too-many-branches,5,0, , , , , , , , 
src\transformers\models\chinese_clip\configuration_chinese_clip.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\convbert\configuration_convbert.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\deprecated\speech_to_text_2\processing_speech_to_text_2.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\deprecated\van\modeling_van.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\distilbert\modeling_tf_distilbert.py,C0301, line-too-long,54,0, , , , , , , , 
src\transformers\models\fuyu\processing_fuyu.py,C0301, line-too-long,52,0, , , , , , , , 
src\transformers\models\gpt2\tokenization_gpt2.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\hubert\modeling_hubert.py,C0301, line-too-long,111,0, , , , , , , , 
src\transformers\models\hubert\modeling_hubert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\hubert\modeling_hubert.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\hubert\modeling_hubert.py,R1719, simplifiable-if-expression,3,0, , , , , , , , 
src\transformers\models\layoutlmv3\processing_layoutlmv3.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\llava_next_video\image_processing_llava_next_video.py,C0301, line-too-long,51,0, , , , , , , , 
src\transformers\models\mllama\image_processing_mllama.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\mobilebert\convert_mobilebert_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\mobilenet_v1\modeling_mobilenet_v1.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\nystromformer\modeling_nystromformer.py,C0301, line-too-long,63,0, , , , , , , , 
src\transformers\models\paligemma\configuration_paligemma.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\wav2vec2\convert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\xglm\modeling_tf_xglm.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\xglm\modeling_tf_xglm.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\xglm\modeling_tf_xglm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\optimization.py,C0301, line-too-long,61,0, , , , , , , , 
src\transformers\optimization.py,C0325, superfluous-parens,8,0, , , , , , , , 
src\transformers\optimization.py,R0911, too-many-return-statements,1,0, , , , , , , , 
src\transformers\optimization.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\flax\summarization\run_summarization_flax.py,C0301, line-too-long,79,0, , , , , , , , 
examples\flax\summarization\run_summarization_flax.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\flax\summarization\run_summarization_flax.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\pytorch\instance-segmentation\run_instance_segmentation.py,C0301, line-too-long,38,0, , , , , , , , 
examples\research_projects\luke\luke_utils.py,C0301, line-too-long,12,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\lightning_base.py,C0301, line-too-long,18,0, , , , , , , , 
examples\tensorflow\multiple-choice\run_swag.py,C0301, line-too-long,47,0, , , , , , , , 
examples\tensorflow\multiple-choice\run_swag.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\tensorflow\token-classification\run_ner.py,C0301, line-too-long,50,0, , , , , , , , 
examples\tensorflow\token-classification\run_ner.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\convert_slow_tokenizer.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\generation\streamers.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\barthez\tokenization_barthez_fast.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\bert_generation\configuration_bert_generation.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\biogpt\configuration_biogpt.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\blip\image_processing_blip.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\bloom\modeling_flax_bloom.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\clvp\feature_extraction_clvp.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\deprecated\realm\tokenization_realm_fast.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\detr\convert_detr_to_pytorch.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\models\dpt\convert_dinov2_depth_to_hf.py,C0301, line-too-long,45,0, , , , , , , , 
src\transformers\models\dpt\convert_dinov2_depth_to_hf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\encoder_decoder\configuration_encoder_decoder.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\esm\openfold_utils\residue_constants.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\gemma\modeling_flax_gemma.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\gpt_neox_japanese\modeling_gpt_neox_japanese.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\idefics3\modeling_idefics3.py,C0301, line-too-long,137,0, , , , , , , , 
src\transformers\models\idefics3\modeling_idefics3.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\instructblipvideo\configuration_instructblipvideo.py,C0301, line-too-long,53,0, , , , , , , , 
src\transformers\models\llava\convert_llava_weights_to_hf.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\markuplm\configuration_markuplm.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\mobilenet_v2\modeling_mobilenet_v2.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\models\mt5\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\olmo\modeling_olmo.py,C0301, line-too-long,94,0, , , , , , , , 
src\transformers\models\olmo\modeling_olmo.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\olmo\modeling_olmo.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\pvt_v2\modeling_pvt_v2.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\vivit\image_processing_vivit.py,C0301, line-too-long,38,0, , , , , , , , 
src\transformers\models\xlm_roberta_xl\convert_xlm_roberta_xl_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\onnx\features.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\pipelines\zero_shot_object_detection.py,C0301, line-too-long,13,0, , , , , , , , 
examples\pytorch\text-classification\run_xnli.py,C0301, line-too-long,31,0, , , , , , , , 
examples\pytorch\text-classification\run_xnli.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\quantization-qdqbert\evaluate-hf-trt-qa.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\data\metrics\squad_metrics.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\data\metrics\squad_metrics.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\image_processing_utils.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\integrations\eetq.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\auto\image_processing_auto.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\auto\image_processing_auto.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\byt5\tokenization_byt5.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\configuration_transfo_xl.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\detr\convert_detr_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\detr\convert_detr_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\grounding_dino\modeling_grounding_dino.py,C0301, line-too-long,296,0, , , , , , , , 
src\transformers\models\grounding_dino\modeling_grounding_dino.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\grounding_dino\modeling_grounding_dino.py,R0915, too-many-statements,4,0, , , , , , , , 
src\transformers\models\grounding_dino\modeling_grounding_dino.py,W0718, broad-exception-caught,2,0, , , , , , , , 
src\transformers\models\llava_next_video\modular_llava_next_video.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\llava_next_video\modular_llava_next_video.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mask2former\modeling_mask2former.py,C0301, line-too-long,238,0, , , , , , , , 
src\transformers\models\mask2former\modeling_mask2former.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\opt\modeling_flax_opt.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\opt\modeling_tf_opt.py,C0301, line-too-long,79,0, , , , , , , , 
src\transformers\models\opt\modeling_tf_opt.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\pix2struct\convert_pix2struct_original_pytorch_to_hf.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\pvt_v2\convert_pvt_v2_to_pytorch.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\pvt_v2\convert_pvt_v2_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\resnet\modeling_resnet.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\roberta\modeling_tf_roberta.py,C0301, line-too-long,109,0, , , , , , , , 
src\transformers\models\roberta\modeling_tf_roberta.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\roberta\modeling_tf_roberta.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\univnet\convert_univnet.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\vision_text_dual_encoder\configuration_vision_text_dual_encoder.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\vit\configuration_vit.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\vitmatte\modeling_vitmatte.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\xlm_roberta\tokenization_xlm_roberta_fast.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\tokenization_utils_fast.py,C0301, line-too-long,45,0, , , , , , , , 
src\transformers\tokenization_utils_fast.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\legacy\seq2seq\seq2seq_trainer.py,C0301, line-too-long,17,0, , , , , , , , 
examples\pytorch\question-answering\trainer_seq2seq_qa.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\rag\distributed_ray_retriever.py,C0301, line-too-long,11,0, , , , , , , , 
examples\run_on_remote.py,C0301, line-too-long,10,0, , , , , , , , 
examples\tensorflow\language-modeling-tpu\train_unigram.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\bert\configuration_bert.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\bit\configuration_bit.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\ctrl\modeling_tf_ctrl.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\ctrl\modeling_tf_ctrl.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\efficientformer\modeling_tf_efficientformer.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\models\deprecated\xlm_prophetnet\modeling_xlm_prophetnet.py,C0301, line-too-long,246,0, , , , , , , , 
src\transformers\models\deprecated\xlm_prophetnet\modeling_xlm_prophetnet.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\deprecated\xlm_prophetnet\modeling_xlm_prophetnet.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\electra\tokenization_electra_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\encodec\convert_encodec_checkpoint_to_pytorch.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\encodec\convert_encodec_checkpoint_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\idefics\perceiver.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\instructblip\processing_instructblip.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\maskformer\convert_maskformer_resnet_to_pytorch.py,C0301, line-too-long,69,0, , , , , , , , 
src\transformers\models\maskformer\convert_maskformer_resnet_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\maskformer\convert_maskformer_resnet_to_pytorch.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\mt5\modeling_tf_mt5.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\pegasus\configuration_pegasus.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\qwen2_vl\configuration_qwen2_vl.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\qwen2_vl\modeling_qwen2_vl.py,C0301, line-too-long,164,0, , , , , , , , 
src\transformers\models\qwen2_vl\modeling_qwen2_vl.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\qwen2_vl\modeling_qwen2_vl.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\qwen2_vl\modeling_qwen2_vl.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\recurrent_gemma\modeling_recurrent_gemma.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\models\splinter\configuration_splinter.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\vivit\modeling_vivit.py,C0301, line-too-long,33,0, , , , , , , , 
utils\pr_slow_ci_models.py,C0301, line-too-long,6,0, , , , , , , , 
examples\legacy\token-classification\utils_ner.py,C0301, line-too-long,11,0, , , , , , , , 
examples\research_projects\movement-pruning\emmental\modules\binarizer.py,C0301, line-too-long,10,0, , , , , , , , 
examples\research_projects\quantization-qdqbert\run_quant_qa.py,C0301, line-too-long,68,0, , , , , , , , 
examples\research_projects\quantization-qdqbert\run_quant_qa.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\generation\utils.py,C0301, line-too-long,626,0, , , , , , , , 
src\transformers\generation\utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\generation\utils.py,R0912, too-many-branches,12,0, , , , , , , , 
src\transformers\generation\utils.py,R0915, too-many-statements,9,0, , , , , , , , 
src\transformers\generation\utils.py,R1703, simplifiable-if-statement,1,0, , , , , , , , 
src\transformers\image_utils.py,C0301, line-too-long,53,0, , , , , , , , 
src\transformers\image_utils.py,R0916, too-many-boolean-expressions,2,0, , , , , , , , 
src\transformers\image_utils.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\blenderbot\modeling_flax_blenderbot.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\models\blenderbot\modeling_flax_blenderbot.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\bridgetower\image_processing_bridgetower.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\bros\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\chameleon\convert_chameleon_weights_to_hf.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\chameleon\convert_chameleon_weights_to_hf.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\clip\tokenization_clip.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\data2vec\modeling_tf_data2vec_vision.py,C0301, line-too-long,82,0, , , , , , , , 
src\transformers\models\deprecated\ernie_m\configuration_ernie_m.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\dpt\convert_dpt_swinv2_to_hf.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\fastspeech2_conformer\convert_model_with_hifigan.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\flava\modeling_flava.py,C0301, line-too-long,145,0, , , , , , , , 
src\transformers\models\flava\modeling_flava.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\flava\modeling_flava.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\fuyu\modeling_fuyu.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\git\modeling_git.py,C0301, line-too-long,101,0, , , , , , , , 
src\transformers\models\git\modeling_git.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\megatron_gpt2\checkpoint_reshaping_and_interoperability.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\models\megatron_gpt2\checkpoint_reshaping_and_interoperability.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\mobilenet_v2\configuration_mobilenet_v2.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\mvp\tokenization_mvp.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\qwen2\tokenization_qwen2_fast.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\reformer\tokenization_reformer.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\regnet\modeling_tf_regnet.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\rembert\modeling_tf_rembert.py,C0301, line-too-long,102,0, , , , , , , , 
src\transformers\models\rembert\modeling_tf_rembert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\rembert\modeling_tf_rembert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\speech_encoder_decoder\configuration_speech_encoder_decoder.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\vivit\convert_vivit_flax_to_pytorch.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\xlm_roberta_xl\modeling_xlm_roberta_xl.py,C0301, line-too-long,133,0, , , , , , , , 
src\transformers\models\xlm_roberta_xl\modeling_xlm_roberta_xl.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\xlm_roberta_xl\modeling_xlm_roberta_xl.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\xlm_roberta_xl\modeling_xlm_roberta_xl.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
examples\pytorch\image-pretraining\run_mae.py,C0301, line-too-long,32,0, , , , , , , , 
examples\pytorch\image-pretraining\run_mae.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\pytorch\summarization\run_summarization.py,C0301, line-too-long,69,0, , , , , , , , 
examples\pytorch\summarization\run_summarization.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\deebert\src\modeling_highway_roberta.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\jax-projects\hybrid_clip\configuration_hybrid_clip.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\utils.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\agents\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\agents\search.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\generation\__init__.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\generation\tf_utils.py,C0301, line-too-long,517,0, , , , , , , , 
src\transformers\generation\tf_utils.py,R0912, too-many-branches,5,0, , , , , , , , 
src\transformers\generation\tf_utils.py,R0915, too-many-statements,8,0, , , , , , , , 
src\transformers\models\albert\tokenization_albert.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\big_bird\modeling_flax_big_bird.py,C0301, line-too-long,151,0, , , , , , , , 
src\transformers\models\big_bird\modeling_flax_big_bird.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\big_bird\modeling_flax_big_bird.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\clip\configuration_clip.py,C0301, line-too-long,54,0, , , , , , , , 
src\transformers\models\clipseg\configuration_clipseg.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\models\data2vec\configuration_data2vec_text.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\dpr\modeling_dpr.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\gemma\configuration_gemma.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\gpt_neox\tokenization_gpt_neox_fast.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\layoutlm\modeling_layoutlm.py,C0301, line-too-long,70,0, , , , , , , , 
src\transformers\models\layoutlm\modeling_layoutlm.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\layoutlm\modeling_layoutlm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mt5\configuration_mt5.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\vit\image_processing_vit.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\onnx\convert.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\onnx\convert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\pipelines\object_detection.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\pipelines\text_generation.py,C0301, line-too-long,53,0, , , , , , , , 
benchmark\benchmark.py,C0301, line-too-long,12,0, , , , , , , , 
benchmark\benchmark.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\flax\language-modeling\t5_tokenizer_model.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\albert\tokenization_albert_fast.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\auto\processing_auto.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\auto\processing_auto.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\auto\processing_auto.py,W0718, broad-exception-caught,3,0, , , , , , , , 
src\transformers\models\bigbird_pegasus\modeling_bigbird_pegasus.py,C0301, line-too-long,228,0, , , , , , , , 
src\transformers\models\bigbird_pegasus\modeling_bigbird_pegasus.py,R0912, too-many-branches,6,0, , , , , , , , 
src\transformers\models\bigbird_pegasus\modeling_bigbird_pegasus.py,R0915, too-many-statements,4,0, , , , , , , , 
src\transformers\models\blip\modeling_blip.py,C0301, line-too-long,113,0, , , , , , , , 
src\transformers\models\blip_2\configuration_blip_2.py,C0301, line-too-long,46,0, , , , , , , , 
src\transformers\models\camembert\tokenization_camembert_fast.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\codegen\tokenization_codegen_fast.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\cpmant\modeling_cpmant.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\models\dbrx\configuration_dbrx.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\deit\modeling_tf_deit.py,C0301, line-too-long,63,0, , , , , , , , 
src\transformers\models\deprecated\van\configuration_van.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\dpr\modeling_tf_dpr.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\models\instructblip\convert_instructblip_original_to_pytorch.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\instructblip\convert_instructblip_original_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mamba2\configuration_mamba2.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\maskformer\convert_maskformer_swin_to_pytorch.py,C0301, line-too-long,85,0, , , , , , , , 
src\transformers\models\maskformer\convert_maskformer_swin_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mpnet\configuration_mpnet.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\mpt\configuration_mpt.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\owlv2\convert_owlv2_to_hf.py,C0301, line-too-long,70,0, , , , , , , , 
src\transformers\models\owlv2\convert_owlv2_to_hf.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\pegasus\tokenization_pegasus.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\poolformer\configuration_poolformer.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\prophetnet\tokenization_prophetnet.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\stablelm\configuration_stablelm.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\vit_mae\configuration_vit_mae.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\wav2vec2\processing_wav2vec2.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\xglm\modeling_flax_xglm.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\utils\__init__.py,C0301, line-too-long,4,0, , , , , , , , 
examples\flax\question-answering\run_qa.py,C0301, line-too-long,98,0, , , , , , , , 
examples\flax\question-answering\run_qa.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\flax\question-answering\run_qa.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\legacy\multiple_choice\run_multiple_choice.py,C0301, line-too-long,6,0, , , , , , , , 
examples\pytorch\image-classification\run_image_classification.py,C0301, line-too-long,34,0, , , , , , , , 
examples\pytorch\image-classification\run_image_classification.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\language-modeling\run_mlm.py,C0301, line-too-long,61,0, , , , , , , , 
examples\pytorch\language-modeling\run_mlm.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\codeparrot\scripts\preprocessing.py,C0301, line-too-long,3,0, , , , , , , , 
examples\research_projects\longform-qa\eli5_utils.py,C0301, line-too-long,37,0, , , , , , , , 
examples\research_projects\onnx\summarization\bart_onnx\generation_onnx.py,C0301, line-too-long,42,0, , , , , , , , 
examples\research_projects\pplm\run_pplm.py,C0301, line-too-long,17,0, , , , , , , , 
examples\research_projects\pplm\run_pplm.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\research_projects\pplm\run_pplm.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\benchmark\benchmark_utils.py,C0301, line-too-long,75,0, , , , , , , , 
src\transformers\benchmark\benchmark_utils.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\benchmark\benchmark_utils.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\benchmark\benchmark_utils.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\generation\flax_logits_process.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\generation\watermarking.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\integrations\deepspeed.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\integrations\peft.py,C0301, line-too-long,72,0, , , , , , , , 
src\transformers\integrations\peft.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\clvp\tokenization_clvp.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\conditional_detr\configuration_conditional_detr.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\data2vec\convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\decision_transformer\configuration_decision_transformer.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\deit\image_processing_deit.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\models\deprecated\mctct\processing_mctct.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\esm\modeling_tf_esm.py,C0301, line-too-long,97,0, , , , , , , , 
src\transformers\models\esm\modeling_tf_esm.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\esm\modeling_tf_esm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\fuyu\image_processing_fuyu.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\grounding_dino\configuration_grounding_dino.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\layoutlm\configuration_layoutlm.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\llama\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\marian\modeling_tf_marian.py,C0301, line-too-long,108,0, , , , , , , , 
src\transformers\models\marian\modeling_tf_marian.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\markuplm\processing_markuplm.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\mistral\modeling_tf_mistral.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\models\mistral\modeling_tf_mistral.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\perceiver\configuration_perceiver.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\rt_detr\modeling_rt_detr_resnet.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\speech_to_text\modeling_tf_speech_to_text.py,C0301, line-too-long,103,0, , , , , , , , 
src\transformers\models\speech_to_text\modeling_tf_speech_to_text.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\speech_to_text\modeling_tf_speech_to_text.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\tapas\tokenization_tapas.py,C0301, line-too-long,178,0, , , , , , , , 
src\transformers\models\tapas\tokenization_tapas.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\tapas\tokenization_tapas.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\tapas\tokenization_tapas.py,R0916, too-many-boolean-expressions,1,0, , , , , , , , 
src\transformers\models\tapas\tokenization_tapas.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
src\transformers\models\tvp\processing_tvp.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\xmod\modeling_xmod.py,C0301, line-too-long,130,0, , , , , , , , 
src\transformers\models\xmod\modeling_xmod.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\xmod\modeling_xmod.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\research_projects\distillation\scripts\extract_distilbert.py,C0301, line-too-long,11,0, , , , , , , , 
examples\research_projects\rag\utils_rag.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\integrations\hqq.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\modeling_attn_mask_utils.py,C0301, line-too-long,52,0, , , , , , , , 
src\transformers\models\bert_japanese\tokenization_bert_japanese.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\bert_japanese\tokenization_bert_japanese.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_tf_blenderbot_small.py,C0301, line-too-long,111,0, , , , , , , , 
src\transformers\models\blenderbot_small\modeling_tf_blenderbot_small.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\clip\tokenization_clip_fast.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\ernie\modeling_ernie.py,C0301, line-too-long,147,0, , , , , , , , 
src\transformers\models\ernie\modeling_ernie.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\ernie\modeling_ernie.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\longformer\tokenization_longformer_fast.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\mimi\modeling_mimi.py,C0301, line-too-long,153,0, , , , , , , , 
src\transformers\models\mimi\modeling_mimi.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\mimi\modeling_mimi.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mobilebert\configuration_mobilebert.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\omdet_turbo\processing_omdet_turbo.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\pvt\convert_pvt_to_pytorch.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\reformer\convert_reformer_trax_checkpoint_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\seamless_m4t\tokenization_seamless_m4t.py,C0301, line-too-long,60,0, , , , , , , , 
src\transformers\models\seamless_m4t_v2\modeling_seamless_m4t_v2.py,C0301, line-too-long,460,0, , , , , , , , 
src\transformers\models\seamless_m4t_v2\modeling_seamless_m4t_v2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\seamless_m4t_v2\modeling_seamless_m4t_v2.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\seamless_m4t_v2\modeling_seamless_m4t_v2.py,R0915, too-many-statements,4,0, , , , , , , , 
src\transformers\models\siglip\configuration_siglip.py,C0301, line-too-long,38,0, , , , , , , , 
src\transformers\models\speecht5\convert_speecht5_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\models\speecht5\convert_speecht5_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\t5\convert_t5x_checkpoint_to_flax.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\utils\chat_template_utils.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\utils\chat_template_utils.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\utils\chat_template_utils.py,W0107,unnecessary-pass,2,0, , , , , , , , 
examples\legacy\pytorch-lightning\run_glue.py,C0301, line-too-long,5,0, , , , , , , , 
examples\pytorch\object-detection\run_object_detection_no_trainer.py,C0301, line-too-long,46,0, , , , , , , , 
examples\pytorch\object-detection\run_object_detection_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\pytorch\text-generation\run_generation.py,C0301, line-too-long,26,0, , , , , , , , 
examples\pytorch\text-generation\run_generation.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\pytorch\token-classification\run_ner_no_trainer.py,C0301, line-too-long,56,0, , , , , , , , 
examples\pytorch\token-classification\run_ner_no_trainer.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\pytorch\xla_spawn.py,C0301, line-too-long,3,0, , , , , , , , 
examples\research_projects\codeparrot\scripts\minhash_deduplication.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\movement-pruning\emmental\modeling_bert_masked.py,C0301, line-too-long,66,0, , , , , , , , 
examples\research_projects\movement-pruning\emmental\modeling_bert_masked.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\movement-pruning\emmental\modeling_bert_masked.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\pplm\run_pplm_discrim_train.py,C0301, line-too-long,19,0, , , , , , , , 
examples\research_projects\pplm\run_pplm_discrim_train.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\pplm\run_pplm_discrim_train.py,W0107,unnecessary-pass,3,0, , , , , , , , 
examples\research_projects\pplm\run_pplm_discrim_train.py,W0718, broad-exception-caught,4,0, , , , , , , , 
examples\research_projects\rag\distributed_pytorch_retriever.py,C0301, line-too-long,13,0, , , , , , , , 
examples\tensorflow\text-classification\run_glue.py,C0301, line-too-long,38,0, , , , , , , , 
examples\tensorflow\text-classification\run_glue.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\agents\default_tools.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\integrations\executorch.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\albert\modeling_flax_albert.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\models\bert\modeling_tf_bert.py,C0301, line-too-long,132,0, , , , , , , , 
src\transformers\models\bert\modeling_tf_bert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\bert\modeling_tf_bert.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\clvp\processing_clvp.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\dac\modeling_dac.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\deberta_v2\modeling_deberta_v2.py,C0301, line-too-long,90,0, , , , , , , , 
src\transformers\models\deberta_v2\modeling_deberta_v2.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\deprecated\deta\convert_deta_resnet_to_pytorch.py,C0301, line-too-long,59,0, , , , , , , , 
src\transformers\models\deprecated\mmbt\modeling_mmbt.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\depth_anything\modeling_depth_anything.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\dpr\tokenization_dpr.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\ibert\quant_modules.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\mamba\convert_mamba_ssm_checkpoint_to_pytorch.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\mluke\tokenization_mluke.py,C0301, line-too-long,155,0, , , , , , , , 
src\transformers\models\mluke\tokenization_mluke.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\mluke\tokenization_mluke.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\speecht5\configuration_speecht5.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\swin\convert_swin_simmim_to_pytorch.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\xglm\configuration_xglm.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\xlnet\modeling_xlnet.py,C0301, line-too-long,161,0, , , , , , , , 
src\transformers\models\xlnet\modeling_xlnet.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\xlnet\modeling_xlnet.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\pipelines\text_to_audio.py,C0301, line-too-long,16,0, , , , , , , , 
examples\pytorch\multiple-choice\run_swag_no_trainer.py,C0301, line-too-long,58,0, , , , , , , , 
examples\pytorch\multiple-choice\run_swag_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\jax-projects\big_bird\prepare_natural_questions.py,C0301, line-too-long,3,0, , , , , , , , 
examples\research_projects\jax-projects\big_bird\prepare_natural_questions.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\seq2seq-distillation\run_eval.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\agents\llm_engine.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\autoformer\modeling_autoformer.py,C0301, line-too-long,226,0, , , , , , , , 
src\transformers\models\autoformer\modeling_autoformer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\autoformer\modeling_autoformer.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\big_bird\convert_bigbird_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\canine\tokenization_canine.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\clvp\modeling_clvp.py,C0301, line-too-long,150,0, , , , , , , , 
src\transformers\models\clvp\modeling_clvp.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\clvp\modeling_clvp.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\clvp\modeling_clvp.py,W0104, pointless-statement,2,0, , , , , , , , 
src\transformers\models\deprecated\deta\convert_deta_swin_to_pytorch.py,C0301, line-too-long,78,0, , , , , , , , 
src\transformers\models\deprecated\deta\convert_deta_swin_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\modeling_gptsan_japanese.py,C0301, line-too-long,109,0, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\modeling_gptsan_japanese.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\deprecated\gptsan_japanese\modeling_gptsan_japanese.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\deprecated\trajectory_transformer\convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\efficientnet\image_processing_efficientnet.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\models\gemma2\modular_gemma2.py,C0301, line-too-long,72,0, , , , , , , , 
src\transformers\models\gemma2\modular_gemma2.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\hubert\convert_distilhubert_original_s3prl_checkpoint_to_pytorch.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\idefics\configuration_idefics.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\led\modeling_led.py,C0301, line-too-long,291,0, , , , , , , , 
src\transformers\models\led\modeling_led.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\led\modeling_led.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\llava_next_video\configuration_llava_next_video.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\mt5\modeling_mt5.py,C0301, line-too-long,121,0, , , , , , , , 
src\transformers\models\mt5\modeling_mt5.py,R0912, too-many-branches,6,0, , , , , , , , 
src\transformers\models\mt5\modeling_mt5.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\roformer\modeling_tf_roformer.py,C0301, line-too-long,72,0, , , , , , , , 
src\transformers\models\vit\image_processing_vit_fast.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\vits\configuration_vits.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\wav2vec2\configuration_wav2vec2.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\wav2vec2\modeling_tf_wav2vec2.py,C0301, line-too-long,82,0, , , , , , , , 
src\transformers\pipelines\image_feature_extraction.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\quantizers\quantizer_eetq.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\utils\model_parallel_utils.py,C0301, line-too-long,3,0, , , , , , , , 
examples\research_projects\quantization-qdqbert\trainer_quant_qa.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\data\datasets\glue.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\auto\modeling_auto.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\clvp\convert_clvp_to_hf.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\convbert\tokenization_convbert.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_text.py,C0301, line-too-long,123,0, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_text.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_text.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\deberta_v2\tokenization_deberta_v2.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\deberta_v2\tokenization_deberta_v2.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\efficientnet\convert_efficientnet_to_pytorch.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\fastspeech2_conformer\tokenization_fastspeech2_conformer.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\focalnet\modeling_focalnet.py,C0301, line-too-long,64,0, , , , , , , , 
src\transformers\models\gpt2\configuration_gpt2.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\gpt_neo\configuration_gpt_neo.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\idefics\perceiver_tf.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\levit\image_processing_levit.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\models\longt5\configuration_longt5.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\longt5\modeling_longt5.py,C0301, line-too-long,128,0, , , , , , , , 
src\transformers\models\longt5\modeling_longt5.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\longt5\modeling_longt5.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\longt5\modeling_longt5.py,W0107,unnecessary-pass,1,0, , , , , , , , 
src\transformers\models\longt5\modeling_longt5.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\pixtral\processing_pixtral.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\plbart\convert_plbart_original_checkpoint_to_torch.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\rembert\convert_rembert_tf_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\seggpt\image_processing_seggpt.py,C0301, line-too-long,86,0, , , , , , , , 
src\transformers\models\stablelm\modeling_stablelm.py,C0301, line-too-long,130,0, , , , , , , , 
src\transformers\models\stablelm\modeling_stablelm.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\stablelm\modeling_stablelm.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
examples\pytorch\image-pretraining\run_mim.py,C0301, line-too-long,38,0, , , , , , , , 
examples\pytorch\image-pretraining\run_mim.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\distillation\distiller.py,C0301, line-too-long,55,0, , , , , , , , 
examples\research_projects\distillation\distiller.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\research_projects\rag\eval_rag.py,C0301, line-too-long,11,0, , , , , , , , 
examples\research_projects\robust-speech-event\run_speech_recognition_ctc_streaming.py,C0301, line-too-long,51,0, , , , , , , , 
examples\research_projects\robust-speech-event\run_speech_recognition_ctc_streaming.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\tapex\wikisql_utils.py,R0911, too-many-return-statements,2,0, , , , , , , , 
examples\tensorflow\question-answering\utils_qa.py,C0301, line-too-long,51,0, , , , , , , , 
examples\tensorflow\question-answering\utils_qa.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\tensorflow\question-answering\utils_qa.py,R0916, too-many-boolean-expressions,2,0, , , , , , , , 
src\transformers\commands\serving.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\bert\modeling_flax_bert.py,C0301, line-too-long,67,0, , , , , , , , 
src\transformers\models\bert\modeling_flax_bert.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\big_bird\configuration_big_bird.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\cpmant\tokenization_cpmant.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\dpt\image_processing_dpt.py,C0301, line-too-long,51,0, , , , , , , , 
src\transformers\models\hiera\configuration_hiera.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\layoutlmv3\configuration_layoutlmv3.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\mbart50\tokenization_mbart50.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\musicgen_melody\feature_extraction_musicgen_melody.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\persimmon\modeling_persimmon.py,C0301, line-too-long,96,0, , , , , , , , 
src\transformers\models\persimmon\modeling_persimmon.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\rag\modeling_rag.py,C0301, line-too-long,201,0, , , , , , , , 
src\transformers\models\rag\modeling_rag.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\rag\modeling_tf_rag.py,C0301, line-too-long,192,0, , , , , , , , 
src\transformers\models\rembert\tokenization_rembert.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\roberta\tokenization_roberta_fast.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\seamless_m4t\convert_fairseq2_to_hf.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\splinter\tokenization_splinter_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\vipllava\modeling_vipllava.py,C0301, line-too-long,70,0, , , , , , , , 
src\transformers\models\vision_encoder_decoder\modeling_vision_encoder_decoder.py,C0301, line-too-long,68,0, , , , , , , , 
src\transformers\models\whisper\generation_whisper.py,C0301, line-too-long,219,0, , , , , , , , 
src\transformers\models\whisper\generation_whisper.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\whisper\generation_whisper.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\whisper\generation_whisper.py,R0915, too-many-statements,3,0, , , , , , , , 
utils\get_github_job_time.py,C0301, line-too-long,3,0, , , , , , , , 
examples\flax\image-captioning\run_image_captioning_flax.py,C0301, line-too-long,98,0, , , , , , , , 
examples\flax\image-captioning\run_image_captioning_flax.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\flax\image-captioning\run_image_captioning_flax.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\flax\image-captioning\run_image_captioning_flax.py,W0718, broad-exception-caught,2,0, , , , , , , , 
examples\research_projects\deebert\run_glue_deebert.py,C0301, line-too-long,50,0, , , , , , , , 
examples\research_projects\deebert\run_glue_deebert.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\research_projects\deebert\run_glue_deebert.py,R0915, too-many-statements,3,0, , , , , , , , 
examples\research_projects\deebert\src\modeling_highway_bert.py,C0301, line-too-long,26,0, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_glue.py,C0301, line-too-long,55,0, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_glue.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_glue.py,R0915, too-many-statements,3,0, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_glue.py,R1702, too-many-nested-blocks,4,0, , , , , , , , 
src\transformers\agents\prompts.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\commands\run.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\convert_pytorch_checkpoint_to_tf2.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\integrations\aqlm.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\bark\processing_bark.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\bert\convert_bert_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\blip_2\processing_blip_2.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\convbert\modeling_tf_convbert.py,C0301, line-too-long,64,0, , , , , , , , 
src\transformers\models\convnext\convert_convnext_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\convnext\convert_convnext_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\data2vec\configuration_data2vec_vision.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\deformable_detr\modeling_deformable_detr.py,C0301, line-too-long,215,0, , , , , , , , 
src\transformers\models\deformable_detr\modeling_deformable_detr.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\deformable_detr\modeling_deformable_detr.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\deformable_detr\modeling_deformable_detr.py,W0718, broad-exception-caught,2,0, , , , , , , , 
src\transformers\models\deprecated\van\convert_van_to_pytorch.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\git\convert_git_to_pytorch.py,C0301, line-too-long,75,0, , , , , , , , 
src\transformers\models\git\convert_git_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\gpt2\tokenization_gpt2_tf.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\gpt_neo\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\gpt_sw3\tokenization_gpt_sw3.py,C0301, line-too-long,24,0, , , , , , , , 
src\transformers\models\imagegpt\image_processing_imagegpt.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\models\luke\modeling_luke.py,C0301, line-too-long,217,0, , , , , , , , 
src\transformers\models\m2m_100\modeling_m2m_100.py,C0301, line-too-long,121,0, , , , , , , , 
src\transformers\models\m2m_100\modeling_m2m_100.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\m2m_100\modeling_m2m_100.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\m2m_100\modeling_m2m_100.py,R1719, simplifiable-if-expression,3,0, , , , , , , , 
src\transformers\models\maskformer\configuration_maskformer_swin.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\mllama\configuration_mllama.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\mluke\convert_mluke_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\mluke\convert_mluke_original_pytorch_checkpoint_to_pytorch.py,C0325, superfluous-parens,2,0, , , , , , , , 
src\transformers\models\mluke\convert_mluke_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mra\configuration_mra.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\openai\modeling_tf_openai.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\models\openai\modeling_tf_openai.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\owlvit\image_processing_owlvit.py,C0301, line-too-long,66,0, , , , , , , , 
src\transformers\models\phobert\tokenization_phobert.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\pixtral\convert_pixtral_weights_to_hf.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\superpoint\modeling_superpoint.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\unispeech_sat\convert_unispeech_original_s3prl_checkpoint_to_pytorch.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\visual_bert\configuration_visual_bert.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\zoedepth\image_processing_zoedepth.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\zoedepth\modeling_zoedepth.py,C0301, line-too-long,81,0, , , , , , , , 
src\transformers\pipelines\image_to_image.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\sagemaker\training_args_sm.py,C0301, line-too-long,5,0, , , , , , , , 
utils\create_dummy_models.py,C0301, line-too-long,117,0, , , , , , , , 
utils\create_dummy_models.py,C0302, too-many-lines,1,0, , , , , , , , 
utils\create_dummy_models.py,R0912, too-many-branches,6,0, , , , , , , , 
utils\create_dummy_models.py,R0915, too-many-statements,6,0, , , , , , , , 
utils\create_dummy_models.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
utils\create_dummy_models.py,W0718, broad-exception-caught,22,0, , , , , , , , 
examples\legacy\question-answering\run_squad_trainer.py,C0301, line-too-long,9,0, , , , , , , , 
examples\legacy\seq2seq\run_eval_search.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\cache_utils.py,C0301, line-too-long,212,0, , , , , , , , 
src\transformers\integrations\quanto.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\bert_japanese\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\bit\modeling_bit.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\clip\convert_clip_original_pytorch_to_hf.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\deprecated\deta\modeling_deta.py,C0301, line-too-long,254,0, , , , , , , , 
src\transformers\models\deprecated\deta\modeling_deta.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\deprecated\deta\modeling_deta.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\deprecated\deta\modeling_deta.py,W0718, broad-exception-caught,2,0, , , , , , , , 
src\transformers\models\dpt\convert_dpt_hybrid_to_pytorch.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\dpt\convert_dpt_hybrid_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\efficientnet\configuration_efficientnet.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\instructblip\configuration_instructblip.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\models\layoutxlm\tokenization_layoutxlm_fast.py,C0301, line-too-long,57,0, , , , , , , , 
src\transformers\models\layoutxlm\tokenization_layoutxlm_fast.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\layoutxlm\tokenization_layoutxlm_fast.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
src\transformers\models\lilt\configuration_lilt.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\megatron_bert\convert_megatron_bert_checkpoint.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\mra\modeling_mra.py,C0301, line-too-long,84,0, , , , , , , , 
src\transformers\models\mra\modeling_mra.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\mra\modeling_mra.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\models\openai\tokenization_openai_fast.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\rembert\configuration_rembert.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\speecht5\processing_speecht5.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\splinter\modeling_splinter.py,C0301, line-too-long,87,0, , , , , , , , 
src\transformers\models\splinter\modeling_splinter.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\splinter\modeling_splinter.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\swinv2\convert_swinv2_timm_to_pytorch.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\swinv2\convert_swinv2_timm_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\umt5\modeling_umt5.py,C0301, line-too-long,82,0, , , , , , , , 
src\transformers\models\umt5\modeling_umt5.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\umt5\modeling_umt5.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\vitmatte\configuration_vitmatte.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\pipelines\zero_shot_audio_classification.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\utils\backbone_utils.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\utils\peft_utils.py,C0301, line-too-long,12,0, , , , , , , , 
utils\check_doc_toc.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\zero-shot-distillation\distill_classifier.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\convert_tf_hub_seq_to_seq_bert_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\camembert\modeling_camembert.py,C0301, line-too-long,140,0, , , , , , , , 
src\transformers\models\camembert\modeling_camembert.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\camembert\modeling_camembert.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\camembert\modeling_camembert.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\clipseg\convert_clipseg_original_pytorch_to_hf.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\clipseg\convert_clipseg_original_pytorch_to_hf.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\clipseg\convert_clipseg_original_pytorch_to_hf.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_transfo_xl_utilities.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_transfo_xl_utilities.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\deprecated\vit_hybrid\image_processing_vit_hybrid.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\detr\modeling_detr.py,C0301, line-too-long,239,0, , , , , , , , 
src\transformers\models\detr\modeling_detr.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\detr\modeling_detr.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\dpr\convert_dpr_original_checkpoint_to_pytorch.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\fastspeech2_conformer\modeling_fastspeech2_conformer.py,C0301, line-too-long,149,0, , , , , , , , 
src\transformers\models\fastspeech2_conformer\modeling_fastspeech2_conformer.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\fastspeech2_conformer\modeling_fastspeech2_conformer.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\fnet\tokenization_fnet.py,C0301, line-too-long,29,0, , , , , , , , 
src\transformers\models\llava_onevision\configuration_llava_onevision.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\mixtral\configuration_mixtral.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\musicgen_melody\convert_musicgen_melody_transformers.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\paligemma\modeling_paligemma.py,C0301, line-too-long,65,0, , , , , , , , 
src\transformers\models\pixtral\configuration_pixtral.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\pixtral\image_processing_pixtral.py,C0301, line-too-long,53,0, , , , , , , , 
src\transformers\models\seamless_m4t\modeling_seamless_m4t.py,C0301, line-too-long,347,0, , , , , , , , 
src\transformers\models\seamless_m4t\modeling_seamless_m4t.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\seamless_m4t\modeling_seamless_m4t.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\seamless_m4t\modeling_seamless_m4t.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\speech_to_text\tokenization_speech_to_text.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\videomae\image_processing_videomae.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\vision_text_dual_encoder\modeling_tf_vision_text_dual_encoder.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\wav2vec2_with_lm\processing_wav2vec2_with_lm.py,C0301, line-too-long,63,0, , , , , , , , 
utils\check_modular_conversion.py,C0301, line-too-long,7,0, , , , , , , , 
examples\pytorch\text-classification\run_glue.py,C0301, line-too-long,49,0, , , , , , , , 
examples\pytorch\text-classification\run_glue.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\bert-loses-patience\pabee\modeling_pabee_albert.py,C0301, line-too-long,24,0, , , , , , , , 
examples\research_projects\bert-loses-patience\pabee\modeling_pabee_albert.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\codeparrot\scripts\arguments.py,C0301, line-too-long,45,0, , , , , , , , 
examples\research_projects\lxmert\processing_image.py,C0301, line-too-long,5,0, , , , , , , , 
examples\tensorflow\text-classification\run_text_classification.py,C0301, line-too-long,50,0, , , , , , , , 
examples\tensorflow\text-classification\run_text_classification.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\tensorflow\text-classification\run_text_classification.py,R0916, too-many-boolean-expressions,1,0, , , , , , , , 
src\transformers\models\dbrx\modeling_dbrx.py,C0301, line-too-long,103,0, , , , , , , , 
src\transformers\models\dbrx\modeling_dbrx.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\dbrx\modeling_dbrx.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\dbrx\modeling_dbrx.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\deformable_detr\configuration_deformable_detr.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\electra\convert_electra_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\esm\openfold_utils\chunk_utils.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\esm\openfold_utils\chunk_utils.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\funnel\modeling_funnel.py,C0301, line-too-long,82,0, , , , , , , , 
src\transformers\models\funnel\modeling_funnel.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\funnel\modeling_funnel.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\hiera\modeling_hiera.py,C0301, line-too-long,126,0, , , , , , , , 
src\transformers\models\kosmos2\processing_kosmos2.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\kosmos2\processing_kosmos2.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\layoutlm\tokenization_layoutlm_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\owlv2\processing_owlv2.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\phi3\modeling_phi3.py,C0301, line-too-long,136,0, , , , , , , , 
src\transformers\models\phi3\modeling_phi3.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\phi3\modeling_phi3.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\phi3\modeling_phi3.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_flax_roberta_prelayernorm.py,C0301, line-too-long,78,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_flax_roberta_prelayernorm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\segformer\image_processing_segformer.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\models\video_llava\configuration_video_llava.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\vit_mae\modeling_vit_mae.py,C0301, line-too-long,75,0, , , , , , , , 
src\transformers\models\whisper\modeling_whisper.py,C0301, line-too-long,195,0, , , , , , , , 
src\transformers\models\whisper\modeling_whisper.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\whisper\modeling_whisper.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\whisper\modeling_whisper.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\whisper\processing_whisper.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\yolos\configuration_yolos.py,C0301, line-too-long,9,0, , , , , , , , 
examples\research_projects\distillation\lm_seqs_dataset.py,C0301, line-too-long,4,0, , , , , , , , 
examples\research_projects\wav2vec2\run_common_voice.py,C0301, line-too-long,35,0, , , , , , , , 
examples\research_projects\wav2vec2\run_common_voice.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\commands\lfs.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\blenderbot\configuration_blenderbot.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\chinese_clip\modeling_chinese_clip.py,C0301, line-too-long,120,0, , , , , , , , 
src\transformers\models\chinese_clip\modeling_chinese_clip.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\chinese_clip\modeling_chinese_clip.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\deprecated\qdqbert\modeling_qdqbert.py,C0301, line-too-long,129,0, , , , , , , , 
src\transformers\models\deprecated\qdqbert\modeling_qdqbert.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\deprecated\qdqbert\modeling_qdqbert.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\dpt\convert_dpt_beit_to_hf.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\models\idefics3\processing_idefics3.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\layoutxlm\processing_layoutxlm.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\megatron_gpt2\convert_megatron_gpt2_checkpoint.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\megatron_gpt2\convert_megatron_gpt2_checkpoint.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\mobilenet_v1\image_processing_mobilenet_v1.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\resnet\convert_resnet_to_pytorch.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\roformer\tokenization_roformer_fast.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\sam\image_processing_sam.py,C0301, line-too-long,110,0, , , , , , , , 
src\transformers\models\table_transformer\configuration_table_transformer.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\table_transformer\convert_table_transformer_to_hf.py,C0301, line-too-long,44,0, , , , , , , , 
src\transformers\models\upernet\modeling_upernet.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_tf_xlm_roberta.py,C0301, line-too-long,122,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_tf_xlm_roberta.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_tf_xlm_roberta.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\yoso\modeling_yoso.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\yoso\modeling_yoso.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\onnx\utils.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\quantizers\quantizer_awq.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\quantizers\quantizer_quanto.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\tf_utils.py,C0301, line-too-long,18,0, , , , , , , , 
examples\flax\language-modeling\run_bart_dlm_flax.py,C0301, line-too-long,69,0, , , , , , , , 
examples\flax\language-modeling\run_bart_dlm_flax.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\flax\text-classification\run_flax_glue.py,C0301, line-too-long,53,0, , , , , , , , 
examples\flax\text-classification\run_flax_glue.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\pytorch\image-classification\run_image_classification_no_trainer.py,C0301, line-too-long,42,0, , , , , , , , 
examples\pytorch\image-classification\run_image_classification_no_trainer.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\performer\modeling_flax_performer_utils.py,C0301, line-too-long,4,0, , , , , , , , 
examples\research_projects\wav2vec2\alignment.py,C0301, line-too-long,8,0, , , , , , , , 
examples\tensorflow\contrastive-image-text\run_clip.py,C0301, line-too-long,50,0, , , , , , , , 
examples\tensorflow\contrastive-image-text\run_clip.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\tensorflow\contrastive-image-text\run_clip.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\modeling_flax_pytorch_utils.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\modeling_flax_pytorch_utils.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\modeling_flax_pytorch_utils.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\bert\convert_bert_original_tf2_checkpoint_to_pytorch.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\bert\convert_bert_original_tf2_checkpoint_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\biogpt\tokenization_biogpt.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\clip\image_processing_clip.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\deberta_v2\tokenization_deberta_v2_fast.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\distilbert\tokenization_distilbert.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\models\encoder_decoder\modeling_flax_encoder_decoder.py,C0301, line-too-long,75,0, , , , , , , , 
src\transformers\models\glpn\convert_glpn_to_pytorch.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\glpn\convert_glpn_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\glpn\image_processing_glpn.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\led\tokenization_led_fast.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\levit\configuration_levit.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\longformer\modeling_longformer.py,C0301, line-too-long,272,0, , , , , , , , 
src\transformers\models\marian\tokenization_marian.py,C0301, line-too-long,20,0, , , , , , , , 
src\transformers\models\nllb_moe\modeling_nllb_moe.py,C0301, line-too-long,132,0, , , , , , , , 
src\transformers\models\nllb_moe\modeling_nllb_moe.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\nllb_moe\modeling_nllb_moe.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\nllb_moe\modeling_nllb_moe.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\qwen2\configuration_qwen2.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\resnet\modeling_tf_resnet.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\swiftformer\convert_swiftformer_original_to_hf.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\timm_backbone\modeling_timm_backbone.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\wav2vec2_conformer\convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\wav2vec2_conformer\convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\xlnet\tokenization_xlnet_fast.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\pipelines\audio_utils.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\pipelines\base.py,C0301, line-too-long,94,0, , , , , , , , 
src\transformers\pipelines\base.py,R0911, too-many-return-statements,1,0, , , , , , , , 
src\transformers\pipelines\base.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\pipelines\base.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\pipelines\image_segmentation.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\pipelines\question_answering.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\pipelines\question_answering.py,W0718, broad-exception-caught,1,0, , , , , , , , 
src\transformers\trainer_pt_utils.py,C0301, line-too-long,143,0, , , , , , , , 
examples\pytorch\question-answering\run_qa_no_trainer.py,C0301, line-too-long,97,0, , , , , , , , 
examples\pytorch\question-answering\run_qa_no_trainer.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\pytorch\question-answering\run_qa_no_trainer.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\research_projects\distillation\scripts\extract.py,C0301, line-too-long,3,0, , , , , , , , 
examples\research_projects\lxmert\modeling_frcnn.py,C0301, line-too-long,52,0, , , , , , , , 
examples\research_projects\lxmert\modeling_frcnn.py,C0302, too-many-lines,1,0, , , , , , , , 
examples\research_projects\lxmert\modeling_frcnn.py,R0911, too-many-return-statements,1,0, , , , , , , , 
examples\research_projects\lxmert\modeling_frcnn.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\research_projects\lxmert\modeling_frcnn.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\lxmert\modeling_frcnn.py,W0125,using-constant-test,1,0, , , , , , , , 
examples\research_projects\robust-speech-event\eval.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\modeling_tf_outputs.py,C0301, line-too-long,267,0, , , , , , , , 
src\transformers\models\auto\configuration_auto.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\bart\configuration_bart.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\bert\modeling_bert.py,C0301, line-too-long,152,0, , , , , , , , 
src\transformers\models\bert\modeling_bert.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\bert\modeling_bert.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\bert\modeling_bert.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\convnext\modeling_tf_convnext.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\deprecated\vit_hybrid\modeling_vit_hybrid.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\deprecated\xlm_prophetnet\tokenization_xlm_prophetnet.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\esm\modeling_esm.py,C0301, line-too-long,82,0, , , , , , , , 
src\transformers\models\esm\modeling_esm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mistral\modeling_flax_mistral.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\mllama\convert_mllama_weights_to_hf.py,C0301, line-too-long,63,0, , , , , , , , 
src\transformers\models\mllama\convert_mllama_weights_to_hf.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mobilenet_v2\image_processing_mobilenet_v2.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\opt\configuration_opt.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\perceiver\tokenization_perceiver.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\pop2piano\tokenization_pop2piano.py,C0301, line-too-long,75,0, , , , , , , , 
src\transformers\models\roberta\convert_roberta_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\starcoder2\configuration_starcoder2.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\vivit\configuration_vivit.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\wavlm\modeling_wavlm.py,C0301, line-too-long,111,0, , , , , , , , 
src\transformers\models\wavlm\modeling_wavlm.py,C0325, superfluous-parens,2,0, , , , , , , , 
src\transformers\pipelines\table_question_answering.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\pipelines\table_question_answering.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\trainer_callback.py,C0301, line-too-long,59,0, , , , , , , , 
src\transformers\trainer_callback.py,W0107,unnecessary-pass,15,0, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_seq2seq.py,C0301, line-too-long,46,0, , , , , , , , 
examples\pytorch\speech-recognition\run_speech_recognition_seq2seq.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\benchmark\benchmark.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\benchmark\benchmark_tf.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\modeling_flash_attention_utils.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\big_bird\tokenization_big_bird.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\blenderbot_small\tokenization_blenderbot_small.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\convnextv2\modeling_tf_convnextv2.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\deprecated\open_llama\configuration_open_llama.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\deprecated\qdqbert\configuration_qdqbert.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\deprecated\realm\tokenization_realm.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_transfo_xl.py,C0301, line-too-long,92,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_transfo_xl.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_transfo_xl.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\modeling_transfo_xl.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\fuyu\convert_fuyu_model_weights_to_hf.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\llava_next\image_processing_llava_next.py,C0301, line-too-long,83,0, , , , , , , , 
src\transformers\models\mbart\convert_mbart_original_checkpoint_to_pytorch.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\models\mimi\configuration_mimi.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\mvp\configuration_mvp.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\rt_detr\configuration_rt_detr_resnet.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\sew_d\modeling_sew_d.py,C0301, line-too-long,109,0, , , , , , , , 
src\transformers\models\sew_d\modeling_sew_d.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\t5\convert_t5x_checkpoint_to_pytorch.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\video_llava\processing_video_llava.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\quantizers\quantizer_fbgemm_fp8.py,C0301, line-too-long,10,0, , , , , , , , 
examples\pytorch\summarization\run_summarization_no_trainer.py,C0301, line-too-long,59,0, , , , , , , , 
examples\pytorch\summarization\run_summarization_no_trainer.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\utils_rag.py,C0301, line-too-long,4,0, , , , , , , , 
examples\research_projects\rag\finetune_rag.py,C0301, line-too-long,29,0, , , , , , , , 
examples\research_projects\rag\finetune_rag.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\visual_bert\extracting_data.py,C0301, line-too-long,6,0, , , , , , , , 
examples\research_projects\visual_bert\extracting_data.py,W0718, broad-exception-caught,3,0, , , , , , , , 
examples\tensorflow\summarization\run_summarization.py,C0301, line-too-long,66,0, , , , , , , , 
examples\tensorflow\summarization\run_summarization.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\activations_tf.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\generation\configuration_utils.py,C0301, line-too-long,225,0, , , , , , , , 
src\transformers\generation\configuration_utils.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\generation\configuration_utils.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\generation\configuration_utils.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\code_llama\tokenization_code_llama.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\codegen\tokenization_codegen.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\deprecated\trajectory_transformer\modeling_trajectory_transformer.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\deprecated\trajectory_transformer\modeling_trajectory_transformer.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\esm\openfold_utils\protein.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\groupvit\configuration_groupvit.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\models\idefics2\modeling_idefics2.py,C0301, line-too-long,180,0, , , , , , , , 
src\transformers\models\idefics2\modeling_idefics2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\idefics2\modeling_idefics2.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\jamba\configuration_jamba.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\longformer\modeling_tf_longformer.py,C0301, line-too-long,279,0, , , , , , , , 
src\transformers\models\longformer\modeling_tf_longformer.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\luke\tokenization_luke.py,C0301, line-too-long,173,0, , , , , , , , 
src\transformers\models\luke\tokenization_luke.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\luke\tokenization_luke.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\marian\__init__.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\megatron_bert\configuration_megatron_bert.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\mgp_str\processing_mgp_str.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_tf_roberta_prelayernorm.py,C0301, line-too-long,131,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_tf_roberta_prelayernorm.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\roberta_prelayernorm\modeling_tf_roberta_prelayernorm.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\seamless_m4t\tokenization_seamless_m4t_fast.py,C0301, line-too-long,51,0, , , , , , , , 
src\transformers\models\seamless_m4t_v2\convert_fairseq2_to_hf.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\t5\modeling_flax_t5.py,C0301, line-too-long,71,0, , , , , , , , 
src\transformers\models\time_series_transformer\modeling_time_series_transformer.py,C0301, line-too-long,149,0, , , , , , , , 
src\transformers\models\time_series_transformer\modeling_time_series_transformer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\time_series_transformer\modeling_time_series_transformer.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\univnet\feature_extraction_univnet.py,C0301, line-too-long,59,0, , , , , , , , 
src\transformers\models\vilt\modeling_vilt.py,C0301, line-too-long,71,0, , , , , , , , 
src\transformers\quantizers\base.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\trainer_seq2seq.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\trainer_seq2seq.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\utils\import_utils.py,C0301, line-too-long,64,0, , , , , , , , 
src\transformers\utils\import_utils.py,R0911, too-many-return-statements,1,0, , , , , , , , 
src\transformers\utils\import_utils.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\utils\import_utils.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\utils\import_utils.py,R1702, too-many-nested-blocks,2,0, , , , , , , , 
src\transformers\utils\import_utils.py,W0718, broad-exception-caught,3,0, , , , , , , , 
examples\flax\language-modeling\run_t5_mlm_flax.py,C0301, line-too-long,80,0, , , , , , , , 
examples\flax\language-modeling\run_t5_mlm_flax.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\flax\language-modeling\run_t5_mlm_flax.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\legacy\token-classification\run_ner.py,C0301, line-too-long,12,0, , , , , , , , 
examples\legacy\token-classification\run_ner.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\agents\agents.py,C0301, line-too-long,71,0, , , , , , , , 
src\transformers\agents\agents.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\agents\agents.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\agents\agents.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\agents\agents.py,W0107,unnecessary-pass,4,0, , , , , , , , 
src\transformers\agents\agents.py,W0718, broad-exception-caught,6,0, , , , , , , , 
src\transformers\models\audio_spectrogram_transformer\feature_extraction_audio_spectrogram_transformer.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\convnext\configuration_convnext.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\dac\configuration_dac.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\data2vec\modeling_data2vec_vision.py,C0301, line-too-long,92,0, , , , , , , , 
src\transformers\models\deprecated\jukebox\tokenization_jukebox.py,C0301, line-too-long,34,0, , , , , , , , 
src\transformers\models\deprecated\speech_to_text_2\tokenization_speech_to_text_2.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\flaubert\configuration_flaubert.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\fnet\convert_fnet_original_flax_checkpoint_to_pytorch.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\llava_next_video\processing_llava_next_video.py,C0301, line-too-long,43,0, , , , , , , , 
src\transformers\models\longformer\convert_longformer_original_pytorch_lightning_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\maskformer\convert_maskformer_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,65,0, , , , , , , , 
src\transformers\models\mbart\modeling_tf_mbart.py,C0301, line-too-long,111,0, , , , , , , , 
src\transformers\models\mbart\modeling_tf_mbart.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\mbart\modeling_tf_mbart.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mixtral\convert_mixtral_weights_to_hf.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\mobilevit\modeling_mobilevit.py,C0301, line-too-long,27,0, , , , , , , , 
src\transformers\models\pegasus_x\modeling_pegasus_x.py,C0301, line-too-long,118,0, , , , , , , , 
src\transformers\models\pegasus_x\modeling_pegasus_x.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\pegasus_x\modeling_pegasus_x.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\sam\configuration_sam.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\tapas\modeling_tf_tapas.py,C0301, line-too-long,164,0, , , , , , , , 
src\transformers\models\tapas\modeling_tf_tapas.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\tapas\modeling_tf_tapas.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\wav2vec2_conformer\modeling_wav2vec2_conformer.py,C0301, line-too-long,154,0, , , , , , , , 
src\transformers\models\wav2vec2_conformer\modeling_wav2vec2_conformer.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\whisper\configuration_whisper.py,C0301, line-too-long,35,0, , , , , , , , 
src\transformers\models\x_clip\configuration_x_clip.py,C0301, line-too-long,55,0, , , , , , , , 
src\transformers\utils\quantization_config.py,C0301, line-too-long,133,0, , , , , , , , 
src\transformers\utils\quantization_config.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\utils\quantization_config.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\utils\quantization_config.py,W0107,unnecessary-pass,1,0, , , , , , , , 
examples\research_projects\distillation\scripts\token_counts.py,C0301, line-too-long,3,0, , , , , , , , 
examples\research_projects\performer\modeling_flax_performer.py,C0301, line-too-long,21,0, , , , , , , , 
examples\research_projects\performer\modeling_flax_performer.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\barthez\tokenization_barthez.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\chameleon\configuration_chameleon.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\convnext\image_processing_convnext.py,C0301, line-too-long,36,0, , , , , , , , 
src\transformers\models\deprecated\efficientformer\modeling_efficientformer.py,C0301, line-too-long,56,0, , , , , , , , 
src\transformers\models\deprecated\ernie_m\modeling_ernie_m.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\deprecated\ernie_m\modeling_ernie_m.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\deprecated\ernie_m\modeling_ernie_m.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\deprecated\transfo_xl\tokenization_transfo_xl.py,C0301, line-too-long,46,0, , , , , , , , 
src\transformers\models\deprecated\tvlt\feature_extraction_tvlt.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\esm\modeling_esmfold.py,C0301, line-too-long,92,0, , , , , , , , 
src\transformers\models\esm\modeling_esmfold.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\esm\modeling_esmfold.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\fnet\configuration_fnet.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\gpt2\convert_gpt2_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2.py,C0301, line-too-long,99,0, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2.py,R0912, too-many-branches,4,0, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2.py,R0916, too-many-boolean-expressions,1,0, , , , , , , , 
src\transformers\models\llava_next\processing_llava_next.py,C0301, line-too-long,31,0, , , , , , , , 
src\transformers\models\longformer\configuration_longformer.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\maskformer\modeling_maskformer_swin.py,C0301, line-too-long,73,0, , , , , , , , 
src\transformers\models\mobilebert\modeling_tf_mobilebert.py,C0301, line-too-long,104,0, , , , , , , , 
src\transformers\models\mobilevit\modeling_tf_mobilevit.py,C0301, line-too-long,42,0, , , , , , , , 
src\transformers\models\nemotron\modeling_nemotron.py,C0301, line-too-long,118,0, , , , , , , , 
src\transformers\models\nemotron\modeling_nemotron.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\nemotron\modeling_nemotron.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\omdet_turbo\convert_omdet_turbo_to_hf.py,C0301, line-too-long,41,0, , , , , , , , 
src\transformers\models\omdet_turbo\convert_omdet_turbo_to_hf.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\omdet_turbo\convert_omdet_turbo_to_hf.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\owlv2\modeling_owlv2.py,C0301, line-too-long,118,0, , , , , , , , 
src\transformers\models\phi\convert_phi_weights_to_hf.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\poolformer\convert_poolformer_original_to_pytorch.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\poolformer\convert_poolformer_original_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\tvp\image_processing_tvp.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\umt5\convert_umt5_checkpoint_to_pytorch.py,C0301, line-too-long,14,0, , , , , , , , 
src\transformers\models\videomae\convert_videomae_to_pytorch.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\videomae\convert_videomae_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\vilt\processing_vilt.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\vit\modeling_flax_vit.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\time_series_utils.py,C0301, line-too-long,9,0, , , , , , , , 
utils\release.py,C0301, line-too-long,9,0, , , , , , , , 
examples\legacy\seq2seq\utils.py,C0301, line-too-long,19,0, , , , , , , , 
examples\tensorflow\language-modeling-tpu\prepare_tfrecord_shards.py,C0301, line-too-long,5,0, , , , , , , , 
scripts\check_tokenizers.py,C0301, line-too-long,5,0, , , , , , , , 
src\transformers\commands\env.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\convert_slow_tokenizers_checkpoints_to_fast.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\bert\tokenization_bert.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\encoder_decoder\modeling_encoder_decoder.py,C0301, line-too-long,76,0, , , , , , , , 
src\transformers\models\ernie\configuration_ernie.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\models\funnel\tokenization_funnel.py,C0301, line-too-long,32,0, , , , , , , , 
src\transformers\models\gptj\modeling_tf_gptj.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\gptj\modeling_tf_gptj.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\gptj\modeling_tf_gptj.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\marian\convert_marian_to_pytorch.py,C0301, line-too-long,21,0, , , , , , , , 
src\transformers\models\mbart\tokenization_mbart_fast.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\mobilevit\convert_mlcvnets_to_pytorch.py,C0301, line-too-long,15,0, , , , , , , , 
src\transformers\models\mobilevit\convert_mlcvnets_to_pytorch.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\qwen2_vl\image_processing_qwen2_vl.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\siglip\modeling_siglip.py,C0301, line-too-long,111,0, , , , , , , , 
src\transformers\models\siglip\modeling_siglip.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\tapas\configuration_tapas.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\xglm\tokenization_xglm_fast.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\models\xlnet\modeling_tf_xlnet.py,C0301, line-too-long,113,0, , , , , , , , 
src\transformers\models\xlnet\modeling_tf_xlnet.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\xlnet\modeling_tf_xlnet.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\pipelines\document_question_answering.py,C0301, line-too-long,48,0, , , , , , , , 
src\transformers\pipelines\document_question_answering.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_squad.py,C0301, line-too-long,82,0, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_squad.py,R0912, too-many-branches,3,0, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_squad.py,R0915, too-many-statements,3,0, , , , , , , , 
examples\research_projects\movement-pruning\masked_run_squad.py,R1702, too-many-nested-blocks,4,0, , , , , , , , 
src\transformers\benchmark\benchmark_args_utils.py,C0301, line-too-long,17,0, , , , , , , , 
src\transformers\generation\candidate_generator.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\biogpt\convert_biogpt_original_pytorch_checkpoint_to_pytorch.py,C0301, line-too-long,6,0, , , , , , , , 
src\transformers\models\blip\configuration_blip.py,C0301, line-too-long,40,0, , , , , , , , 
src\transformers\models\detr\configuration_detr.py,C0301, line-too-long,23,0, , , , , , , , 
src\transformers\models\distilbert\configuration_distilbert.py,C0301, line-too-long,12,0, , , , , , , , 
src\transformers\models\llama\modeling_llama.py,C0301, line-too-long,143,0, , , , , , , , 
src\transformers\models\llama\modeling_llama.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\llama\modeling_llama.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\mbart\tokenization_mbart.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\oneformer\processing_oneformer.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\perceiver\image_processing_perceiver.py,C0301, line-too-long,39,0, , , , , , , , 
src\transformers\models\pixtral\modeling_pixtral.py,C0301, line-too-long,30,0, , , , , , , , 
src\transformers\models\roformer\convert_roformer_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\squeezebert\modeling_squeezebert.py,C0301, line-too-long,58,0, , , , , , , , 
src\transformers\models\tapas\modeling_tapas.py,C0301, line-too-long,190,0, , , , , , , , 
src\transformers\models\tapas\modeling_tapas.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\tapas\modeling_tapas.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\wav2vec2\modeling_flax_wav2vec2.py,C0301, line-too-long,69,0, , , , , , , , 
src\transformers\models\wavlm\configuration_wavlm.py,C0301, line-too-long,50,0, , , , , , , , 
src\transformers\pipelines\fill_mask.py,C0301, line-too-long,18,0, , , , , , , , 
src\transformers\quantizers\quantizer_bnb_8bit.py,C0301, line-too-long,29,0, , , , , , , , 
utils\check_support_list.py,C0301, line-too-long,7,0, , , , , , , , 
examples\legacy\run_openai_gpt.py,C0301, line-too-long,29,0, , , , , , , , 
examples\legacy\run_openai_gpt.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\adversarial\utils_hans.py,C0301, line-too-long,10,0, , , , , , , , 
examples\research_projects\layoutlmv3\run_funsd_cord.py,C0301, line-too-long,31,0, , , , , , , , 
examples\research_projects\layoutlmv3\run_funsd_cord.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\movement-pruning\counts_parameters.py,C0301, line-too-long,3,0, , , , , , , , 
examples\research_projects\rag\use_own_knowledge_dataset.py,C0301, line-too-long,17,0, , , , , , , , 
examples\tensorflow\question-answering\run_qa.py,C0301, line-too-long,83,0, , , , , , , , 
examples\tensorflow\question-answering\run_qa.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\image_transforms.py,C0301, line-too-long,65,0, , , , , , , , 
src\transformers\models\albert\convert_albert_original_tf_checkpoint_to_pytorch.py,C0301, line-too-long,3,0, , , , , , , , 
src\transformers\models\bigbird_pegasus\configuration_bigbird_pegasus.py,C0301, line-too-long,37,0, , , , , , , , 
src\transformers\models\blenderbot\tokenization_blenderbot.py,C0301, line-too-long,54,0, , , , , , , , 
src\transformers\models\blip\convert_blip_original_pytorch_to_hf.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\blip\processing_blip.py,C0301, line-too-long,10,0, , , , , , , , 
src\transformers\models\blip_2\modeling_blip_2.py,C0301, line-too-long,183,0, , , , , , , , 
src\transformers\models\conditional_detr\image_processing_conditional_detr.py,C0301, line-too-long,180,0, , , , , , , , 
src\transformers\models\conditional_detr\image_processing_conditional_detr.py,C0325, superfluous-parens,1,0, , , , , , , , 
src\transformers\models\conditional_detr\image_processing_conditional_detr.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\conditional_detr\image_processing_conditional_detr.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\convnextv2\convert_convnextv2_to_pytorch.py,C0301, line-too-long,22,0, , , , , , , , 
src\transformers\models\convnextv2\convert_convnextv2_to_pytorch.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\cpm\tokenization_cpm_fast.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\dinov2\convert_dinov2_to_hf.py,C0301, line-too-long,13,0, , , , , , , , 
src\transformers\models\donut\convert_donut_to_pytorch.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\gpt_bigcode\configuration_gpt_bigcode.py,C0301, line-too-long,9,0, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2_fast.py,C0301, line-too-long,62,0, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2_fast.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\layoutlmv2\tokenization_layoutlmv2_fast.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\mra\convert_mra_pytorch_to_pytorch.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\nllb\tokenization_nllb_fast.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\pegasus\modeling_pegasus.py,C0301, line-too-long,149,0, , , , , , , , 
src\transformers\models\pegasus\modeling_pegasus.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\pegasus\modeling_pegasus.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\prophetnet\configuration_prophetnet.py,C0301, line-too-long,16,0, , , , , , , , 
src\transformers\models\qwen2\modeling_qwen2.py,C0301, line-too-long,124,0, , , , , , , , 
src\transformers\models\qwen2\modeling_qwen2.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\qwen2\modeling_qwen2.py,R0912, too-many-branches,3,0, , , , , , , , 
src\transformers\models\qwen2\modeling_qwen2.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
src\transformers\models\seamless_m4t\feature_extraction_seamless_m4t.py,C0301, line-too-long,28,0, , , , , , , , 
src\transformers\models\siglip\tokenization_siglip.py,C0301, line-too-long,26,0, , , , , , , , 
src\transformers\models\superpoint\configuration_superpoint.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\videomae\modeling_videomae.py,C0301, line-too-long,77,0, , , , , , , , 
src\transformers\models\videomae\modeling_videomae.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_xlm_roberta.py,C0301, line-too-long,146,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_xlm_roberta.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_xlm_roberta.py,R0912, too-many-branches,2,0, , , , , , , , 
src\transformers\models\xlm_roberta\modeling_xlm_roberta.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
examples\flax\token-classification\run_flax_ner.py,C0301, line-too-long,65,0, , , , , , , , 
examples\flax\token-classification\run_flax_ner.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\legacy\run_swag.py,C0301, line-too-long,49,0, , , , , , , , 
examples\legacy\run_swag.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\legacy\run_swag.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
examples\pytorch\language-modeling\run_clm.py,C0301, line-too-long,59,0, , , , , , , , 
examples\pytorch\language-modeling\run_clm.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\pytorch\text-generation\run_generation_contrastive_search.py,C0301, line-too-long,10,0, , , , , , , , 
examples\research_projects\luke\run_luke_ner_no_trainer.py,C0301, line-too-long,48,0, , , , , , , , 
examples\research_projects\luke\run_luke_ner_no_trainer.py,R0915, too-many-statements,1,0, , , , , , , , 
examples\research_projects\mm-imdb\run_mmimdb.py,C0301, line-too-long,38,0, , , , , , , , 
examples\research_projects\mm-imdb\run_mmimdb.py,R0912, too-many-branches,1,0, , , , , , , , 
examples\research_projects\mm-imdb\run_mmimdb.py,R0915, too-many-statements,2,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\finetune_rag.py,C0301, line-too-long,41,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\finetune_rag.py,R0912, too-many-branches,2,0, , , , , , , , 
examples\research_projects\rag-end2end-retriever\finetune_rag.py,R0915, too-many-statements,2,0, , , , , , , , 
src\transformers\models\align\convert_align_tf_to_hf.py,C0301, line-too-long,33,0, , , , , , , , 
src\transformers\models\bert\convert_bert_pytorch_checkpoint_to_original_tf.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\clvp\configuration_clvp.py,C0301, line-too-long,47,0, , , , , , , , 
src\transformers\models\mamba\configuration_mamba.py,C0301, line-too-long,11,0, , , , , , , , 
src\transformers\models\marian\convert_marian_tatoeba_to_pytorch.py,C0301, line-too-long,19,0, , , , , , , , 
src\transformers\models\marian\convert_marian_tatoeba_to_pytorch.py,R0912, too-many-branches,1,0, , , , , , , , 
src\transformers\models\marian\convert_marian_tatoeba_to_pytorch.py,R0915, too-many-statements,1,0, , , , , , , , 
src\transformers\models\markuplm\feature_extraction_markuplm.py,C0301, line-too-long,7,0, , , , , , , , 
src\transformers\models\mgp_str\configuration_mgp_str.py,C0301, line-too-long,4,0, , , , , , , , 
src\transformers\models\mpnet\tokenization_mpnet_fast.py,C0301, line-too-long,25,0, , , , , , , , 
src\transformers\models\musicgen\modeling_musicgen.py,C0301, line-too-long,243,0, , , , , , , , 
src\transformers\models\musicgen\modeling_musicgen.py,C0302, too-many-lines,1,0, , , , , , , , 
src\transformers\models\musicgen\modeling_musicgen.py,R0912, too-many-branches,5,0, , , , , , , , 
src\transformers\models\musicgen\modeling_musicgen.py,R0915, too-many-statements,3,0, , , , , , , , 
src\transformers\models\pegasus\convert_pegasus_tf_to_pytorch.py,C0301, line-too-long,8,0, , , , , , , , 
src\transformers\models\trocr\processing_trocr.py,C0301, line-too-long,15,0, , , , , , , , 
utils\extract_warnings.py,C0301, line-too-long,4,0, , , , , , , , 
