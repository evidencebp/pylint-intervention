path,msg_id,msg,alerts,chosen,In which repository the modification was done?,In which pull request the modification was done?,Do you consider the removed alert harmful?,Why do you consider it harmful (or harmless)?,"What is the code quality (1 lowest, 10 best)? Code quality refers to the code prior to the pull request.",Why do you consider the code quality as such?,"What is the expected benefit(1 – negative, 5 – neutral, 10 – great)?",Why do you consider the pull request to improve the code (or not improve it)?
tf_agents\agents\behavioral_cloning\behavioral_cloning_agent.py,C0301, line-too-long,2,1, , , , , , , , 
tf_agents\bandits\environments\piecewise_bernoulli_py_environment.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\environments\random_py_environment.py,R1719, simplifiable-if-expression,1,1, , , , , , , , 
tf_agents\networks\encoding_network.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\policies\policy_info_updater_wrapper.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\bandits\environments\stationary_stochastic_structured_py_environment.py,C0301, line-too-long,2,1, , , , , , , , 
tf_agents\agents\td3\examples\v2\train_eval.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\replay_buffers\py_uniform_replay_buffer.py,W0107,unnecessary-pass,1,1, , , , , , , , 
tf_agents\bandits\environments\stationary_stochastic_py_environment.py,C0301, line-too-long,2,1, , , , , , , , 
tf_agents\bandits\policies\reward_prediction_base_policy.py,W0107,unnecessary-pass,1,1, , , , , , , , 
tf_agents\policies\fixed_policy.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\utils\nest_utils.py,C0302, too-many-lines,1,1, , , , , , , , 
tf_agents\agents\ddpg\examples\v2\train_eval.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\agents\ppo\examples\v2\train_eval_clip_agent.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\agents\qtopt\qtopt_agent.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\agents\ppo\ppo_agent.py,R0912, too-many-branches,2,1, , , , , , , , 
tf_agents\policies\random_tf_policy.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\agents\sac\examples\v2\train_eval_rnn.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\environments\py_environment.py,W0107,unnecessary-pass,1,1, , , , , , , , 
tf_agents\environments\gymnasium_wrapper.py,R0911, too-many-return-statements,1,1, , , , , , , , 
tf_agents\policies\ou_noise_policy.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\agents\dqn\dqn_agent.py,W0107,unnecessary-pass,1,1, , , , , , , , 
tf_agents\networks\layer_utils.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\bandits\environments\stationary_stochastic_per_arm_py_environment.py,C0301, line-too-long,2,1, , , , , , , , 
tf_agents\policies\policy_saver.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\agents\sac\examples\v2\train_eval.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\policies\tf_policy.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\agents\tf_agent.py,W0107,unnecessary-pass,1,1, , , , , , , , 
tf_agents\utils\eager_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\environments\parallel_py_environment.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\policies\epsilon_greedy_policy.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\agents\td3\examples\v2\train_eval_rnn.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\agents\ddpg\examples\v2\train_eval_rnn.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\networks\sequential.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\policies\gaussian_policy.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\bandits\policies\neural_linucb_policy.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\bandits\policies\linear_bandit_policy.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\networks\network.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\replay_buffers\episodic_replay_buffer.py,C0302, too-many-lines,1,1, , , , , , , , 
tf_agents\bandits\agents\ranking_agent.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\agents\reinforce\reinforce_agent.py,W0107,unnecessary-pass,1,1, , , , , , , , 
tf_agents\agents\dqn\examples\v2\train_eval.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\policies\samplers\qtopt_cem_actions_sampler_continuous_and_one_hot.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\utils\common.py,C0302, too-many-lines,1,1, , , , , , , , 
tf_agents\environments\gym_wrapper.py,R0911, too-many-return-statements,1,1, , , , , , , , 
tf_agents\train\learner.py,C0301, line-too-long,2,1, , , , , , , , 
tf_agents\agents\categorical_dqn\examples\train_eval_atari.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\agents\reinforce\examples\v2\train_eval.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\agents\cql\cql_sac_agent.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\agents\categorical_dqn\categorical_dqn_agent.py,R0915, too-many-statements,1,1, , , , , , , , 
tf_agents\bandits\agents\examples\v2\trainer.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\bandits\policies\mixture_policy.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\agents\sac\tanh_normal_projection_network.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\environments\wrappers.py,W0107,unnecessary-pass,2,1, , , , , , , , 
tf_agents\policies\temporal_action_smoothing.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\bandits\agents\examples\v2\train_eval_ranking.py,R0912, too-many-branches,1,1, , , , , , , , 
tf_agents\bandits\agents\greedy_multi_objective_neural_agent.py,C0301, line-too-long,1,1, , , , , , , , 
tf_agents\agents\behavioral_cloning\behavioral_cloning_agent.py,W0107,unnecessary-pass,1,0, , , , , , , , 
tf_agents\networks\encoding_network.py,R0915, too-many-statements,1,0, , , , , , , , 
tf_agents\bandits\multi_objective\multi_objective_scalarizer.py,C0301, line-too-long,3,0, , , , , , , , 
tf_agents\policies\batched_py_policy.py,C0301, line-too-long,7,0, , , , , , , , 
tf_agents\utils\nest_utils.py,R0911, too-many-return-statements,1,0, , , , , , , , 
tf_agents\utils\nest_utils.py,R0912, too-many-branches,1,0, , , , , , , , 
tf_agents\utils\nest_utils.py,R1719, simplifiable-if-expression,1,0, , , , , , , , 
tf_agents\agents\ppo\ppo_agent.py,C0302, too-many-lines,1,0, , , , , , , , 
tf_agents\agents\ppo\ppo_agent.py,R0915, too-many-statements,2,0, , , , , , , , 
tf_agents\policies\random_tf_policy.py,C0301, line-too-long,1,0, , , , , , , , 
tf_agents\policies\random_tf_policy.py,R0915, too-many-statements,1,0, , , , , , , , 
tf_agents\agents\sac\examples\v2\train_eval_rnn.py,R0915, too-many-statements,1,0, , , , , , , , 
tf_agents\networks\layer_utils.py,R0912, too-many-branches,1,0, , , , , , , , 
tf_agents\networks\layer_utils.py,R1702, too-many-nested-blocks,1,0, , , , , , , , 
tf_agents\policies\policy_saver.py,R0915, too-many-statements,1,0, , , , , , , , 
tf_agents\agents\sac\examples\v2\train_eval.py,R0912, too-many-branches,1,0, , , , , , , , 
tf_agents\bandits\policies\neural_linucb_policy.py,C0301, line-too-long,1,0, , , , , , , , 
tf_agents\bandits\policies\neural_linucb_policy.py,R0912, too-many-branches,1,0, , , , , , , , 
tf_agents\bandits\policies\linear_bandit_policy.py,R0912, too-many-branches,1,0, , , , , , , , 
tf_agents\bandits\environments\non_stationary_stochastic_environment.py,W0107,unnecessary-pass,5,0, , , , , , , , 
tf_agents\agents\dqn\examples\v2\train_eval.py,R0915, too-many-statements,1,0, , , , , , , , 
tf_agents\policies\samplers\qtopt_cem_actions_sampler_continuous_and_one_hot.py,R0912, too-many-branches,1,0, , , , , , , , 
tf_agents\environments\gym_wrapper.py,R0912, too-many-branches,1,0, , , , , , , , 
tf_agents\train\learner.py,R0912, too-many-branches,1,0, , , , , , , , 
tf_agents\environments\wrappers.py,C0302, too-many-lines,1,0, , , , , , , , 
tf_agents\bandits\agents\examples\v2\train_eval_ranking.py,R0915, too-many-statements,1,0, , , , , , , , 
