path,msg_id,msg,alerts,chosen,In which repository the modification was done?,In which pull request the modification was done?,Do you consider the removed alert harmful?,Why do you consider it harmful (or harmless)?,"What is the code quality (1 lowest, 10 best)? Code quality refers to the code prior to the pull request.",Why do you consider the code quality as such?,"What is the expected benefit(1 – negative, 5 – neutral, 10 – great)?",Why do you consider the pull request to improve the code (or not improve it)?
references\depth\stereo\utils\metrics.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\prototype\datasets\_builtin\dtd.py,C0325, superfluous-parens,1,1, , , , , , , , 
torchvision\prototype\datasets\utils\_dataset.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\transforms\transforms.py,C0325, superfluous-parens,2,1, , , , , , , , 
references\depth\stereo\visualization.py,C0301, line-too-long,2,1, , , , , , , , 
references\segmentation\train.py,R0915, too-many-statements,1,1, , , , , , , , 
torchvision\datasets\usps.py,C0301, line-too-long,2,1, , , , , , , , 
gallery\transforms\plot_custom_transforms.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\datasets\cityscapes.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\datasets\hmdb51.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\prototype\datasets\utils\_resource.py,W0718, broad-exception-caught,1,1, , , , , , , , 
scripts\release_notes\classify_prs.py,W0104, pointless-statement,2,1, , , , , , , , 
references\detection\engine.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\detection\ssd.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\tv_tensors\_torch_function_helpers.py,C0301, line-too-long,1,1, , , , , , , , 
gallery\transforms\plot_transforms_getting_started.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\prototype\datasets\__init__.py,C0301, line-too-long,2,1, , , , , , , , 
gallery\others\plot_visualization_utils.py,C0325, superfluous-parens,1,1, , , , , , , , 
references\classification\sampler.py,C0301, line-too-long,2,1, , , , , , , , 
scripts\release_notes\retrieve_prs_data.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\_utils.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\datasets\svhn.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\ops\focal_loss.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\transforms\v2\functional\_misc.py,R0912, too-many-branches,2,1, , , , , , , , 
references\similarity\sampler.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\detection\generalized_rcnn.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\models\shufflenetv2.py,C0325, superfluous-parens,1,1, , , , , , , , 
gallery\others\plot_optical_flow.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\_internally_replaced_utils.py,C0301, line-too-long,1,1, , , , , , , , 
examples\cpp\script_model.py,C0301, line-too-long,1,1, , , , , , , , 
references\detection\group_by_aspect_ratio.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\datasets\video_utils.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\datasets\lsun.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\ops\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\prototype\transforms\_augment.py,C0325, superfluous-parens,1,1, , , , , , , , 
references\segmentation\coco_utils.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\io\video_reader.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\models\mobilenetv3.py,C0325, superfluous-parens,1,1, , , , , , , , 
benchmarks\encoding_decoding.py,C0301, line-too-long,2,1, , , , , , , , 
references\video_classification\presets.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\models\feature_extraction.py,R0915, too-many-statements,1,1, , , , , , , , 
torchvision\prototype\datasets\_api.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\prototype\datasets\_builtin\usps.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\models\_meta.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\detection\fcos.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\transforms\v2\_geometry.py,C0302, too-many-lines,1,1, , , , , , , , 
torchvision\transforms\v2\functional\_deprecated.py,C0301, line-too-long,1,1, , , , , , , , 
docs\source\conf.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\datasets\mnist.py,C0325, superfluous-parens,1,1, , , , , , , , 
torchvision\prototype\datasets\generate_category_files.py,C0301, line-too-long,2,1, , , , , , , , 
packaging\wheel\relocate.py,R0915, too-many-statements,1,1, , , , , , , , 
references\video_classification\train.py,R0915, too-many-statements,1,1, , , , , , , , 
torchvision\datasets\moving_mnist.py,C0325, superfluous-parens,1,1, , , , , , , , 
torchvision\models\detection\retinanet.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\models\swin_transformer.py,R0915, too-many-statements,1,1, , , , , , , , 
torchvision\ops\giou_loss.py,C0301, line-too-long,2,1, , , , , , , , 
references\classification\train.py,R0912, too-many-branches,2,1, , , , , , , , 
torchvision\transforms\v2\functional\_temporal.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\prototype\transforms\_type_conversion.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\transforms\v2\_type_conversion.py,C0301, line-too-long,1,1, , , , , , , , 
gallery\transforms\plot_custom_tv_tensors.py,W0104, pointless-statement,1,1, , , , , , , , 
torchvision\prototype\datasets\_builtin\caltech.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\transforms\v2\functional\_type_conversion.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\segmentation\_utils.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\prototype\datasets\_builtin\food101.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\prototype\models\depth\stereo\crestereo.py,C0302, too-many-lines,1,1, , , , , , , , 
torchvision\models\segmentation\deeplabv3.py,W0107,unnecessary-pass,1,1, , , , , , , , 
torchvision\transforms\v2\_auto_augment.py,C0325, superfluous-parens,1,1, , , , , , , , 
torchvision\datasets\fgvc_aircraft.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\prototype\tv_tensors\_label.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\transforms\v2\functional\_geometry.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\datasets\kitti.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\detection\roi_heads.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\transforms\v2\_temporal.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\extension.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\segmentation\fcn.py,W0107,unnecessary-pass,1,1, , , , , , , , 
gallery\transforms\helpers.py,C0301, line-too-long,1,1, , , , , , , , 
references\detection\train.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\ops\diou_loss.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\transforms\_functional_pil.py,R0915, too-many-statements,1,1, , , , , , , , 
references\classification\presets.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\models\quantization\mobilenet.py,W0401, wildcard-import,2,1, , , , , , , , 
gallery\others\plot_scripted_tensor_transforms.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\datasets\cifar.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\transforms\_functional_video.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\datasets\ucf101.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\transforms\functional.py,C0302, too-many-lines,1,1, , , , , , , , 
references\depth\stereo\train.py,R0912, too-many-branches,2,1, , , , , , , , 
references\optical_flow\presets.py,C0301, line-too-long,2,1, , , , , , , , 
references\optical_flow\utils.py,C0325, superfluous-parens,1,1, , , , , , , , 
torchvision\io\image.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\models\mobilenet.py,W0401, wildcard-import,2,1, , , , , , , , 
torchvision\transforms\v2\_augment.py,C0325, superfluous-parens,1,1, , , , , , , , 
hubconf.py,C0301, line-too-long,2,1, , , , , , , , 
references\depth\stereo\utils\distributed.py,C0325, superfluous-parens,1,1, , , , , , , , 
references\detection\presets.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\vision_transformer.py,R0915, too-many-statements,1,1, , , , , , , , 
references\optical_flow\train.py,R0915, too-many-statements,1,1, , , , , , , , 
torchvision\datasets\_stereo_matching.py,C0302, too-many-lines,1,1, , , , , , , , 
torchvision\datasets\dtd.py,C0325, superfluous-parens,1,1, , , , , , , , 
references\detection\transforms.py,C0325, superfluous-parens,1,1, , , , , , , , 
torchvision\models\video\mvit.py,R0912, too-many-branches,1,1, , , , , , , , 
setup.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\datasets\sbu.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\prototype\datasets\_builtin\eurosat.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\transforms\autoaugment.py,C0325, superfluous-parens,1,1, , , , , , , , 
.github\scripts\run-clang-format.py,R0915, too-many-statements,1,1, , , , , , , , 
torchvision\datasets\semeion.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\models\detection\faster_rcnn.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\prototype\datasets\_builtin\svhn.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\prototype\utils\_internal.py,W0107,unnecessary-pass,1,1, , , , , , , , 
torchvision\ops\ciou_loss.py,C0301, line-too-long,2,1, , , , , , , , 
references\depth\stereo\parsing.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\prototype\datasets\_builtin\semeion.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\prototype\datasets\utils\_encoded.py,C0301, line-too-long,1,1, , , , , , , , 
references\detection\coco_utils.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\io\video.py,R0915, too-many-statements,1,1, , , , , , , , 
gallery\transforms\plot_cutmix_mixup.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\models\_utils.py,R0916, too-many-boolean-expressions,1,1, , , , , , , , 
scripts\download_model_urls.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\models\efficientnet.py,C0302, too-many-lines,1,1, , , , , , , , 
torchvision\prototype\datasets\benchmark.py,W0718, broad-exception-caught,1,1, , , , , , , , 
torchvision\transforms\v2\_transform.py,C0325, superfluous-parens,1,1, , , , , , , , 
torchvision\datasets\eurosat.py,C0301, line-too-long,1,1, , , , , , , , 
torchvision\transforms\_functional_tensor.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\transforms\v2\_container.py,C0325, superfluous-parens,1,1, , , , , , , , 
references\classification\train_quantization.py,R0912, too-many-branches,1,1, , , , , , , , 
torchvision\tv_tensors\_video.py,C0301, line-too-long,2,1, , , , , , , , 
torchvision\models\regnet.py,C0302, too-many-lines,1,1, , , , , , , , 
torchvision\prototype\datasets\utils\__init__.py,C0301, line-too-long,1,1, , , , , , , , 
references\depth\stereo\utils\metrics.py,R0912, too-many-branches,1,0, , , , , , , , 
torchvision\models\quantization\utils.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\ops\drop_block.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\models\vgg.py,C0301, line-too-long,16,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\dtd.py,C0301, line-too-long,2,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\pcam.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\transforms\transforms.py,C0301, line-too-long,92,0, , , , , , , , 
torchvision\transforms\transforms.py,C0302, too-many-lines,1,0, , , , , , , , 
torchvision\transforms\transforms.py,R0912, too-many-branches,1,0, , , , , , , , 
references\segmentation\train.py,C0301, line-too-long,21,0, , , , , , , , 
references\segmentation\train.py,R0912, too-many-branches,1,0, , , , , , , , 
torchvision\datasets\lfw.py,C0301, line-too-long,9,0, , , , , , , , 
torchvision\models\detection\transform.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\fer2013.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\datasets\cityscapes.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\datasets\folder.py,C0301, line-too-long,8,0, , , , , , , , 
torchvision\datasets\vision.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\models\segmentation\lraspp.py,C0301, line-too-long,12,0, , , , , , , , 
torchvision\prototype\datasets\utils\_resource.py,C0301, line-too-long,9,0, , , , , , , , 
scripts\release_notes\classify_prs.py,C0301, line-too-long,1,0, , , , , , , , 
torchvision\datasets\coco.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\models\optical_flow\_utils.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\ops\poolers.py,C0301, line-too-long,6,0, , , , , , , , 
references\depth\stereo\cascade_evaluation.py,C0301, line-too-long,21,0, , , , , , , , 
torchvision\datasets\sbd.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\models\detection\ssd.py,C0301, line-too-long,39,0, , , , , , , , 
torchvision\__init__.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\datasets\stl10.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\models\detection\rpn.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\transforms\_transforms_video.py,C0301, line-too-long,3,0, , , , , , , , 
gallery\others\plot_visualization_utils.py,C0301, line-too-long,15,0, , , , , , , , 
torchvision\transforms\_presets.py,C0301, line-too-long,16,0, , , , , , , , 
references\classification\transforms.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\oxford_iiit_pet.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\transforms\v2\_deprecated.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\transforms\v2\functional\_misc.py,C0301, line-too-long,37,0, , , , , , , , 
torchvision\transforms\v2\functional\_misc.py,R0911, too-many-return-statements,1,0, , , , , , , , 
torchvision\models\detection\generalized_rcnn.py,C0301, line-too-long,8,0, , , , , , , , 
torchvision\models\shufflenetv2.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\tv_tensors\__init__.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\tv_tensors\__init__.py,R0801, duplicate-code,298,0, , , , , , , , 
torchvision\datasets\imagenet.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\datasets\inaturalist.py,C0301, line-too-long,8,0, , , , , , , , 
torchvision\datasets\rendered_sst2.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\datasets\video_utils.py,C0301, line-too-long,12,0, , , , , , , , 
torchvision\io\_video_opt.py,C0301, line-too-long,8,0, , , , , , , , 
torchvision\prototype\transforms\_geometry.py,C0301, line-too-long,6,0, , , , , , , , 
references\segmentation\v2_extras.py,C0301, line-too-long,8,0, , , , , , , , 
torchvision\datasets\gtsrb.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\ops\ps_roi_pool.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\prototype\transforms\_augment.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\utils.py,C0301, line-too-long,26,0, , , , , , , , 
torchvision\utils.py,R0912, too-many-branches,3,0, , , , , , , , 
references\segmentation\utils.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\ops\boxes.py,C0301, line-too-long,11,0, , , , , , , , 
torchvision\ops\feature_pyramid_network.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\ops\misc.py,C0301, line-too-long,23,0, , , , , , , , 
references\depth\stereo\transforms.py,C0301, line-too-long,20,0, , , , , , , , 
torchvision\io\video_reader.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\models\mobilenetv3.py,C0301, line-too-long,11,0, , , , , , , , 
references\similarity\train.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\datasets\food101.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\models\feature_extraction.py,C0301, line-too-long,14,0, , , , , , , , 
torchvision\models\feature_extraction.py,C0325, superfluous-parens,1,0, , , , , , , , 
torchvision\models\feature_extraction.py,R0912, too-many-branches,1,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\imagenet.py,C0301, line-too-long,7,0, , , , , , , , 
references\depth\stereo\utils\logger.py,C0301, line-too-long,4,0, , , , , , , , 
references\detection\coco_eval.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\datasets\_optical_flow.py,C0301, line-too-long,20,0, , , , , , , , 
torchvision\models\_meta.py,C0302, too-many-lines,1,0, , , , , , , , 
torchvision\models\detection\fcos.py,C0301, line-too-long,44,0, , , , , , , , 
torchvision\transforms\v2\_geometry.py,C0301, line-too-long,114,0, , , , , , , , 
torchvision\transforms\v2\_geometry.py,C0325, superfluous-parens,3,0, , , , , , , , 
docs\source\conf.py,C0301, line-too-long,18,0, , , , , , , , 
torchvision\_meta_registrations.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\datasets\mnist.py,C0301, line-too-long,20,0, , , , , , , , 
torchvision\prototype\datasets\generate_category_files.py,W0718, broad-exception-caught,1,0, , , , , , , , 
packaging\wheel\relocate.py,C0301, line-too-long,7,0, , , , , , , , 
references\video_classification\train.py,C0301, line-too-long,27,0, , , , , , , , 
references\video_classification\train.py,R0912, too-many-branches,1,0, , , , , , , , 
torchvision\datasets\moving_mnist.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\models\detection\retinanet.py,C0301, line-too-long,57,0, , , , , , , , 
torchvision\models\quantization\mobilenetv3.py,C0301, line-too-long,14,0, , , , , , , , 
torchvision\models\quantization\resnet.py,C0301, line-too-long,14,0, , , , , , , , 
torchvision\models\swin_transformer.py,C0301, line-too-long,46,0, , , , , , , , 
torchvision\models\swin_transformer.py,C0302, too-many-lines,1,0, , , , , , , , 
references\classification\train.py,C0301, line-too-long,49,0, , , , , , , , 
references\classification\train.py,R0915, too-many-statements,2,0, , , , , , , , 
torchvision\models\squeezenet.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\models\detection\keypoint_rcnn.py,C0301, line-too-long,39,0, , , , , , , , 
torchvision\models\mobilenetv2.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\tv_tensors\_bounding_boxes.py,C0301, line-too-long,10,0, , , , , , , , 
gallery\transforms\plot_custom_tv_tensors.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\models\video\resnet.py,C0301, line-too-long,25,0, , , , , , , , 
torchvision\tv_tensors\_image.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\models\inception.py,C0301, line-too-long,14,0, , , , , , , , 
torchvision\datasets\phototour.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\models\detection\backbone_utils.py,C0301, line-too-long,17,0, , , , , , , , 
torchvision\models\video\swin_transformer.py,C0301, line-too-long,20,0, , , , , , , , 
torchvision\models\googlenet.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\prototype\models\depth\stereo\crestereo.py,C0301, line-too-long,68,0, , , , , , , , 
torchvision\prototype\models\depth\stereo\crestereo.py,R0915, too-many-statements,1,0, , , , , , , , 
torchvision\transforms\v2\_misc.py,C0301, line-too-long,42,0, , , , , , , , 
references\depth\stereo\utils\losses.py,C0301, line-too-long,21,0, , , , , , , , 
torchvision\models\segmentation\deeplabv3.py,C0301, line-too-long,25,0, , , , , , , , 
torchvision\ops\roi_pool.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\transforms\v2\_auto_augment.py,C0301, line-too-long,41,0, , , , , , , , 
torchvision\transforms\v2\_auto_augment.py,R0911, too-many-return-statements,1,0, , , , , , , , 
torchvision\transforms\v2\_auto_augment.py,R0912, too-many-branches,1,0, , , , , , , , 
torchvision\datasets\widerface.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\models\detection\anchor_utils.py,C0301, line-too-long,17,0, , , , , , , , 
torchvision\transforms\v2\functional\_geometry.py,C0301, line-too-long,104,0, , , , , , , , 
torchvision\transforms\v2\functional\_geometry.py,C0302, too-many-lines,1,0, , , , , , , , 
.github\process_commit.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\datasets\country211.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\datasets\fer2013.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\models\detection\roi_heads.py,C0301, line-too-long,31,0, , , , , , , , 
torchvision\models\detection\roi_heads.py,R0915, too-many-statements,1,0, , , , , , , , 
torchvision\ops\roi_align.py,C0301, line-too-long,10,0, , , , , , , , 
gallery\transforms\plot_transforms_e2e.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\datasets\clevr.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\datasets\places365.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\datasets\utils.py,C0301, line-too-long,25,0, , , , , , , , 
torchvision\extension.py,W0718, broad-exception-caught,1,0, , , , , , , , 
torchvision\models\resnet.py,C0301, line-too-long,35,0, , , , , , , , 
torchvision\models\segmentation\fcn.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\tv_tensors\_dataset_wrapper.py,C0301, line-too-long,62,0, , , , , , , , 
references\detection\train.py,C0301, line-too-long,27,0, , , , , , , , 
references\detection\train.py,R0915, too-many-statements,1,0, , , , , , , , 
torchvision\ops\_utils.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\transforms\_functional_pil.py,C0301, line-too-long,2,0, , , , , , , , 
torchvision\transforms\_functional_pil.py,C0325, superfluous-parens,1,0, , , , , , , , 
torchvision\transforms\_functional_pil.py,R0912, too-many-branches,1,0, , , , , , , , 
gallery\others\plot_video_api.py,C0301, line-too-long,11,0, , , , , , , , 
torchvision\models\quantization\googlenet.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\gtsrb.py,C0301, line-too-long,6,0, , , , , , , , 
references\detection\utils.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\datasets\sun397.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\models\maxvit.py,C0301, line-too-long,27,0, , , , , , , , 
torchvision\models\quantization\inception.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\celeba.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\transforms\functional.py,C0301, line-too-long,71,0, , , , , , , , 
torchvision\transforms\functional.py,C0325, superfluous-parens,1,0, , , , , , , , 
torchvision\transforms\functional.py,R0912, too-many-branches,3,0, , , , , , , , 
torchvision\transforms\functional.py,R0915, too-many-statements,1,0, , , , , , , , 
references\depth\stereo\train.py,C0301, line-too-long,67,0, , , , , , , , 
references\depth\stereo\train.py,R0915, too-many-statements,3,0, , , , , , , , 
references\optical_flow\utils.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\datasets\omniglot.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\io\image.py,C0301, line-too-long,9,0, , , , , , , , 
torchvision\transforms\v2\_augment.py,C0301, line-too-long,24,0, , , , , , , , 
torchvision\models\quantization\shufflenetv2.py,C0301, line-too-long,22,0, , , , , , , , 
torchvision\models\vision_transformer.py,C0301, line-too-long,36,0, , , , , , , , 
references\optical_flow\train.py,C0301, line-too-long,35,0, , , , , , , , 
references\optical_flow\train.py,R0912, too-many-branches,1,0, , , , , , , , 
torchvision\datasets\_stereo_matching.py,C0301, line-too-long,53,0, , , , , , , , 
torchvision\datasets\dtd.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\models\video\s3d.py,C0301, line-too-long,6,0, , , , , , , , 
references\detection\transforms.py,C0301, line-too-long,19,0, , , , , , , , 
references\detection\transforms.py,R0912, too-many-branches,1,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\voc.py,C0301, line-too-long,15,0, , , , , , , , 
references\video_classification\utils.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\models\_api.py,C0301, line-too-long,23,0, , , , , , , , 
torchvision\models\optical_flow\raft.py,C0301, line-too-long,73,0, , , , , , , , 
torchvision\models\video\mvit.py,C0301, line-too-long,38,0, , , , , , , , 
references\optical_flow\transforms.py,C0301, line-too-long,15,0, , , , , , , , 
setup.py,C0301, line-too-long,20,0, , , , , , , , 
setup.py,R0915, too-many-statements,2,0, , , , , , , , 
setup.py,W0718, broad-exception-caught,1,0, , , , , , , , 
torchvision\models\convnext.py,C0301, line-too-long,13,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\sbd.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\transforms\autoaugment.py,C0301, line-too-long,28,0, , , , , , , , 
torchvision\transforms\autoaugment.py,R0912, too-many-branches,1,0, , , , , , , , 
.github\scripts\run-clang-format.py,C0301, line-too-long,6,0, , , , , , , , 
.github\scripts\run-clang-format.py,R0912, too-many-branches,1,0, , , , , , , , 
torchvision\transforms\v2\functional\_meta.py,C0301, line-too-long,19,0, , , , , , , , 
references\depth\stereo\presets.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\models\detection\faster_rcnn.py,C0301, line-too-long,64,0, , , , , , , , 
torchvision\datasets\flowers102.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\datasets\kinetics.py,C0301, line-too-long,8,0, , , , , , , , 
torchvision\datasets\oxford_iiit_pet.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\datasets\stanford_cars.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\models\detection\mask_rcnn.py,C0301, line-too-long,41,0, , , , , , , , 
torchvision\prototype\utils\_internal.py,C0301, line-too-long,11,0, , , , , , , , 
gallery\transforms\plot_tv_tensors.py,C0301, line-too-long,8,0, , , , , , , , 
references\classification\utils.py,C0301, line-too-long,12,0, , , , , , , , 
torchvision\models\detection\ssdlite.py,C0301, line-too-long,23,0, , , , , , , , 
torchvision\datasets\samplers\clip_sampler.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\io\video.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\io\video.py,R0912, too-many-branches,2,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\coco.py,C0301, line-too-long,9,0, , , , , , , , 
torchvision\tv_tensors\_mask.py,C0301, line-too-long,4,0, , , , , , , , 
gallery\others\plot_repurposing_annotations.py,C0301, line-too-long,9,0, , , , , , , , 
torchvision\datasets\pcam.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\models\_utils.py,C0301, line-too-long,25,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\mnist.py,C0301, line-too-long,33,0, , , , , , , , 
torchvision\prototype\datasets\_folder.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\datasets\imagenette.py,C0301, line-too-long,9,0, , , , , , , , 
torchvision\models\mnasnet.py,C0301, line-too-long,12,0, , , , , , , , 
torchvision\transforms\v2\functional\_color.py,C0301, line-too-long,41,0, , , , , , , , 
torchvision\transforms\v2\functional\_color.py,C0325, superfluous-parens,3,0, , , , , , , , 
torchvision\models\alexnet.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\cub200.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\prototype\models\depth\stereo\raft_stereo.py,C0301, line-too-long,77,0, , , , , , , , 
torchvision\transforms\v2\_meta.py,C0301, line-too-long,3,0, , , , , , , , 
torchvision\models\quantization\mobilenetv2.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\ops\ps_roi_align.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\stanford_cars.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\prototype\datasets\utils\_internal.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\transforms\v2\functional\_utils.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\ops\deform_conv.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\prototype\datasets\_builtin\clevr.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\transforms\v2\_utils.py,C0301, line-too-long,20,0, , , , , , , , 
references\segmentation\presets.py,C0301, line-too-long,4,0, , , , , , , , 
torchvision\datasets\celeba.py,C0301, line-too-long,18,0, , , , , , , , 
torchvision\models\efficientnet.py,C0301, line-too-long,42,0, , , , , , , , 
torchvision\models\efficientnet.py,C0325, superfluous-parens,2,0, , , , , , , , 
torchvision\ops\_register_onnx_ops.py,C0301, line-too-long,10,0, , , , , , , , 
torchvision\prototype\datasets\benchmark.py,C0301, line-too-long,22,0, , , , , , , , 
torchvision\prototype\transforms\_presets.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\transforms\v2\_transform.py,C0301, line-too-long,28,0, , , , , , , , 
torchvision\models\densenet.py,C0301, line-too-long,15,0, , , , , , , , 
torchvision\datasets\voc.py,C0301, line-too-long,5,0, , , , , , , , 
torchvision\models\detection\_utils.py,C0301, line-too-long,17,0, , , , , , , , 
torchvision\transforms\_functional_tensor.py,C0301, line-too-long,31,0, , , , , , , , 
torchvision\transforms\_functional_tensor.py,C0325, superfluous-parens,7,0, , , , , , , , 
torchvision\transforms\_functional_tensor.py,R0911, too-many-return-statements,1,0, , , , , , , , 
torchvision\transforms\v2\_container.py,C0301, line-too-long,6,0, , , , , , , , 
gallery\transforms\plot_transforms_illustrations.py,C0301, line-too-long,9,0, , , , , , , , 
references\classification\train_quantization.py,C0301, line-too-long,25,0, , , , , , , , 
references\classification\train_quantization.py,R0915, too-many-statements,1,0, , , , , , , , 
torchvision\tv_tensors\_tv_tensor.py,C0301, line-too-long,16,0, , , , , , , , 
torchvision\datasets\caltech.py,C0301, line-too-long,7,0, , , , , , , , 
torchvision\models\regnet.py,C0301, line-too-long,110,0, , , , , , , , 
torchvision\prototype\transforms\_misc.py,C0301, line-too-long,6,0, , , , , , , , 
torchvision\transforms\v2\_color.py,C0301, line-too-long,24,0, , , , , , , , 
